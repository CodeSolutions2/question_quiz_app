{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8311d7c",
   "metadata": {},
   "source": [
    "# Etudier pour Python Linkedin üòî\n",
    "\n",
    "Exam URL: https://www.linkedin.com/skill-assessments/Python%20(Programming%20Language)/quiz-intro/\n",
    "\n",
    "https://www.gcertificationcourse.com/linkedin-python-skill-quiz-answers/\n",
    "\n",
    "https://learn.microsoft.com/en-us/python/api/overview/azure/storage-file-share-readme?view=azure-python\n",
    "\n",
    "https://learn.microsoft.com/en-us/rest/api/storageservices/put-blob-from-url?tabs=azure-ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6980aa8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE html>\\n<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en-US\">\\n    <head>\\n        <!--start-optimizely--><!--end-optimizely-->\\n        <!-- Google Tag Manager -->\\n<script>\\nwindow.dataLayer = window.dataLayer || [];\\ndataLayer.push({\"environment\":\"production\"});\\ndataLayer.push({\"ads\":{\"display\":true}});\\n(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push(\\n{\\'gtm.start\\': new Date().getTime(),event:\\'gtm.js\\'}\\n);var f=d.getElementsByTagName(s)[0],\\nj=d.createElement(s),dl=l!=\\'dataLayer\\'?\\'&l=\\'+l:\\'\\';j.async=true;j.src=\\n\\'//www.googletagmanager.com/gtm.js?id=\\'+i+dl;f.parentNode.insertBefore(j,f);\\n})(window,document,\\'script\\',\\'dataLayer\\',\\'GTM-KCC7SF\\');</script>\\n<!-- End Google Tag Manager -->                    \\n\\n                    \\n                <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=no, minimal-ui\" >\\n        \\n    <meta name=\"apple-itunes-app\" content=\"app-id=734887700\">\\n    <meta name=\"google-play-app\" content=\"app-id=com.studymode.cram\">\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\\n \\n    <link rel=\"stylesheet\" href=\"/assets/whiteboard/styles/smart-app-banner.css\" type=\"text/css\" media=\"screen\">\\n\\n        \\n        \\n        <link rel=\"shortcut icon\" type=\"image/x-icon\" href=\"//www.cram.com/favicon.ico\">\\n        <link rel=\"canonical\" href=\"https://www.cram.com/flashcards/git-12843452\"><meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" >\\n<meta name=\"description\" content=\"Study Flashcards On Git_DATASCIENCE at Cram.com. Quickly memorize the terms, phrases and much more. Cram.com makes it easy to get the grade you want!\" >\\n<meta name=\"ROBOTS\" content=\"NOINDEX, NOFOLLOW\" ><title>Git_DATASCIENCE Flashcards - Cram.com</title>            <script type=\"text/javascript\" src=\"https://browser.sentry-cdn.com/5.24.2/bundle.tracing.min.js\" crossorigin=\\'anonymous\\'></script>\\n            <script type=\"text/javascript\">\\n                if(Sentry) {\\n                    Sentry.init({\\n                          dsn: \\'https://2d050d29bad34510a09dcc3b05120fa3@o133474.ingest.sentry.io/5411670\\',\\n                          version: \\'1.0.3\\',\\n                          ignoreErrors: [/NotAllowedError/,/NotSupportedError/,/SecurityError:/,/NetworkError:/,/AbortError:/,/TypeError:/,/Unable to get property/,/Cannot (read|set) property/,/ResizeObserver loop limit exceeded/,/Failed to fetch/,/No error message/,/Can\\'t execute code from a freed script/,/Extension context invalidated/,/JSON Parse error/,/is not (a|an) (object|constructor|function)/,/Non-Error promise rejection/,/Object expected/,/is (null|undefined)/,/Object doesn\\'t support this action/,/Unexpected token/],\\n                          blacklistUrls: [\\n                            /graph\\\\.facebook\\\\.com/i,\\n                            /connect\\\\.facebook\\\\.net\\\\/en_US\\\\/all\\\\.js/i,\\n                            /extensions\\\\//i,\\n                            /^chrome:\\\\/\\\\//i,\\n                            /127\\\\.0\\\\.0\\\\.1:4001\\\\/isrunning/i,\\n                          ]\\n                    });\\n                    console.log(\\'Sentry Initialized\\');\\n                }\\n          </script><script type=\"text/javascript\">\\n     var googletag = googletag || {};\\n     googletag.cmd = googletag.cmd || [];\\n     (function() {\\n         var gads = document.createElement(\"script\");\\n         gads.async = true;\\n         gads.type = \"text/javascript\";\\n         var useSSL = \"https:\" == document.location.protocol;\\n         gads.src = (useSSL ? \"https:\" : \"http:\") +\\n             \"//www.googletagservices.com/tag/js/gpt.js\";\\n         var node = document.getElementsByTagName(\"script\")[0];\\n         node.parentNode.insertBefore(gads, node);\\n     })();\\n </script>\\n <script type=\"text/javascript\">\\n     googletag.cmd.push(function() {googletag.pubads().enableSingleRequest();googletag.enableServices();});</script><link href=\"//beckett.cram.com/1.13/css/cram.1.13.3.min.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\" >\\n<link href=\"/fce/css/_sets/2969960122.css\" media=\"all\" rel=\"stylesheet\" type=\"text/css\" >\\n<!--[if lte IE 8]> <link href=\"/assets/whiteboard/styles/ie8-and-down.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\" ><![endif]-->\\n<link href=\"//fonts.googleapis.com/css?family=Open+Sans:100,300,400,600,700\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\" >        <script type=\"text/javascript\">\\n        /*! LAB.js (LABjs :: Loading And Blocking JavaScript)\\n    v2.0.3 (c) Kyle Simpson\\n    MIT License\\n*/\\n(function(o){var K=o.$LAB,y=\"UseLocalXHR\",z=\"AlwaysPreserveOrder\",u=\"AllowDuplicates\",A=\"CacheBust\",B=\"BasePath\",C=/^[^?#]*\\\\//.exec(location.href)[0],D=/^\\\\w+\\\\:\\\\/\\\\/\\\\/?[^\\\\/]+/.exec(C)[0],i=document.head||document.getElementsByTagName(\"head\"),L=(o.opera&&Object.prototype.toString.call(o.opera)==\"[object Opera]\")||(\"MozAppearance\"in document.documentElement.style),q=document.createElement(\"script\"),E=typeof q.preload==\"boolean\",r=E||(q.readyState&&q.readyState==\"uninitialized\"),F=!r&&q.async===true,M=!r&&!F&&!L;function G(a){return Object.prototype.toString.call(a)==\"[object Function]\"}function H(a){return Object.prototype.toString.call(a)==\"[object Array]\"}function N(a,c){var b=/^\\\\w+\\\\:\\\\/\\\\//;if(/^\\\\/\\\\/\\\\/?/.test(a)){a=location.protocol+a}else if(!b.test(a)&&a.charAt(0)!=\"/\"){a=(c||\"\")+a}return b.test(a)?a:((a.charAt(0)==\"/\"?D:C)+a)}function s(a,c){for(var b in a){if(a.hasOwnProperty(b)){c[b]=a[b]}}return c}function O(a){var c=false;for(var b=0;b<a.scripts.length;b++){if(a.scripts[b].ready&&a.scripts[b].exec_trigger){c=true;a.scripts[b].exec_trigger();a.scripts[b].exec_trigger=null}}return c}function t(a,c,b,d){a.onload=a.onreadystatechange=function(){if((a.readyState&&a.readyState!=\"complete\"&&a.readyState!=\"loaded\")||c[b])return;a.onload=a.onreadystatechange=null;d()}}function I(a){a.ready=a.finished=true;for(var c=0;c<a.finished_listeners.length;c++){a.finished_listeners[c]()}a.ready_listeners=[];a.finished_listeners=[]}function P(d,f,e,g,h){setTimeout(function(){var a,c=f.real_src,b;if(\"item\"in i){if(!i[0]){setTimeout(arguments.callee,25);return}i=i[0]}a=document.createElement(\"script\");if(f.type)a.type=f.type;if(f.charset)a.charset=f.charset;if(h){if(r){e.elem=a;if(E){a.preload=true;a.onpreload=g}else{a.onreadystatechange=function(){if(a.readyState==\"loaded\")g()}}a.src=c}else if(h&&c.indexOf(D)==0&&d[y]){b=new XMLHttpRequest();b.onreadystatechange=function(){if(b.readyState==4){b.onreadystatechange=function(){};e.text=b.responseText+\"\\\\n//@ sourceURL=\"+c;g()}};b.open(\"GET\",c);b.send()}else{a.type=\"text/cache-script\";t(a,e,\"ready\",function(){i.removeChild(a);g()});a.src=c;i.insertBefore(a,i.firstChild)}}else if(F){a.async=false;t(a,e,\"finished\",g);a.src=c;i.insertBefore(a,i.firstChild)}else{t(a,e,\"finished\",g);a.src=c;i.insertBefore(a,i.firstChild)}},0)}function J(){var l={},Q=r||M,n=[],p={},m;l[y]=true;l[z]=false;l[u]=false;l[A]=false;l[B]=\"\";function R(a,c,b){var d;function f(){if(d!=null){d=null;I(b)}}if(p[c.src].finished)return;if(!a[u])p[c.src].finished=true;d=b.elem||document.createElement(\"script\");if(c.type)d.type=c.type;if(c.charset)d.charset=c.charset;t(d,b,\"finished\",f);if(b.elem){b.elem=null}else if(b.text){d.onload=d.onreadystatechange=null;d.text=b.text}else{d.src=c.real_src}i.insertBefore(d,i.firstChild);if(b.text){f()}}function S(c,b,d,f){var e,g,h=function(){b.ready_cb(b,function(){R(c,b,e)})},j=function(){b.finished_cb(b,d)};b.src=N(b.src,c[B]);b.real_src=b.src+(c[A]?((/\\\\?.*$/.test(b.src)?\"&_\":\"?_\")+~~(Math.random()*1E9)+\"=\"):\"\");if(!p[b.src])p[b.src]={items:[],finished:false};g=p[b.src].items;if(c[u]||g.length==0){e=g[g.length]={ready:false,finished:false,ready_listeners:[h],finished_listeners:[j]};P(c,b,e,((f)?function(){e.ready=true;for(var a=0;a<e.ready_listeners.length;a++){e.ready_listeners[a]()}e.ready_listeners=[]}:function(){I(e)}),f)}else{e=g[0];if(e.finished){j()}else{e.finished_listeners.push(j)}}}function v(){var e,g=s(l,{}),h=[],j=0,w=false,k;function T(a,c){a.ready=true;a.exec_trigger=c;x()}function U(a,c){a.ready=a.finished=true;a.exec_trigger=null;for(var b=0;b<c.scripts.length;b++){if(!c.scripts[b].finished)return}c.finished=true;x()}function x(){while(j<h.length){if(G(h[j])){try{h[j++]()}catch(err){}continue}else if(!h[j].finished){if(O(h[j]))continue;break}j++}if(j==h.length){w=false;k=false}}function V(){if(!k||!k.scripts){h.push(k={scripts:[],finished:true})}}e={script:function(){for(var f=0;f<arguments.length;f++){(function(a,c){var b;if(!H(a)){c=[a]}for(var d=0;d<c.length;d++){V();a=c[d];if(G(a))a=a();if(!a)continue;if(H(a)){b=[].slice.call(a);b.unshift(d,1);[].splice.apply(c,b);d--;continue}if(typeof a==\"string\")a={src:a};a=s(a,{ready:false,ready_cb:T,finished:false,finished_cb:U});k.finished=false;k.scripts.push(a);S(g,a,k,(Q&&w));w=true;if(g[z])e.wait()}})(arguments[f],arguments[f])}return e},wait:function(){if(arguments.length>0){for(var a=0;a<arguments.length;a++){h.push(arguments[a])}k=h[h.length-1]}else k=false;x();return e}};return{script:e.script,wait:e.wait,setOptions:function(a){s(a,g);return e}}}m={setGlobalDefaults:function(a){s(a,l);return m},setOptions:function(){return v().setOptions.apply(null,arguments)},script:function(){return v().script.apply(null,arguments)},wait:function(){return v().wait.apply(null,arguments)},queueScript:function(){n[n.length]={type:\"script\",args:[].slice.call(arguments)};return m},queueWait:function(){n[n.length]={type:\"wait\",args:[].slice.call(arguments)};return m},runQueue:function(){var a=m,c=n.length,b=c,d;for(;--b>=0;){d=n.shift();a=a[d.type].apply(null,d.args)}return a},noConflict:function(){o.$LAB=K;return m},sandbox:function(){return J()}};return m}o.$LAB=J();(function(a,c,b){if(document.readyState==null&&document[a]){document.readyState=\"loading\";document[a](c,b=function(){document.removeEventListener(c,b,false);document.readyState=\"complete\"},false)}})(\"addEventListener\",\"DOMContentLoaded\")})(this);\\n        </script>\\n\\n<!-- <link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css\"> -->\\n          </head>\\n    <body >\\n\\n                <!-- Google Tag Manager (No Script) -->\\n        <noscript><iframe src=\"//www.googletagmanager.com/ns.html?id=GTM-KCC7SF\"\\n        height=\"0\" width=\"0\" style=\"display:none;visibility:hidden\"></iframe></noscript>\\n        <!-- Google Tag Manager (No Script) end -->\\n        <div class=\"body\">\\n                    \\t<div aria-labelledby=\"header\" class=\"patternlab white--bg gray-ultra-light--bg-small\">  \\n   <nav class=\"row top-nav top-nav--slim\">\\n      <div class=\"columns small-8 medium-4 large-3 full-height\">\\n         <a name=\"menu\" role=\"button\" href=\"javascript:void(0);\" id=\"hamburgerExpand\" aria-expanded=\"false\" aria-label=\"Main menu open\" class=\"burger full-height vert-align-middle display-inline-block cursor-pointer position-relative\" data-bv-click=\"toggleVis():\\'burger-popup-menu\\';toggleAttr(\\'aria-expanded\\',\\'true\\',\\'false\\'):\\'hamburgerExpand\\'\">\\n            <img class=\"vert-center burger__hero-img\" src=\"//beckett.cram.com/1.12/images/icons/burger.png\"/>                     \\n         </a>   \\n         <div class=\"card bv-popup card--bv-popup card--bv-popup--burger card--bv-popup--burger-left\" id=\"burger-popup-menu\">\\n               <ul class=\"card__menu-list \">\\n                  <li class=\"card__menu-list-item text-xs\">\\n                     <a class=\"card__menu-list-link display-block brand-primary--hover\" \\n                        href=\"/\"\\n                        >\\n                     Home\\n                     </a>\\n                  </li>\\n                  <li class=\"card__menu-list-item card__menu-list-header text-xs\">\\n                     <a class=\"charcoal-gray display-block \" style=\"text-decoration: none;\"\\n                        href=\"/flashcards\" >\\n                     Flashcards\\n                     </a>\\n                  </li>\\n                  <li class=\"card__menu-list-item text-xs\">\\n                     <a class=\"card__menu-list-link display-block green--hover\" \\n                        href=\"/flashcards/create\">\\n                     Create Flashcards\\n                     </a>\\n                  </li>\\n                  <li class=\"card__menu-list-item card__menu-list-header text-xs display-block\">\\n                     <a class=\"charcoal-gray display-block\" style=\"text-decoration: none;\" \\n                        href=\"/writing\">\\n                     Essays\\n                     </a>\\n                  </li>\\n                  <li class=\"card__menu-list-item  text-xs\">\\n                     <a class=\"charcoal-gray display-block \" style=\"text-decoration: none;\" href=\"/topics\">\\n                     Essay Topics                        \\n                     </a>\\n                  </li>\\n                  <li class=\"card__menu-list-item  text-xs\">\\n                     <a class=\"charcoal-gray display-block \" style=\"text-decoration: none;\" href=\"/writing-tool/edit\">\\n                     Language and Plagiarism Checks\\n                     </a>\\n                  </li>\\n               </ul>\\n         </div>         \\n         <div class=\"show-for-large display-inline-block full-height\">\\n            <a href=\"/\">\\n               <img name=\"Homepage\" class=\"vert-center\" src=\"//beckett.cram.com/1.12/images/logos/cram/logo-cram.png\" width=\"127\" height=\"30\"/>\\n            </a>\\n                   </div>\\n         <div class=\"hide-for-large-up display-inline-block vert-align-middle full-height\">\\n            <a href=\"/\">\\n               <img name=\"Homepage\" class=\"vert-center\" src=\"//beckett.cram.com/1.12/images/logos/cram/logo-cram-mobile.png\" width=\"84\" height=\"20\"/>\\n            </a>\\n         </div>\\n      </div>\\n      <div class=\"columns position-relative small-2 medium-6 large-5 full-height\">\\n                  <div class=\"search-box search-box--blue header-splat__search-box header-splat__search-box--custom-nav vert-center--medium \" id=\"cram-search-box\">\\n            <form class=\"toggle-trigger\" id=\"\" action=\"/search\" method=\"\">\\n               <a href=\"javascript:void(0)\" role=\"combobox\" class=\"center uppercase weight-500 text-xs cursor-pointer search-box__select cornflowerblue-btn-bg\" data-bv-click=\"toggleVis():\\'search-select-popup\\';\">\\n               <span class=\"search-box__select-text\">\\n               Flashcards\\n               </span>\\n               </a>\\n               <div class=\"card bv-popup card--bv-popup search-box__popup\" id=\"search-select-popup\">\\n                  <ul class=\"card__menu-list \">\\n                     <li class=\"card__menu-list-item cursor-pointer white align-left uppercase text-xs display-block\">\\n                        <a class=\"card__menu-list-link display-block blue blue--hover\" \\n                           data-bv-click=\"setFocus():\\'query\\';toggleVis():\\'search-select-popup\\';\">FlashCards</a>\\n                     </li>\\n                     <li class=\"card__menu-list-item cursor-pointer white align-left uppercase text-xs display-block\">\\n                        <a class=\"card__menu-list-link display-block blue--hover\" \\n                           href=\"/#essays\">Essays</a>\\n                     </li>                     \\n                  </ul>\\n               </div>\\n               <input type=\"text\" class=\"search-box__input search-box search-box__input--with-select search-box__input--splat-header\" name=\"query\" id=\"query\" placeholder=\"Search over 166 million flashcards\">\\n               <button aria-label=\"Search\" class=\"search-box__button search-box__button search-box__button--splat-header cornflowerblue-btn-bg\" type=\"submit\">\\n               <span class=\"search-box__icon search-box__icon--splat-header white\">\\n               <i class=\"icon icon-ui-24-search\"></i>\\n               </span>\\n               </button>\\n            </form>\\n         </div>\\n         <div class=\"header-splat__search-toggle-container header-splat__search-toggle-container--custom-nav\" data-bv-click=\"toggleClass(\\'conditionally-visible\\'):\\'cram-search-box\\';\">\\n            <i class=\"green weight-500 icon icon-ui-24-search header-splat__icon-ui-24-search-toggle\" id=\"header-splat__icon-ui-24-search-toggle\"></i>\\n         </div>\\n               </div>\\n      <div class=\"columns hide-for-small-only hide-for-medium-only large-3 full-height align-right\">\\n         <div class=\"top-nav__item vert-center\">\\n            <a href=\"/flashcards/create\" class=\"cornflowerblue text-xs\">Create Flashcards</a>\\n         </div>\\n      </div>\\n      <div class=\"columns small-2 medium-2 large-1 full-height\">\\n                  \\n         <div id=\"account-signin-link\" class=\"vert-center align-left\">\\n            <a href=\"/user/login\" class=\"cornflowerblue text-xs\">Sign&nbsp;in</a>\\n         </div>\\n                  \\n            \\n      </div>\\n   </nav>\\n</div>\\n\\n\\n\\n\\n\\n\\n<script src=\"/assets/libs/smartbanner.js\"></script>\\n    <script type=\"text/javascript\">\\n\\n    if ( !((/(iPhone)*(OS ([6-9]|1[0-9])_)/i.test(navigator.userAgent))&&(/Safari/.test(navigator.userAgent))) ) {\\n      new SmartBanner({\\n          daysHidden: 0,   // days to hide banner after close button is clicked (defaults to 15)\\n          daysReminder: 0, // days to hide banner after \"VIEW\" button is clicked (defaults to 90)\\n          appStoreLanguage: \\'us\\', // language code for the App Store (defaults to user\\'s browser language)\\n          title: \\'Cram\\',\\n          author: \\'Studymode\\',\\n          button: \\'VIEW\\',\\n          store: {\\n              ios: \\'On the App Store\\',\\n              android: \\'In Google Play\\',\\n              windows: \\'In Windows store\\'\\n          },\\n          price: {\\n              ios: \\'FREE\\',\\n              android: \\'FREE\\',\\n              windows: \\'FREE\\'\\n          }\\n           , theme: \\'ios\\' // put platform type (\\'ios\\', \\'android\\', etc.) here to force single theme on all device\\n           , icon: \\'/images/cram_icon_384.png\\' // full path to icon image if not using website icon image\\n           //, force: \\'android\\' // Uncomment for platform emulation\\n      });\\n    }\\n     if ( ((/(iPhone)*(OS ([6-9]|1[0-9])_)/i.test(navigator.userAgent))&&(navigator.userAgent.match(\\'CriOS\\')) )) {\\n      new SmartBanner({\\n          daysHidden: 0,   // days to hide banner after close button is clicked (defaults to 15)\\n          daysReminder: 0, // days to hide banner after \"VIEW\" button is clicked (defaults to 90)\\n          appStoreLanguage: \\'us\\', // language code for the App Store (defaults to user\\'s browser language)\\n          title: \\'Cram\\',\\n          author: \\'Studymode\\',\\n          button: \\'VIEW\\',\\n          store: {\\n              ios: \\'On the App Store\\',\\n              android: \\'In Google Play\\',\\n              windows: \\'In Windows store\\'\\n          },\\n          price: {\\n              ios: \\'FREE\\',\\n              android: \\'FREE\\',\\n              windows: \\'FREE\\'\\n          }\\n           , theme: \\'ios\\' // put platform type (\\'ios\\', \\'android\\', etc.) here to force single theme on all device\\n           , icon: \\'/images/cram_icon_384.png\\' // full path to icon image if not using website icon image\\n           //, force: \\'android\\' // Uncomment for platform emulation\\n      });\\n    }\\n    </script>\\n<div class=\"modal\" id=\"shareBoxModal\">\\n\\t<form action=\"/share\" id=\"share_set\" class=\"login_form\" method=\"post\">\\n        <div id=\"modal_header\"><h3>Share This Flashcard Set</h3> <a id=\"close_modal\" href=\"javascript:void(0);\"><span>Close</span></a></div>\\n        <div id=\"modal_body\" class=\"test\">\\n\\n                      <div class=\"modal_content sign_in\">\\n                <p>Please sign in to share these flashcards. We\\'ll bring you back here when you are done.</p>\\n                <p>\\n                    <a id=\"signInBtn\" class=\"cornflowerblue-btn small-btn round-btn btn thick-btn\" href=\"javascript:void(0);\">\\n                        <span>Sign in</span>\\n                    </a>\\n                </p>\\n                <p class=\"footer\">Don\\'t have an account? <a href=\"javascript:void(0);\" id=\"signUpModalBtn\">Sign Up &raquo;</a></p>\\n            </div>\\n                  </div>\\n    </form>\\n</div>\\n<div id=\"fb-root\"></div>\\n<div class=\"content-type1 study_content\">\\n  <input type=\"hidden\" id=\"setID\" value=\"\" />\\n  <input type=\"hidden\" id=\"setURLLink\" value=\"www.cram.com/flashcards/\" />\\n  <input type=\"hidden\" id=\"urlLink\" value=\"www.cram.com\" />\\n  <input id=\"userLoggedIn\" type=\"hidden\" value=\"0\" />\\n  <input id=\"s3ImageUri\" type=\"hidden\" value=\"https://images.cram.com\" />\\n      <div class=\"heading\">\\n      <h1>Private Set</h1>\\n    </div>\\n    <div class=\"main-content no-access\">\\n      <div class=\"sorry-msg\">\\n        <div>\\n          <h2>Sorry, this is a private set. You don\\'t have permissions to view it.</h2>\\n                      <p>If this set belongs to you, please sign in.</p>\\n            <p>\\n              <a class=\"btn medium-btn thick-btn cornflowerblue-btn round-btn\" title=\"Login\" href=\"/user/login\">\\n                Sign in              </a>\\n            </p>\\n                  </div>\\n      </div>\\n    </div>\\n  </div>\\n\\n  <div class=\"advertBox\">\\n    <div class=\"longerBannerAd\">\\n          </div>\\n  </div>\\n\\n<script type=\"text/javascript\">\\n  var Cards = null,\\n    Langs = {\"lang_front\":null,\"lang_back\":null};\\n</script>\\n\\n\\n\\n\\n<script type=\"text/javascript\">\\r\\nfunction loadJQ(callback) {\\r\\n  if(!window.jQuery) {\\r\\n    // Create jQuery script element.\\r\\n    var script = document.createElement(\\'script\\');\\r\\n    script.type = \\'text/javascript\\';\\r\\n    script.src = \\'//ajax.googleapis.com/ajax/libs/jquery/3.6.3/jquery.min.js\\';\\r\\n    document.body.appendChild(script);\\r\\n\\r\\n    script.onload = function(){ callback(jQuery); };\\r\\n    // IE 6 & 7 ala jfriend00\\r\\n    script.onreadystatechange = function() {\\r\\n      if (this.readyState == \\'complete\\') callback(jQuery);\\r\\n    }\\r\\n  } else {\\r\\n    callback(jQuery);\\r\\n  }\\r\\n}\\r\\n\\r\\nloadJQ(function($){\\r\\n  console.log($ === jQuery); // true. jquery is loaded.\\r\\n});\\r\\n</script>\\r\\n<footer>\\r\\n    <div class=\"footer\">\\r\\n                <div class=\"row\">\\r\\n            <div style=\"float: left;width:12%\"></div>\\r\\n            <div style=\"float:right;width:88%\"></div>\\r\\n        </div>    \\r\\n        <div class=\"nta\">\\r\\n            <img src=\"/fce/images/nta_logo.png\" width=\"200\" /> <span>Cram has partnered with the National Tutoring Association </span>\\r\\n            <a class=\"btn medium-btn thick-btn cornflowerblue-btn round-btn\" href=\"/nta\">Claim your access </a>\\r\\n        </div>\\r\\n                    <div class=\"menu-boxes\">\\r\\n                <div class=\"signup\"><p>Ready To Get Started?</p>\\r\\n                    <a \\r\\n                        id=\"buttonFooterCreateFlashcards\" \\r\\n                        class=\"btn medium-btn thick-btn cornflowerblue-btn round-btn\" \\r\\n                        href=\"/flashcards/create\"\\r\\n                        title=\"Create Flashcards\"\\r\\n                    >\\r\\n                        <span>Create Flashcards</span>\\r\\n                    </a>\\r\\n                </div>\\r\\n                <div>\\r\\n                    <p>Discover</p>\\r\\n                    <ul>\\r\\n                        <li><a id=\"linkFooterCreateFlashcards\" title=\"Create Flashcards\" href=\"/flashcards/create\">Create Flashcards</a></li>\\r\\n                        <li><a id=\"linkFooterMobileApps\" title=\"Mobile Apps\" href=\"/flashcards/apps\">Mobile Apps</a></li>\\r\\n                    </ul>\\r\\n                </div>\\r\\n                <div>\\r\\n                    <p>Company</p>\\r\\n                    <ul>\\r\\n                        <li><a id=\"linkFooterAbout\" title=\"About Cram\" href=\"/about\">About</a></li>\\r\\n                        <li><a id=\"linkFooterFAQ\" title=\"FAQ\" href=\"/docs/help\">FAQ</a></li>\\r\\n                        <li><a id=\"linkFooterSupport\" title=\"Support\" href=\"/support\">Support</a></li>\\r\\n                        <li><a id=\"linkLegal\" title=\"Legal\" href=\"/legal\">Legal</a></li>\\r\\n                        <li><a id=\"linkFooterAccessibility\" title=\"Accessibility\" rel=\"nofollow\" href=\"https://www.bned.com/accessibility/\">Accessibility</a></li>\\r\\n                    </ul>\\r\\n                </div>\\r\\n                <div class=\"social-panel\">\\r\\n                    <p>Follow</p>\\r\\n                    <ul>\\r\\n                        <li><a id=\"linkFooterFacebook\" class=\"facebook-like\" target=\"_blank\" title=\"Facebook\" href=\"https://www.facebook.com/CramMode\">Facebook</a></li>\\r\\n                        <li><a id=\"linkFooterTwitter\" class=\"twitter\" target=\"_blank\" title=\"Twitter\" href=\"https://twitter.com/flashcards\">Twitter</a></li>\\r\\n                    </ul>\\r\\n                </div>\\r\\n            </div>\\r\\n        \\r\\n        <div class=\"copyright\">\\r\\n            <ul>\\r\\n                <li>\\xc2\\xa92023 Cram.com</li>\\r\\n                <li><a href=\"/about-us/privacy\">Privacy Policy</a></li>\\r\\n                                    <li><a href=\"/about-us/privacy#advertising\">About Ads</a></li>\\r\\n                                <li><a id=\"linkFooterSiteMap\" title=\"Site Map\" href=\"/sitemap\">Site Map</a></li>\\r\\n                                    <li><a id=\"linkFooterAdvertise\" title=\"Advertise\" href=\"/advertise-with-us\">Advertise</a></li>\\r\\n                                <li tabindex=\"0\" class=\"ot-sdk-show-settings ot-li\"><a id=\"ot-sdk-btn\">Cookie Settings</a></li>\\r\\n                <script src=\"https://cdn.cookielaw.org/scripttemplates/otSDKStub.js\"  type=\"text/javascript\" charset=\"UTF-8\" data-domain-script=\\'a595ba2e-3318-43cc-9a20-698cffbb2cc8\\' ></script>\\r\\n            </ul>\\r\\n        </div>\\r\\n    </div>\\r\\n</footer>\\r\\n\\r\\n        </div>\\n                <!-- Quantcast Tag -->\\n        <script type=\"text/javascript\">\\n        var _qevents = _qevents || [];\\n        (function() {\\n        var elem = document.createElement(\\'script\\');\\n        elem.src =\\n        (document.location.protocol ==\\n        \"https:\" ? \"https://secure\" : \"http://edge\")\\n        + \".quantserve.com/quant.js\";\\n        elem.async = true;\\n        elem.type = \"text/javascript\";\\n        var scpt = document.getElementsByTagName(\\'script\\')[0];\\n        scpt.parentNode.insertBefore(elem, scpt);\\n        })();\\n\\n        _qevents.push({qacct:\"p-640Vrv-0V_6l-\"});\\n        </script>\\n        <noscript>\\n        <img src=\"//pixel.quantserve.com/pixel/p-640Vrv-0V_6l-.gif\"\\n            border=\"0\" height=\"1\" width=\"1\" alt=\"Quantcast\"/>\\n        </noscript>\\n        <!-- End Quantcast tag -->\\n<script type=\"text/javascript\">var _gaq = _gaq || [];</script><div id=\"js-tpl-var-container\" style=\"display:none;\">{\"cdnAssetsUrl\":\"\",\"facebook\":{\"clientId\":\"363499237066029\",\"version\":\"v12.0\",\"language\":\"en_US\"}}</div>\\n\\n<script type=\"text/javascript\" src=\"/assets/whiteboard/scripts/LAB.min.js\"></script><script type=\"text/javascript\">\\n    window.SM2_DEFER = true;\\n    function downloadJSAtOnload() {\\n            $LAB.script(\\'//ajax.googleapis.com/ajax/libs/jquery/3.6.3/jquery.min.js\\').wait()\\n                .script(\\'//ajax.googleapis.com/ajax/libs/jqueryui/1.13.2/jquery-ui.min.js\\').wait()\\n                    .script(\"/fce/js/_sets/2208406965.js\")\\n                    }\\n    // Check for browser support of event handling capability\\n    if (window.addEventListener)\\n       window.addEventListener(\"load\", downloadJSAtOnload, false);\\n    else if (window.attachEvent)\\n       window.attachEvent(\"onload\", downloadJSAtOnload);\\n    else window.onload = downloadJSAtOnload;\\n</script>        <!-- global JS -->\\n    <script type=\"text/javascript\" src=\"//beckett.cram.com/1.17/js/scripts.1.17.109.min.js\"></script>\\n\\n    </body>\\n</html>\\n'\n",
      "[<p>Please sign in to share these flashcards. We'll bring you back here when you are done.</p>, <p>\n",
      "<a class=\"cornflowerblue-btn small-btn round-btn btn thick-btn\" href=\"javascript:void(0);\" id=\"signInBtn\">\n",
      "<span>Sign in</span>\n",
      "</a>\n",
      "</p>, <p class=\"footer\">Don't have an account? <a href=\"javascript:void(0);\" id=\"signUpModalBtn\">Sign Up ¬ª</a></p>, <p>If this set belongs to you, please sign in.</p>, <p>\n",
      "<a class=\"btn medium-btn thick-btn cornflowerblue-btn round-btn\" href=\"/user/login\" title=\"Login\">\n",
      "                Sign in              </a>\n",
      "</p>, <p>Ready To Get Started?</p>, <p>Discover</p>, <p>Company</p>, <p>Follow</p>]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.gcertificationcourse.com/linkedin-python-skill-quiz-answers/'\n",
    "url = \"https://www.cram.com/flashcards/git-12843452\"\n",
    "\n",
    "# Making a get request\n",
    "response_code = requests.get(url)\n",
    "  \n",
    "print(response_code.content)\n",
    "\n",
    "soup = BeautifulSoup(response_code.content, 'html.parser')\n",
    "page = soup.find_all('p')\n",
    "print(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afa492c",
   "metadata": {},
   "source": [
    "# Enregister des fichier plus vite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3d5b0168",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "with open(\"Q_Python/questions.txt\", 'r') as reader:\n",
    "    out.append(reader.read())\n",
    "out = out[0].split('\\n\\n\\n')\n",
    "out = [i for i in out if any(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f27e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "with open(\"questions.txt\", 'r') as reader:\n",
    "    out.append(reader.read())\n",
    "out = out[0].split('\\n\\n\\n')\n",
    "out = [i for i in out if any(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40e3f2c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your manager has asked you to create a binary classification model to predict whether a person has a disease. You need to detect possible classification errors. Which error type should you choose for the following description? ‚ÄúA person has a disease. The model classifies the case as having a disease‚Äù.\n",
      "False positives\n",
      "True negatives\n",
      "True positives\n",
      "False negatives\n",
      "True positives\n",
      "Your manager has asked you to create a binary classification model to predict whether a person has a disease. You need to detect possible classification errors. Which error type should you choose for the following description? ‚ÄúA person has a disease. The model classifies the case as having no disease‚Äù.\n",
      "True negatives\n",
      "False negatives\n",
      "False positives\n",
      "True positives\n",
      "False negatives\n",
      "You are a senior data scientist in the company and you are tasked with evaluating a completed binary classification machine learning model. You need to use the precision as the evaluation metric. Which visualization should you use?\n",
      "Gradient descent\n",
      "Scatter plot\n",
      "Violin plot\n",
      "Receiver Operating Characteristic (ROC) curve\n",
      "Receiver Operating Characteristic (ROC) curve\n",
      "4. You are a data scientist of a company and you are tasked with building a deep convolutional neural network (CNN) for image classification. The CNN model you built shows signs of overfitting. You need to reduce overfitting and converge the model to an optimal fit.\n",
      "Which two actions should you perform?\n",
      "(accroch√©) Add L1/L2 regularization\n",
      "Reduce the amount of training data\n",
      "Add an additional dense layer with 64 input units\n",
      "(accroch√© - option3) Add an additional dense layer with 512 input units\n",
      "(accroch√©) Use training data augmentation\n",
      "Correct. Adding more training records should decrease the overfitting.\n",
      "5. Your manager has provided you a dataset created for multiclass classification tasks that contains a normalized numerical feature set with 10,000 data points and 150 features. You use 75 percent of the data points for training and 25 percent for testing.\n",
      "Name\n",
      "Description\n",
      "X_train\n",
      "Training feature set\n",
      "Y_train\n",
      "Training class labels\n",
      "x_train\n",
      "Testing feature set\n",
      "y_train\n",
      "Testing class labels\n",
      "You need to apply the Principal Component Analysis (PCA) method to reduce the dimensionality of the feature set to 10 features in both training and testing sets.\n",
      "You are using the scikit-learn machine learning library in Python.\n",
      "You use X to denote the feature set and Y to denote class labels.\n",
      "You create the following Python data frames:\n",
      "From sklearn.decomposition import PCA\n",
      "pca ‚Äì [...]\n",
      "x_train=[...] .fit_transform(X_train)\n",
      "x_test = pca.[...]\n",
      "How should you complete the code segment?\n",
      "1 / 1 point\n",
      "Box1: PCA(n_components=150);\n",
      "Box2: pca;\n",
      "Box3: x_test\n",
      "(accroch√©) Box1: PCA(n_components=10);\n",
      "Box2: pca;\n",
      "Box3: transform(x_test)\n",
      "Box1: PCA(n_components=10);\n",
      "Box2: model;\n",
      "Box3: transform(x_test)\n",
      "Box1: PCA(n_components=10000);\n",
      "Box2: pca;\n",
      "Box3: X_train\n",
      "Correct\n",
      "Box 1: PCA(n_components = 10) Need to reduce the dimensionality of the feature set to 10 features in both training and testing sets. Box 2: pca fit_transform(X )fits the model with X and apply the dimensionality reduction on X. Box 3: transform(x_test) transform(X) applies dimensionality reduction to X.\n",
      "6. You are creating a model to predict the price of a student‚Äôs artwork depending on the following variables: the student‚Äôs length of education, degree type, and art form.\n",
      "You start by creating a linear regression model. You need to evaluate the linear regression model.\n",
      "Solution: Use the following metrics: Relative Squared Error, Coefficient of Determination, Accuracy, Precision, Recall, F1 score, and AUC: Does the solution meet the goal?\n",
      "Yes\n",
      "(accroch√©) No\n",
      "7. What happens when a list is multiplied by 5?\n",
      "(accroch√©) The new list created has the length 5 times the original length with the sequence repeated 5 times.\n",
      "The new list remains the same size, but the elements are multiplied by 5.\n",
      "The new list created has the length 5 times the original length with the sequence repeated 5 times and also all the elements are also multiplied by 5.\n",
      "You are creating a model and you want to evaluate it. One metric yields an absolute metric in the same unit as the label. Which metric is described?\n",
      "Coefficient of Determination (known as R-squared or R2)\n",
      "Root Mean Square Error (RMSE)\n",
      "Mean Square Error (MSE)\n",
      "Nothing\n",
      "Root Mean Square Error (RMSE)\n",
      "It is well known that Python provides extensive functionality with powerful and statistical numerical libraries. What is Scikit-learn useful for?\n",
      "Providing attractive data visualizations\n",
      "Offering simple and effective predictive data analysis\n",
      "Analyzing and manipulating data\n",
      "Supplying machine learning and deep learning capabilities\n",
      "Offering simple and effective predictive data analysis\n",
      "What data values are influencing prediction models?\n",
      "Identifiers\n",
      "Features\n",
      "Dependent variables\n",
      "Labels\n",
      "Features\n",
      "2. Let‚Äôs suppose you want to create an AI system that can predict how many minutes late a flight will arrive based on the amount of snowfall at an airport. Which machine learning type should you use?\n",
      "Clustering\n",
      "(accroch√©) Regression\n",
      "Classification\n",
      "3. Imagine you work for a government institution that wants to predict the sea level in meters for the following 10 years. Which type of machine learning should you use?\n",
      "(accroch√©) Regression\n",
      "Correct. Regression is a supervised machine learning technique used to predict numeric values.\n",
      "Classification\n",
      "Clustering\n",
      "4. Let‚Äôs suppose you are working on an AI application that should predict the weather. From the dataset you have, you want to pick temperature and pressure to train the model. Which machine learning task enables you to do that?\n",
      "Feature engineering\n",
      "Model training\n",
      "(accroch√©) Feature selection\n",
      "Correct. Feature selection is the process of selecting a subset of relevant, useful features to use in building an analytical model.\n",
      "5. True or False?\n",
      "Azure Machine Learning designer supports custom JavaScript functions.\n",
      "True\n",
      "(accroch√©) False\n",
      "Correct\n",
      "Azure Machine Learning designer does not support custom JavaScript functions.\n",
      "6. Predicting whether someone uses a bicycle to travel to work based on the distance from home to work is a use case for?\n",
      "Regression\n",
      "(accroch√©) Classification\n",
      "Clustering\n",
      "Correct\n",
      "Classification is a supervised machine learning technique used to predict categories or classes.\n",
      "7. Which of the following metrics is used to evaluate a classification model?\n",
      "Coefficient of determination (R2)\n",
      "(accroch√©) True positive rate\n",
      "Correct. The best metric to evaluate a classification model is by looking at the true positive rate.\n",
      "Root mean squared error (RMSE)\n",
      "Mean absolute error (MAE)\n",
      "8. True or False?\n",
      "Automated machine learning can automatically infer the training data from the use case provided.\n",
      "True\n",
      "(accroch√©) False\n",
      "Correct. Automated machine learning cannot automatically infer the training data from the use case provided.\n",
      "9. True or False?\n",
      "Azure Machine Learning designer provides a drag-and-drop visual canvas to build, test, and deploy machine learning models.\n",
      "(accroch√©) True\n",
      "Correct. Azure Machine Learning provides a drag-and-drop visual canvas to build, test, and deploy machine learning models.\n",
      "False\n",
      "10. You want to create a CRM application that uses AI to segment customers into different groups to support a marketing department. Which machine learning type should you use?\n",
      "(accroch√©) Clustering\n",
      "Classification\n",
      "Regression\n",
      "Correct. Clustering is an unsupervised machine learning technique used to group similar entities based on their features.\n",
      "1. You create a new Azure subscription. No resources are provisioned in the subscription. You need to create an Azure Machine Learning workspace.\n",
      "What are three possible ways to achieve this goal? Each correct answer presents a complete solution.\n",
      "(accroch√©) Run Python code that uses the Azure ML SDK library and calls the Workspace.create method with name, subscription_id, resource_group, and location parameters.\n",
      "Correct. This is one way to achieve the goal.\n",
      "(accroch√©) Use the Azure Command Line Interface (CLI) with the Azure Machine Learning extension to call the az group create function with ‚Äìname and ‚Äìlocation parameters, and then the az ml workspace create function, specifying Cw and Cg parameters for the workspace name and resource group.\n",
      "Correct. This is one way to achieve the goal.\n",
      "Run Python code that uses the Azure ML SDK library and calls the Workspace.get method with name, subscription_id, and resource_group parameters.\n",
      "(Incorrect) Navigate to Azure Machine Learning studio and create a workspace.\n",
      "(accroch√© - essaie √ßa) Use an Azure Resource Management template that includes a Microsoft.MachineLearningServices/ workspaces resource and its dependencies.\n",
      "1. You create an Azure Machine Learning workspace. You are preparing a local Python environment on a laptop computer.\n",
      "You want to use the laptop to connect to the workspace and run experiments.\n",
      "You create the following config.json file:\n",
      " { \"workspace_name\" : \"ml-workspace\" }\n",
      "You must use the Azure Machine Learning SDK to interact with data and experiments in the workspace. You need to configure the config.json file to connect to the workspace from the Python environment. Which two additional parameters must you add to the config.json file in order to connect to the workspace? Each correct answer presents part of the solution.\n",
      "Key\n",
      "(accroch√©) Resource_group\n",
      "Correct. This parameter must be specified.\n",
      "Region\n",
      "Login\n",
      "(accroch√©) Subscription_id\n",
      "Correct. This parameter must be specified.\n",
      "2. An organization uses Azure Machine Learning service and wants to expand their use of machine learning. You have the following compute environments. The organization does not want to create another compute environment.\n",
      "Environment name, Compute Type\n",
      "nb_server, Compute instance\n",
      "aks_cluster, Azure Kubernetes Service\n",
      "mlc_cluster, Machine Learning compute\n",
      "You need to determine which compute environment to use for the following scenarios:\n",
      "1. Run an Azure Machine Learning Designer training pipeline.\n",
      "2. Deploying a web service from the Azure Machine Learning Designer.\n",
      "Which compute types should you use?\n",
      "(accroch√©) 1 mlc_cluster, 2 aks_cluster\n",
      "1 nb_server, 2 aks_cluster\n",
      "1 mlc_cluster, 2 nb_server\n",
      "1 nb_server, 2 mlc_cluster\n",
      "2. You are developing a data science workspace that uses an Azure Machine Learning service. You need to select a compute target to deploy the workspace. What should you use?\n",
      "Azure Data Lake Analytics\n",
      "(accroch√©) Azure Container Instances\n",
      "Correct. Azure Container Instances can be used a compute target for testing or developement. Use for low-scale CPU-based workloads that require less than 48 GB of RAM.\n",
      "Azure Databricks\n",
      "Apache Spark for HDInsight\n",
      "3. The finance team asked you to train a model using data in an Azure Storage blob container named finance-data.\n",
      "You need to register the container as a datastore in an Azure Machine Learning workspace and ensure that an error will be raised if the container does not exist.\n",
      "How should you complete the code?\n",
      "Datastore = Datastore.<add answer here> (workspace = ws,\n",
      "datastore_name = ‚Äòfinance_datastore‚Äô,\n",
      "container_name = ‚Äòfinance-data‚Äô,\n",
      "account_name = ‚Äòfintrainingdatastorage‚Äô,\n",
      "account_key = ‚ÄòFdhIWHDaiwh2‚Ä¶‚Äô\n",
      "<add answer here>\n",
      "1 / 1 point\n",
      "register_azure_data_lake, create_if_not_exists = False\n",
      "register_azure_blob_container, overwrite = True\n",
      "(accroch√©) register_azure_blob_container, create_if_not_exists = False\n",
      "register_azure_data_lake, overwrite = False\n",
      "Correct\n",
      "register_azure_blob_container to Register an Azure Blob Container to the datastore and create_if_not_exists = False to create the file share if it does not exist, defaults to False.\n",
      "3. A coworker registers a datastore in a Machine Learning services workspace by using the following code:\n",
      "Datastore.register_azure_blob_container(workspace=ws,\n",
      "datastore_name=‚Äòdemo_datastore‚Äô,\n",
      "container_name=‚Äòdemo_datacontainer‚Äô,\n",
      "account_name=‚Äôdemo_account‚Äô,\n",
      "account_key=‚Äô0A0A0A-0A00A0A-0A0A0A0A0A0‚Äô\n",
      "create_if_not_exists=True)\n",
      "You need to write code to access the datastore from a notebook. How should you complete the code segment?\n",
      "import azureml.core\n",
      "from azureml.core import Workspace, Datastore\n",
      "ws = Workspace.from_config()\n",
      "datastore = <add answer here> .get( <add answer here>, ‚Äò<add answer here>‚Äô)\n",
      "Run, experiment, demo_datastore\n",
      "(accroch√©) DataStore, ws, demo_datastore\n",
      "Experiment, run, demo_account\n",
      "Run, ws, demo_datastore\n",
      "Correct. To get a specific datastore registered in the current workspace, use the get() static method on the Datastore class, like this:\n",
      "datastore = Datastore.get(ws, datastore_name='your datastore name')\n",
      "A set of CSV files contains sales records. All the CSV files have the same data schema.\n",
      "Each CSV file contains the sales record for a particular month and has the filename sales.csv. Each file is stored in a folder that indicates the month and year when the data was recorded. The folders are in an Azure blob container for which a datastore has been defined in an Azure Machine Learning workspace. The folders are organized in a parent folder named sales to create the following hierarchical structure:\n",
      "/sales\n",
      "  /01-2019\n",
      "    /sales.csv\n",
      "  /02-2019\n",
      "    /sales.csv\n",
      "  /03-2019\n",
      "    /sales.csv\n",
      "‚Ä¶\n",
      "At the end of each month, a new folder with that month's sales file is added to the sales folder. You plan to use the sales data to train a machine learning model based on the following requirements:\n",
      "- You must define a dataset that loads all of the sales data to date into a structure that can be easily converted to a dataframe.\n",
      "- You must be able to create experiments that use only data that was created before a specific previous month, ignoring any data that was added after that month.\n",
      "- You must register the minimum number of datasets possible.\n",
      "You need to register the sales data as a dataset in Azure Machine Learning service workspace. What should you do?\n",
      "0 / 1 point\n",
      "(Incorrect) Create a new tabular dataset that references the datastore and explicitly specifies each 'sales/mm-yyyy/sales.csv' file every month. Register the dataset with the name sales_dataset_MM-YYYY each month with appropriate MM and YYYY values for the month and year. Use the appropriate month-specific dataset for experiments.\n",
      "Create a tabular dataset that references the datastore and explicitly specifies each 'sales/mm-yyyy/sales.csv' file every month. Register the dataset with the name sales_dataset each month, replacing the existing dataset and specifying a tag named month indicating the month and year it was registered. Use this dataset for all experiments.\n",
      "Create a tabular dataset that references the datastore and specifies the path 'sales/*/sales.csv', register the dataset with the name sales_dataset and a tag named month indicating the month and year it was registered, and use this dataset for all experiments.\n",
      "(accroch√©) Create a tabular dataset that references the datastore and explicitly specifies each 'sales/mm-yyyy/sales.csv' file. Register the dataset with the name sales_dataset each month as a new version and with a tag named month indicating the month and year it was registered. Use this dataset for all experiments, identifying the version to be used based on the month tag as necessary.\n",
      "4. You are a lead data scientist for a project that tracks the health and migration of birds. You create a multi-class image classification deep learning model that uses a set of labeled bird photographs collected by experts.\n",
      "You have 100,000 photographs of birds. All photographs use the JPG format and are stored in an Azure blob container in an Azure subscription. You need to access the bird photograph files in the Azure blob container from the Azure Machine Learning service workspace that will be used for deep learning model training.\n",
      "You must minimize data movement. What should you do?\n",
      "Create an Azure Cosmos DB database and attach the Azure Blob containing bird photographs storage to the database.\n",
      "Create and register a dataset by using TabularDataset class that references the Azure blob storage containing bird photographs.\n",
      "Copy the bird photographs to the blob datastore that was created with your Azure Machine Learning service workspace.\n",
      "Create an Azure Data Lake store and move the bird photographs to the store.\n",
      "(accroch√©) Register the Azure blob storage containing the bird photographs as a datastore in Azure Machine Learning service.\n",
      "5. You train a machine learning model. You must deploy the model as a real-time inference service for testing. The service requires low CPU utilization and less than 48 MB of RAM. The compute target for the deployed service must initialize automatically while minimizing cost and administrative overhead. Which compute target should you use?\n",
      "(accroch√©) Azure Container Instance (ACI)\n",
      "attached Azure Databricks cluster\n",
      "Azure Machine Learning compute cluster\n",
      "Azure Kubernetes Service (AKS) inference cluster\n",
      "5. You create a deep learning model for image recognition on Azure Machine Learning service using GPU-based training. You must deploy the model to a context that allows for real-time GPU-based inferencing. You need to configure compute resources for model inferencing. Which compute type should you use?\n",
      "Machine Learning Compute\n",
      "Azure Container Instance\n",
      "Field Programmable Gate Array\n",
      "(accroch√©) Azure Kubernetes Service\n",
      "6. An organization creates and deploys a multi-class image classification deep learning model that uses a set of labeled photographs.\n",
      "The software engineering team reports there is a heavy inferencing load for the prediction web services during the summer. The production web service for the model fails to meet demand despite having a fully-utilized compute cluster where the web service is deployed.\n",
      "You need to improve performance of the image classification web service with minimal downtime and minimal administrative effort. What should you advise the IT Operations team to do?\n",
      "Create a new compute cluster by using larger VM sizes for the nodes, redeploy the web service to that cluster, and update the DNS registration for the service endpoint to point to the new cluster.\n",
      "Increase the minimum node count of the compute cluster where the web service is deployed.\n",
      "Increase the VM size of nodes in the compute cluster where the web service is deployed.\n",
      "(accroch√©) Increase the node count of the compute cluster where the web service is deployed.\n",
      "Correct. The Azure Machine Learning SDK does not provide support scaling an AKS cluster. To scale the nodes in the cluster, use the UI for your AKS cluster in the Azure Machine Learning studio. You can only change the node count (le nombre des VMs), not the VM size of the cluster.\n",
      "6. You use Azure Machine Learning designer to create a real-time service endpoint. You have a single Azure Machine Learning service compute resource. You train the model and prepare the real-time pipeline for deployment. You need to publish the inference pipeline as a web service. Which compute type should you use?\n",
      "(Incorrect) HDInsight\n",
      "Azure Databricks\n",
      "(Incorrect) A new Machine Learning Compute resource\n",
      "(Incorrect) The existing Machine Learning Compute resource\n",
      "(accroch√©) Azure Kubernetes Services\n",
      "7. You use the Azure Machine Learning Python SDK to define a pipeline that consists of multiple steps. When you run the pipeline, you observe that some steps do not run. The cached output from a previous run is used instead. You need to ensure that every step in the pipeline is run, even if the parameters and contents of the source directory have not changed since the previous run. What are two possible ways to achieve this goal? Each correct answer presents a complete solution. Set the outputs property of each step in the pipeline to True.\n",
      "Set the allow_reuse property of each step in the pipeline to False.\n",
      "Restart the compute cluster where the pipeline experiment is configured to run.\n",
      "Set the regenerate_outputs property of the pipeline to True.\n",
      "Use a PipelineData object that references a datastore other than the default datastore.\n",
      "Set the regenerate_outputs property of the pipeline to True. Set the allow_reuse property of each step in the pipeline to False.\n",
      "7. You deploy a model as an Azure Machine Learning real-time web service using the following code.\n",
      "# ws, model, inference_config, and deployment_config defined previously\n",
      "service = Model.deploy(ws, ‚Äòclassification-service‚Äô, [model], inference_config, deployment_config)\n",
      "service.wait_for_deployment(True)\n",
      "The deployment fails.\n",
      "You need to troubleshoot the deployment failure by determining the actions that were performed during deployment and identifying the specific action that failed.\n",
      "Which code segment should you run?\n",
      "(accroch√©) service.get_logs()\n",
      "Correct. You can print out detailed Docker engine log messages from the service object. You can view the log for ACI, AKS, and Local deployments.\n",
      "service.serialize()\n",
      "service.update_deployment_state()\n",
      "service.state\n",
      "8. You register a model that you plan to use in a batch inference pipeline.\n",
      "The batch inference pipeline must use a ParallelRunStep step to process files in a file dataset. The script has the ParallelRunStep step and the runs must process six input files each time the inferencing function is called.\n",
      "You need to configure the pipeline. Which configuration setting should you specify in the ParallelRunConfig object for the ParallelRunStep step?\n",
      "error_threshold= \"6\"\n",
      "node_count= \"6\"\n",
      "process_count_per_node= \"6\"\n",
      "(accroch√©) mini_batch_size= \"6\"\n",
      "8. You train and register a model in your Azure Machine Learning workspace.\n",
      "You must publish a pipeline that enables client applications to use the model for batch inferencing.\n",
      "You must use a pipeline with a single ParallelRunStep step that runs a Python inferencing script to get predictions from the input data.\n",
      "You need to create the inferencing script for the ParallelRunStep pipeline step.\n",
      "Which two functions should you include? Each correct answer presents part of the solution.\n",
      "main()\n",
      "score(mini_batch)\n",
      "(accroch√©) run(mini_batch)\n",
      "(accroch√©) init()\n",
      "batch()\n",
      "9. Yes or No?\n",
      "You must be able to explain the model's predictions by calculating the importance of each feature, both as an overall global relative importance value and as a measure of local importance for a specific set of predictions.\n",
      "You need to create an explainer that you can use to retrieve the required global and local feature importance values.\n",
      "Solution: Create a PFIExplainer. Does the solution meet the goal?\n",
      "Yes\n",
      "(accroch√©) No\n",
      "Correct. The PFIExplainer doesn't support local feature importance explanations.\n",
      "10. You create an Azure Machine Learning compute resource to train models. The compute resource is configured as follows: - Minimum nodes: 2 - Maximum nodes: 4. You must decrease the minimum number of nodes and increase the maximum number of nodes to the following values: - Minimum nodes: 0 - Maximum nodes: 8\n",
      "You need to reconfigure the compute resource. What are three possible ways to achieve this goal? Each correct answer presents a complete solution.\n",
      "Use the Azure portal.\n",
      "(quelque fois correct, quelque fois incorrect) Run the refresh_state() method of the BatchCompute class in the Python SDK.\n",
      "(accroch√©) Run the update method of the AmlCompute class in the Python SDK.\n",
      "Correct. The update(min_nodes=None, max_nodes=None, idle_seconds_before_scaledown=None) of the AmlCompute class updates the ScaleSettings for this AmlCompute target.\n",
      "Use the Azure Machine Learning designer.\n",
      "(accroch√©) Use the Azure Machine Learning studio.\n",
      "Correct. You can manage assets and resources in the Azure Machine Learning studio.\n",
      "9. Yes or No?\n",
      "You train a classification model by using a logistic regression algorithm. You must be able to explain the model's predictions by calculating the importance of each feature, both as an overall global relative importance value and as a measure of local importance for a specific set of predictions.\n",
      "You need to create an explainer that you can use to retrieve the required global and local feature importance values.\n",
      "Solution: Create a TabularExplainer. Does the solution meet the goal?\n",
      "1 / 1 point\n",
      "(accroch√©) Yes\n",
      "Correct. The TabularExplainer supports both global and local feature importance explanations.\n",
      "No\n",
      "10. You deploy a real-time inference service for a trained model. The deployed model supports a business-critical application, and it is important to be able to monitor the data submitted to the web service and the predictions the data generates. You need to implement a monitoring solution for the deployed model using minimal administrative effort. What should you do?\n",
      "Enable Azure Application Insights for the service endpoint and view logged data in the Azure portal.\n",
      "Create an ML Flow tracking URI that references the endpoint, and view the data logged by ML Flow.\n",
      "View the log files generated by the experiment used to train the model.\n",
      "View the explanations for the registered model in Azure ML studio.\n",
      "Enable Azure Application Insights for the service endpoint and view logged data in the Azure portal.\n",
      "1. You have an AirBnB housing dataframe which you preprocessed and filtered down to only the relevant columns.\n",
      "The columns are: id, host_name, bedrooms, neighbourhood_cleansed, price.\n",
      "You‚Äôve written the function below name firstInitialFunction that returns the first initial from the host_name column:\n",
      "def firstInitialFunction(name):\n",
      "    return name[0]\n",
      "firstInitialFunction(\"George\")\n",
      "Because Python UDFs are much slower than Scala UDFs, you now want to create a Vectorized UDF in Python to speed up the computation.\n",
      "How would you code that?\n",
      "from pyspark.sql.functions import pandas_udf\n",
      "# We have a string input/output\n",
      "@pandas_udf(\"string\")\n",
      "create vectorizedUDF(name):\n",
      "return name.str[0]\n",
      "from pyspark.sql.functions import pandas_udf\n",
      "@pandas_udf(\"string\")\n",
      "def vectorizedUDF(host_name):\n",
      "get name.str[0]\n",
      "from pyspark.sql.functions import pandas_udf\n",
      "@pandas_udf(\"int\")\n",
      "def vectorizedUDF(name):\n",
      "return name.str[0]\n",
      "(accroch√©) from pyspark.sql.functions import pandas_udf\n",
      "@pandas_udf(\"string\")\n",
      "def vectorizedUDF(name):\n",
      "return name.str[0]\n",
      "# Correct. This is the correct code for the task. We used string as an argument because we have a string input/output.\n",
      "You have a Boston Housing dataset where you find a median value for a number variables such as the number of rooms, per capita crime and economic status of residents. You want to use Linear Regression to predict the median home value based on the average number of rooms. You‚Äôve imported the dataset and created a column named features that has a single input variable named rm by using VectorAssembler. You now want to fit the Liner Regression model. How should you code that?\n",
      "(accroch√©) from pyspark.ml.regression import LinearRegression; lr = LinearRegression(featuresCol=\"features\", labelCol=\"medv\"); lrModel = lr.fit(bostonFeaturizedDF)\n",
      "from pyspark import LinearRegression; lr = LinearRegression(featuresCol=\"features\", labelCol=\"medv\")\n",
      "lrModel = lr.fit(bostonFeaturizedDF)\n",
      "from pyspark.ml.regression import LinearRegression\n",
      "lr = LinearRegression(featuresCol=\"rm\", labelCol=\"medv\")\n",
      "lrModel = lr_fit(bostonFeaturizedDF)\n",
      "from pyspark.ml import LinearRegression\n",
      "lr = LinearRegression(featuresCol=\"rm \", labelCol=\"medv\")\n",
      "lrModel = lr_fit(bostonFeaturizedDF)\n",
      "3. You are using MLflow to track the runs of a Linear Regression model of an AirBnB dataset.\n",
      "You want to use all the features in the dataset.\n",
      "You‚Äôve created the pipeline, logged the pipeline, and logged the parameters.\n",
      "Now you need to create predictions and metrics.\n",
      "How should you code that?\n",
      "predDF = pipelineModel.evaluate(testDF)\n",
      "regressionEvaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\")\n",
      "rmse = regressionEvaluator.setMetricName(\"rmse\").evaluate(predDF)\n",
      "r2 = regressionEvaluator.setMetricName(\"r2\").evaluate(predDF)\n",
      "(accroch√©) predDF = pipelineModel.transform(testDF)\n",
      "regressionEvaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\")\n",
      "rmse = regressionEvaluator.setMetricName(\"rmse\").evaluate(predDF)\n",
      "r2 = regressionEvaluator.setMetricName(\"r2\").evaluate(predDF)\n",
      "predDF = pipelineModel.transform(testDF)\n",
      "regression = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\")\n",
      "rmse = regressionEvaluator.setMetricName(\"rmse\").evaluate(predDF)\n",
      "r2 = regressionEvaluator.setMetricName(\"r2\").evaluate(predDF)\n",
      "predDF = pipelineModel.estimate(testDF)\n",
      "regressionEvaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\")\n",
      "rmse = regressionEvaluator.setMetricName(\"rmse\").evaluate(predDF)\n",
      "r2 = regressionEvaluator.setMetricName(\"r2\").evaluate(predDF)\n",
      "4. You are running Python code interactively in a Conda environment. The environment includes all required Azure Machine Learning SDK and MLflow packages.\n",
      "You must use MLflow to log metrics in an Azure Machine Learning experiment named mlflow-experiment.\n",
      "To answer, replace the bolded comments in the code with the appropriate code options in the answer area.\n",
      "How should you complete the code?\n",
      "import mlflow\n",
      "from azureml.core import Workspace\n",
      "ws = Workspace.from_config()\n",
      "#1 Set the MLflow logging target\n",
      "#2 Configure the experiment\n",
      "with #3 Begin the experiment run\n",
      "               #4 Log my_metric with value 1.00 (‚Äòmy_metric‚Äô, 1.00)\n",
      "print(‚ÄúFinished!‚Äù)\n",
      "#1 mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri()), #2 mlflow.get_run('mlflow-experiment), #3 mlflow.start_run(), #4 run.log()\n",
      "(accroch√©) #1 mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri()), #2 mlflow.set_experiment('mlflow-experiment), #3 mlflow.start_run(), #4 mlflow.log_metric\n",
      "Correct. #1 mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri()) In the following code, the get_mlflow_tracking_uri() method assigns a unique tracking URI address to the workspace, ws, and set_tracking_uri() points the MLflow tracking URI to that address.\n",
      "#2 mlflow.set_experiment(experiment_name) Set the MLflow experiment name with set_experiment() and start your training run with start_run().\n",
      "#3 mlflow.start_run()\n",
      "#4 mlflow.log_metric - Then use log_metric() to activate the MLflow logging API and begin logging your training run metrics.\n",
      "#1 mlflow.tracking.client = ws, #2 mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri()), #3 mlflow.active_run(), #4 mlflow.log_metric\n",
      "#1 mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri()), #2 mlflow.get_run('mlflow-experiment), #3 mlflow.start_run(), #4 mlflow.log_metric\n",
      "5. You are evaluating a Python NumPy array that contains six data points defined as follows: data = [10, 20, 30, 40, 50, 60]\n",
      "You must generate the following output by using the k-fold algorithm implementation in the Python Scikit-learn machine learning library: train: [10 40 50 60], test: [20 30] train: [20 30 40 60], test: [10 50] train: [10 20 30 50], test: [40 60]\n",
      "You need to implement a cross-validation to generate the output.\n",
      "To answer, replace the bolded comments in the code with the appropriate code options in the answer area.\n",
      "How should you complete the code?\n",
      "from numpy import array\n",
      "from sklearn.model_selection import #1st option\n",
      "data ‚Äì array ([10, 20, 30, 40, 50, 60])\n",
      "kfold ‚Äì Kfold(n_splits- #2nd option, shuffle ‚Äì True ‚Äì random_state-1)\n",
      "for train, test in kFold, split( #3rd option):\n",
      "print (‚Äòtrain‚Äô: %s, test: %5‚Äô % (data[train], data[test])\n",
      "K-fold, 3, array\n",
      "CrossValidation, 3, data\n",
      "(accroch√©) K-fold, 3, data\n",
      "K-means, 6, array\n",
      "You use the following code to run a script as an experiment in Azure Machine Learning: from azureml.core import Workspace, Experiment, Run; from azureml.core import RunConfig, ScriptRunConfig; ws = Workspace.from_config(); run_config = RunConfiguration(); run_config.target=‚Äôlocal‚Äô; script_config = ScriptRunConfig(source_directory=‚Äô./script‚Äô,; script=‚Äôexperiment.py‚Äô, run_config=run_config); experiment = Experiment(workspace=ws, name=‚Äôscript experiment‚Äô); run = experiment.submit(config=script_config); run.wait_for_completion(). Which code do you need to add to retrieve the output file names?\n",
      "files = run.get_fine_names()\n",
      "run.get_details_with_logs()\n",
      "files = run.get_properties()\n",
      "files = run.get_metrics()\n",
      "run.get_details_with_logs()\n",
      "Your task is to predict if a person suffers from a disease by setting up a binary classification model. Your solution needs to be able to detect the classification errors that may appear. Considering the below description, which of the following would be the best error type? ‚ÄúA person does not suffer from a disease. Your model classifies the case as having a disease‚Äù.\n",
      "False negatives\n",
      "True positives\n",
      "True negatives\n",
      "False positives\n",
      "False positives\n",
      "Your task is to predict if a person suffers from a disease by setting up a binary classification model. Your solution needs to be able to detect the classification errors that may appear. Considering the below description, which of the following would be the best error type? ‚ÄúA person suffers from a disease. Your model classifies the case as having no disease‚Äù.\n",
      "True negatives\n",
      "False negatives\n",
      "True positives\n",
      "False positives\n",
      "False negatives\n",
      "As a senior data scientist, you need to evaluate a binary classification machine learning model. As evaluation metric, you have to use the precision. Considering this, which is the most appropriate visualization?\n",
      "Violin plot\n",
      "Gradient descent\n",
      "Scatter plot\n",
      "Receiver Operating Characteristic (ROC) curve\n",
      "Receiver Operating Characteristic (ROC) curve\n",
      "In order to foretell the price for a student‚Äôs craftwork, you have to rely on the following variables: the student‚Äôs length of education, degree type, and craft form. You decide to set up a linear regression model that you will have to evaluate. Solution: Apply the following metrics: Relative Squared Error, Coefficient of Determination, Accuracy, Precision, Recall, F1 score, and AUC: Is this solution effective?\n",
      "Yes\n",
      "No\n",
      "None\n",
      "None\n",
      "No\n",
      "What is the result for multiplying a list by 3?\n",
      "The new list created has the length 3 times the original length with the sequence repeated 3 times.\n",
      "The new list created has the length 3 times the original length with the sequence repeated 3 times and also all the elements are also multiplied by 3.\n",
      "The new list remains the same size, but the elements are multiplied by 3.\n",
      "None\n",
      "The new list created has the length 3 times the original length with the sequence repeated 3 times.\n",
      "Python is commonly known to ensure extensive functionality with powerful and statistical numerical libraries. What are the utilities of TensorFlow?\n",
      "Analyzing and manipulating data\n",
      "Supplying machine learning and deep learning capabilities\n",
      "Offering simple and effective predictive data analysis\n",
      "Providing attractive data visualizations\n",
      "Supplying machine learning and deep learning capabilities\n",
      "How should the following sentence be completed? One example of the machine learning [‚Ä¶] type models is the Support Vector Machine algorithm.\n",
      "Clustering\n",
      "Regression\n",
      "Classification (Logistic Regression)\n",
      "None\n",
      "Classification (Logistic Regression)\n",
      "Choose from the list below the evaluation model that is described as a relative metric where the higher the value is, the better will be the fit of the model.\n",
      "Coefficient of Determination (known as R-squared or R2)\n",
      "Root Mean Square Error (RMSE)\n",
      "None\n",
      "Mean Square Error (MSE)\n",
      "Coefficient of Determination (known as R-squared or R2)\n",
      "You have a Pandas DataFrame entitled df_sales that contains the sales data from each day. You DataFrame contains these columns: year, month, day_of_month, sales_total. Which of the following codes should you choose if your goal is to return the average sales_total value?\n",
      "df_sales['sales_total'].mean()\n",
      "mean(df_sales['sales_total'])\n",
      "df_sales['sales_total'].avg()\n",
      "Nothing\n",
      "df_sales['sales_total'].mean()\n",
      "You decided to use the LinearRegression class from the scikit-learn library to create your model object. If you want to train the model, what should your next step be?\n",
      "Call the predict() method of the model object, specifying the training feature and label arrays\n",
      "Call the score() method of the model object, specifying the training feature and test feature arrays\n",
      "Nothing\n",
      "Call the fit() method of the model object, specifying the training feature and label arrays\n",
      "Call the fit() method of the model object, specifying the training feature and label arrays\n",
      "9. What is the effect that you obtain if you increase the Learning Rate parameter for the deep neural network that you are creating?\n",
      "1 / 1 point\n",
      "(accroch√©) Larger adjustments are made to weight values during backpropagation\n",
      "More records are included in each batch passed through the network\n",
      "More hidden layers are added to the network\n",
      "Correct. Increasing the learning rate causes backpropagation to make larger weight adjustments.\n",
      "10. Your task is to reduce the size of the feature maps that a convolutional layer generates when you create a convolutional neural network. What action should you take in this case?\n",
      "1 / 1 point\n",
      "Increase the number of filters in the convolutional layer\n",
      "(accroch√©) Add a pooling layer after the convolutional layer\n",
      "Reduce the size of the filter kernel used in the convolutional layer\n",
      "Correct. A pooling layer reduces the number of features in a feature map.\n",
      "11. Your task is to train a model entitled finance-data for the financial department, by using data in an Azure Storage blob container.\n",
      "Your container has to be registered in an Azure Machine Learning workspace as a datastore and you have to make sure that an error will appear if the container does not exist.\n",
      "Considering this scenario, what should be the continuation for the code below?\n",
      "Datastore = Datastore.<add answer here> (workspace = ws,\n",
      "datastore_name = ‚Äòfinance_datastore‚Äô,\n",
      "container_name = ‚Äòfinance-data‚Äô,\n",
      "account_name = ‚Äòfintrainingdatastorage‚Äô,\n",
      "account_key = ‚ÄòFdhIWHDaiwh2‚Ä¶‚Äô\n",
      "<add answer here>\n",
      "register_azure_data_lake, create_if_not_exists = False\n",
      "register_azure_blob_container, overwrite = True\n",
      "(accroch√©) register_azure_blob_container, create_if_not_exists = False\n",
      "register_azure_data_lake, overwrite = False\n",
      "Correct\n",
      "register_azure_blob_container to Register an Azure Blob Container to the datastore and create_if_not_exists = False to create the file share if it does not exist, defaults to False.\n",
      "12. You have the role of lead data scientist in a project that keeps record of birds‚Äô health and migration. You decide to use a set of labeled bird photographs collected by experts for your multi-class image classification deep learning model.\n",
      "The entire set of 200,000 birds‚Äô photographs uses the JPG format and is being kept in an Azure blob container from an Azure subscription. You have to be able to ensure access from the Azure Machine Learning service workspace used for deep learning model training directly to the bird photograph files stored in the Azure blob container.\n",
      "You have to keep data movement to a minimum. What action should you take?\n",
      "0 / 1 point\n",
      "(Incorrect) Copy the bird photographs to the blob datastore that was created with your Azure Machine Learning service workspace.\n",
      "(accroch√©??) Register the Azure blob storage containing the bird photographs as a datastore in Azure Machine Learning service.\n",
      "(Incorrect) Create and register a dataset by using TabularDataset class that references the Azure blob storage containing bird photographs.\n",
      "(Incorrect) Create an Azure Cosmos DB database and attach the Azure Blob containing bird photographs storage to the database.\n",
      "(accroch√©) Create an Azure Data Lake store and move the bird photographs to the store.\n",
      "13. You decide to use the code below for the deployment of a model as an Azure Machine Learning real-time web service:\n",
      "# ws, model, inference_config, and deployment_config defined previously\n",
      "service = Model.deploy(ws, ‚Äòclassification-service‚Äô, [model], inference_config, deployment_config)\n",
      "service.wait_for_deployment(True)\n",
      "Your deployment does not succeed.\n",
      "You have to troubleshoot the deployment failure in order to determine what actions were taken while deploying and to identify the one action that encountered a problem and didn‚Äôt succeed.\n",
      "For this scenario, which of the following code snippets should you use?\n",
      "(accroch√©) service.get_logs()\n",
      "service.update_deployment_state()\n",
      "service.serialize()\n",
      "service.state\n",
      "14. You decide to register and train a model in your Azure Machine Learning workspace.\n",
      "Your pipeline needs to ensure that the client applications are able to use the model for batch inferencing.\n",
      "Your single ParallelRunStep step pipeline uses a Python inferencing script in order to obtain predictions from the input data.\n",
      "Your task is to configure the inferencing script for the ParallelRunStep pipeline step.\n",
      "Which are the most suitable two functions that you should use? Keep in mind that every correct answer presents a part of the solution.\n",
      "0 / 1 point\n",
      "(accroch√©) init()\n",
      "(accroch√©) run(mini_batch)\n",
      "main()\n",
      "score(mini_batch)\n",
      "batch()\n",
      "Vous n'avez pas s√©lectionn√© toutes les bonnes r√©ponses\n",
      "15.\n",
      "Question 15\n",
      "After installing the Azure Machine Learning Python SDK, you decide to use it to configure on your subscription a workspace entitled ‚Äúaml-workspace‚Äù.\n",
      "What code should you write in Python for this task?\n",
      "(accroch√©) azureml.core import Workspace\n",
      " ws = Workspace.create(name='aml-workspace',\n",
      " subscription_id='123456-abc-123...',\n",
      " resource_group='aml-resources',\n",
      " create_resource_group=False,\n",
      " location='eastus'\n",
      " )\n",
      "from azureml.core import Workspace\n",
      " ws = Workspace.create(name='aml-workspace',\n",
      " subscription_id='123456-abc-123...',\n",
      " resource_group='aml-resources',\n",
      " create_resource_group=True,\n",
      " location='eastus'\n",
      " )\n",
      "from azureml.core import Workspace\n",
      " ws = Workspace.create(name='aml-workspace',\n",
      " subscription_id='123456-abc-123...',\n",
      " resource_group='aml-resources',\n",
      " location='eastus'\n",
      " )\n",
      "Incorrect\n",
      "Vous n‚Äôavez s√©lectionn√© aucune r√©ponse.\n",
      "16.\n",
      "Question 16\n",
      "If your goal is to use a configuration file in order to ensure connection to your Azure ML workspace, what Python command would be the most appropriate?\n",
      "0 / 1 point\n",
      "from azureml.core import Workspace\n",
      "ws = Workspace.from.config\n",
      "from azureml.core import Workspace\n",
      "ws = from.config_Workspace()\n",
      "from azureml.core import Workspace\n",
      "ws = Workspace.from_config()\n",
      "Incorrect\n",
      "Vous n‚Äôavez s√©lectionn√© aucune r√©ponse.\n",
      "17.\n",
      "Question 17\n",
      "You decided to use the from_files method of the Dataset.File class to configure a file dataset.\n",
      "You then want to register the file dataset with the title img_files in a workspace.\n",
      "What SDK commands should you choose for this task?\n",
      "0 / 1 point\n",
      "from azureml.core import Dataset\n",
      "file_ds = Dataset.File.from_files(path=(blob_ds, 'data/files/images/*.jpg'))\n",
      "file_ds = file_ds.register(workspace=ws, name='img_files')\n",
      "from azureml.core import Dataset\n",
      "blob_ds = ws.get_default_datastore()\n",
      "file_ds = Dataset.File.from_files(path=(blob_ds, 'data/files/images/*.jpg'))\n",
      "from azureml.core import Dataset\n",
      "blob_ds = ws.get_default_datastore()\n",
      "file_ds = Dataset.File.from_files(path=(blob_ds, 'data/files/images/*.jpg'))\n",
      "file_ds = file_ds.register(workspace=ws, name='img_files')\n",
      "from azureml.core import Dataset\n",
      "blob_ds = ws.get_default_datastore()\n",
      "file_ds = Dataset.File.from_files(path=(blob_ds, 'data/files/images'))\n",
      "file_ds = file_ds.register(workspace=ws, name='img_files')\n",
      "Incorrect\n",
      "Vous n‚Äôavez s√©lectionn√© aucune r√©ponse.\n",
      "18.\n",
      "Question 18\n",
      "You want to create a pipeline for which you defined three steps entitled as step1, step2, and step3.\n",
      "Your goal is to run the pipeline as an experiment after the steps have been assigned to it.\n",
      "Which of the following SDK command should you choose for this task?\n",
      "0 / 1 point\n",
      "train_pipeline = Pipeline(workspace = ws, steps = [step1;step2;step3])\n",
      "experiment = Experiment(workspace = ws, name = 'training-pipeline')\n",
      "pipeline_run = experiment.submit(train_pipeline)\n",
      "train_pipeline = Pipeline(workspace = ws, steps = [step1,step2,step3])\n",
      "experiment = Experiment(workspace = ws)\n",
      "pipeline_run = experiment.submit(train_pipeline)\n",
      "train_pipeline = Pipeline(workspace = ws, steps = [step1,step2,step3])\n",
      "experiment = Experiment(workspace = ws, name = 'training-pipeline')\n",
      "pipeline_run = experiment.submit(train_pipeline)\n",
      "train_pipeline = Pipeline(workspace = ws, steps = [step1,step2,step3])\n",
      "experiment = Experiment(workspace = ws, name = 'training-pipeline')\n",
      "pipeline_run = experiment_submit(train_pipeline)\n",
      "Incorrect\n",
      "Vous n‚Äôavez s√©lectionn√© aucune r√©ponse.\n",
      "19. Your task is to deploy your service on an AKS cluster that is set up as a compute target.\n",
      "What SDK commands are able to return you the expected result?\n",
      "0 / 1 point\n",
      "from azureml.core.compute import ComputeTarget, AksCompute\n",
      "cluster_name = 'aks-cluster'\n",
      "compute_config = AksCompute.provisioning_configuration(location='eastus')\n",
      "production_cluster = ComputeTarget.deploy (ws, cluster_name, compute_config)\n",
      "production_cluster.wait_for_completion(show_output=True)\n",
      "from azureml.core.webservice import ComputeTarget, AksCompute\n",
      "cluster_name = 'aks-cluster'\n",
      "compute_config = AksCompute.provisioning_configuration(location='eastus')\n",
      "production_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
      "production_cluster.wait_for_completion(show_output=True)\n",
      "from azureml.core.compute import ComputeTarget, AksCompute\n",
      "cluster_name = 'aks-cluster'\n",
      "compute_config = AksCompute.provisioning_configuration(location='eastus')\n",
      "production_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
      "production_cluster.wait_for_completion(show_output=True)\n",
      "from azureml.core.webservice import ComputeTarget, AksWebservice\n",
      "cluster_name = 'aks-cluster'\n",
      "compute_config = AksCompute.provisioning_configuration(location='eastus')\n",
      "production_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
      "production_cluster.wait_for_completion(show_output=True)\n",
      "Incorrect\n",
      "Vous n‚Äôavez s√©lectionn√© aucune r√©ponse.\n",
      "20. You can combine the Bayesian sampling with an early-termination policy and you can use it only with these three parameter expressions: choice, uniform and quniform.\n",
      "0 / 1 point\n",
      "False\n",
      "True\n",
      "Incorrect\n",
      "Vous n‚Äôavez s√©lectionn√© aucune r√©ponse.\n",
      "21.\n",
      "Question 21\n",
      "What code should you write for an instance of a MimicExplainer if you have a model entitled loan_model?\n",
      "0 / 1 point\n",
      "from interpret.ext.blackbox import MimicExplainer\n",
      "from interpret.ext.glassbox import DecisionTreeExplainableModel\n",
      "mim_explainer = MimicExplainer(model=loan_model,\n",
      " initialization_examples=X_test,\n",
      " explainable_model = DecisionTree,\n",
      " classes=['loan_amount','income','age','marital_status'],\n",
      " features=['reject', 'approve'])\n",
      "from interpret.ext.blackbox import MimicExplainer\n",
      "from interpret.ext.glassbox import DecisionTreeExplainableModel\n",
      "mim_explainer = MimicExplainer(model=loan_model,\n",
      " initialization_examples=X_test,\n",
      " explainable_model = DecisionTreeExplainableModel,\n",
      " features=['loan_amount','income','age','marital_status'],\n",
      "from interpret.ext.blackbox import MimicExplainer\n",
      "from interpret.ext.glassbox import DecisionTreeExplainableModel\n",
      "mim_explainer = MimicExplainer(model=loan_model,\n",
      " explainable_model = DecisionTreeExplainableModel,\n",
      " classes=['loan_amount','income','age','marital_status'],\n",
      " features=['reject', 'approve'])\n",
      "from interpret.ext.blackbox import MimicExplainer\n",
      "from interpret.ext.glassbox import DecisionTreeExplainableModel\n",
      "mim_explainer = MimicExplainer(model=loan_model,\n",
      " initialization_examples=X_test,\n",
      " explainable_model = DecisionTreeExplainableModel,\n",
      " features=['loan_amount','income','age','marital_status'],\n",
      " classes=['reject', 'approve'])\n",
      "Incorrect\n",
      "Vous n‚Äôavez s√©lectionn√© aucune r√©ponse.\n",
      "22.\n",
      "Question 22\n",
      "What code should you write for a PFIExplainer if you have a model entitled loan_model?\n",
      "0 / 1 point\n",
      "from interpret.ext.blackbox import PFIExplainer\n",
      "pfi_explainer = PFIExplainer(model = loan_model,\n",
      " features=['loan_amount','income','age','marital_status'],\n",
      " classes=['reject', 'approve'])\n",
      "from interpret.ext.blackbox import PFIExplainer\n",
      "pfi_explainer = PFIExplainer(model = loan_model,\n",
      "      initialization_examples=X_test,\n",
      " classes=['loan_amount','income','age','marital_status'],\n",
      " features=['reject', 'approve'])\n",
      "from interpret.ext.blackbox import PFIExplainer\n",
      "pfi_explainer = PFIExplainer(model = loan_model,\n",
      "      explainable_model= DecisionTreeExplainableModel,\n",
      " features=['loan_amount','income','age','marital_status'],\n",
      " classes=['reject', 'approve'])\n",
      "from interpret.ext.blackbox\n",
      "pfi_explainer = PFIExplainer(model = loan_model,\n",
      "      initialization_examples=X_test,\n",
      " features=['loan_amount','income','age','marital_status'],\n",
      " classes=['reject', 'approve'])\n",
      "Incorrect\n",
      "Vous n‚Äôavez s√©lectionn√© aucune r√©ponse.\n",
      "23.\n",
      "Question 23\n",
      "Your task is to train a binary classification model in order for it to be able to target the correct subjects in a marketing campaign.\n",
      "What actions should you take if you want to ensure that your model is fair and will not be inclined to ethnic discrimination?\n",
      "0 / 1 point\n",
      "Compare disparity between selection rates and performance metrics across ethnicities.\n",
      "Evaluate each trained model with a validation dataset, and use the model with the highest accuracy score. An accurate model is inherently fair.\n",
      "Remove the ethnicity feature from the training dataset.\n",
      "Incorrect\n",
      "Vous n‚Äôavez s√©lectionn√© aucune r√©ponse.\n",
      "24.\n",
      "Question 24\n",
      "Your task is to back fill a dataset monitor for the previous 5 months based on changes made in data on a monthly basis.\n",
      "What code should you write in the SDK to achieve this goal?\n",
      "0 / 1 point\n",
      "import datetime as dt\n",
      "backfill = monitor_backfill( dt.datetime.now(), dt.timedelta(months=5), dt.datetime.now())\n",
      "import datetime as dt\n",
      "backfill = monitor.backfill( dt.datetime.now() - dt.timedelta(months=5), dt.datetime.now())\n",
      "import datetime as dt\n",
      "backfill = monitor.backfill( dt.datetime.now(), dt.timedelta(months=5), dt.datetime.now())\n",
      "import datetime as dt\n",
      "backfill = monitor_backfill( dt.datetime.now() - dt.timedelta(months=5), dt.datetime.now())\n",
      "Incorrect\n",
      "Vous n‚Äôavez s√©lectionn√© aucune r√©ponse.\n",
      "25.\n",
      "Question 25\n",
      "In order to track the runs of a Linear Regression model of your AirBnB dataset, you decide to use MLflow.\n",
      "You want to make use of all the features included in your dataset.\n",
      "At this point, you have created and logged the pipeline and you have logged the parameters.\n",
      "You now have to create some predictions and metrics.\n",
      "Considering this scenario, what code should you write?\n",
      "0 / 1 point\n",
      "predDF = pipelineModel.evaluate(testDF)\n",
      "regressionEvaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\")\n",
      "rmse = regressionEvaluator.setMetricName(\"rmse\").evaluate(predDF)\n",
      "r2 = regressionEvaluator.setMetricName(\"r2\").evaluate(predDF)\n",
      "predDF = pipelineModel.transform(testDF)\n",
      "regressionEvaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\")\n",
      "rmse = regressionEvaluator.setMetricName(\"rmse\").evaluate(predDF)\n",
      "r2 = regressionEvaluator.setMetricName(\"r2\").evaluate(predDF)\n",
      "predDF = pipelineModel.estimate(testDF)\n",
      "regressionEvaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\")\n",
      "rmse = regressionEvaluator.setMetricName(\"rmse\").evaluate(predDF)\n",
      "r2 = regressionEvaluator.setMetricName(\"r2\").evaluate(predDF)\n",
      "predDF = pipelineModel.transform(testDF)\n",
      "regression = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\")\n",
      "rmse = regressionEvaluator.setMetricName(\"rmse\").evaluate(predDF)\n",
      "r2 = regressionEvaluator.setMetricName(\"r2\").evaluate(predDF)\n",
      "Incorrect\n",
      "Vous n‚Äôavez s√©lectionn√© aucune r√©ponse.\n",
      "26.\n",
      "Question 26\n",
      "You are using remote compute in Azure Machine Learning to run a training experiment.\n",
      "The Conda environment used for the experiment includes both the mlflow, and the azureml-contrib-run packages. In order to track the metrics that the experiment generates, you have to log package by using MLflow.\n",
      "To give the correct answer, you have to replace the code comments that are bolded with some suitable code options that you find in the answer area.\n",
      "Considering this, what snippet should you choose to complete the code?\n",
      "Import numpy as np\n",
      "#1 Import library to log metrics\n",
      "#2 Start logging for this run\n",
      "reg_rage = 0.01\n",
      "#3 Log the reg_rate metric\n",
      "#4 Stop loggin for this run\n",
      "0 / 1 point\n",
      "#1 from azureml.core import Run, #2 run = Run.get_context(), #3 logger.info(' ..'), #4 run.complete()\n",
      "#1 import logging, #2 mlflow.start_run(), #3 mlflow.log_metric(' ..'), #4 run.complete()\n",
      "#1 import mlflow, #2 mlflow.start_run(), #3 mlflow.log_metric(' ..'), #4 mlflow.end_run()\n",
      "#1 import mlflow, #2 mlflow.start_run(), #3 logger.info(' ..'), #4 mlflow.end_run()\n",
      "Incorrect\n",
      "Vous n‚Äôavez s√©lectionn√© aucune r√©ponse.\n",
      "27.\n",
      "Question 27\n",
      "You want to deploy in your Azure Container Instance a deep learning model.\n",
      "In order to call the model API, you have to use the Azure Machine Learning SDK.\n",
      "To invoke the deployed model, you have to use native SDK classes and methods.\n",
      "To give the correct answer, you have to replace the code comments that are bolded with some suitable code options that you find in the answer area.\n",
      "Considering this, what snippet should you choose to complete the code?\n",
      "from azureml.core import Workspace\n",
      "#1st code option\n",
      "Import json\n",
      "ws = Workspace.from_config()\n",
      "service_name = ‚Äúmlmodel1-service‚Äù\n",
      "service = Webservice(name=service_name, workspace=ws)\n",
      "x_new = [[2, 101.5, 1, 24, 21], [1, 89.7, 4, 41, 21]]\n",
      "input_json = json.dumps({‚Äúdata‚Äù: x_new})\n",
      "#2nd code option\n",
      "0 / 1 point\n",
      "from azureml.core.webservice import requests, predictions = service.run(input_json)\n",
      "from azureml.core.webservice import Webservice, predictions = service.deserialize(ws, input_json)\n",
      "from azureml.core.webservice import Webservice, predictions = service.run(input_json)\n",
      "from azureml.core.webservice import LocalWebservice, predictions = service.run(input_json)\n",
      "Incorrect\n",
      "Vous n‚Äôavez s√©lectionn√© aucune r√©ponse.\n",
      "28.\n",
      "Question 28\n",
      "One of the categorical variables of your AirBnB dataset is room type.\n",
      "You have three room types, as follows: private room, entire home/apt, and shared room.\n",
      "In order for the machine learning model to know how to handle the room types, you have to firstly encode every unique string into a number.\n",
      "What code should you write to achieve this goal?\n",
      "0 / 1 point\n",
      "from pyspark.ml.feature import Indexer\n",
      "uniqueTypesDF = airbnbDF.select(\"room_type\").distinct()\n",
      "indexer = StringIndexer(inputCol=\"room_type\", outputCol=\"room_type_index\")\n",
      "indexerModel = indexer.fit(uniqueTypesDF)\n",
      "indexedDF = indexerModel.transform(uniqueTypesDF)\n",
      "display(indexedDF)\n",
      "from pyspark.ml.feature import StringIndexer\n",
      "uniqueTypesDF = airbnbDF.select(\"room_type\").distinct()\n",
      "indexer = StringIndexer(inputCol=\"room_type\", outputCol=\"room_type_index\")\n",
      "indexerModel = indexer.transform(uniqueTypesDF)\n",
      "indexedDF = indexerModel.transform(uniqueTypesDF)\n",
      "display(indexedDF)\n",
      "from pyspark.ml.feature import StringIndexer\n",
      "uniqueTypesDF = airbnbDF.select(\"room_type\").distinct()\n",
      "indexer = StringIndexer(inputCol=\"room_type\", outputCol=\"room_type_index\")\n",
      "indexerModel = indexer.fit(uniqueTypesDF)\n",
      "indexedDF = indexerModel.transform(uniqueTypesDF)\n",
      "display(indexedDF)\n",
      "from pyspark.ml.feature import StringIndexer\n",
      "uniqueTypesDF = airbnbDF.select(\"room_type\").distinct()\n",
      "indexer = StringIndexer(inputCol=\"room_type‚Äù)\n",
      "indexerModel = indexer.fit(uniqueTypesDF)\n",
      "indexedDF = indexerModel.transform(uniqueTypesDF)\n",
      "display(indexedDF)\n",
      "29. Your task is to extract from the experiments list the last run.\n",
      "What code should you write in Python to achieve this?\n",
      "runs = client.search_runs(experiment_id, order_by=[\"attributes.start_time desc\"], max_results=1)\n",
      "runs[0].data.metrics\n",
      "runs = client.search_runs(experiment_id, order_by=[\"attributes.start_time asce\"], max_results=1)\n",
      "runs[0].data.metrics\n",
      "runs = client.search_runs(experiment_id, order_by=[\"attributes.start_time\"], max_results=1)\n",
      "runs[0].data.metrics\n",
      "runs = client.search_runs(experiment_id, order_by=[\"attributes.start_time desc\"], max_results=3)\n",
      "runs[0].data.metrics\n",
      "Incorrect\n",
      "Vous n‚Äôavez s√©lectionn√© aucune r√©ponse.\n",
      "30.\n",
      "Question 30\n",
      "Choose from the list below the cross-validation technique that belongs to the exhaustive type.\n",
      "0 / 1 point\n",
      "Holdout cross-validation\n",
      "K-fold cross-validation\n",
      "Leave-one-out cross-validation\n",
      "Leave-p-out cross-validation\n",
      "Vous n'avez pas s√©lectionn√© toutes les bonnes r√©ponses\n",
      "31. Your task is to clean up the deployments and terminate the ‚Äúdev‚Äù ACI webservice by making use of the Azure ML SDK after your work with Azure Machine Learning has ended.\n",
      "What is the most suitable method in order to achieve this goal?\n",
      "(accroch√©) dev_webservice.delete()\n",
      "dev_webservice.terminate()\n",
      "dev_webservice.flush()\n",
      "dev_webservice.remove()\n",
      "32. The DataFrame you are currently working on contains data regarding the daily sales of ice cream. In order to compare the avg_temp and units_sold columns you decided to use the corr method which returned a result of 0.95.\n",
      "What information can you read from this result?\n",
      "0 / 1 point\n",
      "Days with high avg_temp values tend to coincide with days that have high units_sold values\n",
      "On the day with the maximum units_sold value, the avg_temp value was 0.95\n",
      "The units_sold value is, on average, 95% of the avg_temp value\n",
      "Incorrect\n",
      "Vous n‚Äôavez s√©lectionn√© aucune r√©ponse.\n",
      "33.\n",
      "Question 33\n",
      "You can enable the Application Insights when configuring the service deployment at the moment you want to deploy a new real-time service.\n",
      "By using the SDK, what code should you write to achieve this goal?\n",
      "0 / 1 point\n",
      "dep_config = AciWebservice.deploy_configuration(cpu_cores = 1,\n",
      " memory_gb = 1,\n",
      " enable_app_insights=True)\n",
      "dep_config = AciWebservice.deploy_configuration(cpu_cores = 1,\n",
      " memory_gb = 1,\n",
      " app_insights(True))\n",
      "dep_config = AciWebservice.deploy_configuration(cpu_cores = 1,\n",
      " memory_gb = 1,\n",
      " app_insights=True)\n",
      "dep_config = AciWebservice.deploy_configuration(cpu_cores = 1,\n",
      " memory_gb = 1,\n",
      " appinsights=True)\n",
      "Incorrect\n",
      "Vous n‚Äôavez s√©lectionn√© aucune r√©ponse.\n",
      "34.\n",
      "Question 34\n",
      "You decided to use Parquet files and Petastorm to train a distributed neural network by using Horovod.\n",
      "Your housing prices dataset from California is entitled cal_housing.\n",
      "In order to concatenate the features and labels of the model after you loaded the data, you configured from the Pandas DataFrame a Spark DataFrame.\n",
      "At this point, you want to set up Dense Vectors for the features.\n",
      "What code should you write in Python to achieve this?\n",
      "0 / 1 point\n",
      "from pyspark.ml.feature import VectorAssembler\n",
      "vecAssembler = VectorAssembler(inputCols=cal_housing.feature_names, outputCol=\"features\")\n",
      "vecTrainDF = vecAssembler.transform(trainDF).hook(\"features\", \"label\")\n",
      "display(vecTrainDF)\n",
      "from pyspark.ml.feature import VectorAssembler\n",
      "vecAssembler = VectorAssembler(inputCols=cal_housing.feature_names, outputCol=\"features\")\n",
      "vecTrainDF = vecAssembler.transform(trainDF).call(\"features\", \"label\")\n",
      "display(vecTrainDF)\n",
      "from pyspark.ml.feature import VectorAssembler\n",
      "vecAssembler = VectorAssembler(inputCols=cal_housing.feature_names, outputCol=\"features\")\n",
      "vecTrainDF = vecAssembler.transform(trainDF).select(\"features\", \"label\")\n",
      "display(vecTrainDF)\n",
      "from pyspark.ml.feature import VectorAssembler\n",
      "vecAssembler = VectorAssembler(inputCols=cal_housing.feature_names, outputCol=\"labels \")\n",
      "vecTrainDF = vecAssembler.transform(trainDF).select(\"features\", \"label\")\n",
      "display(vecTrainDF)\n",
      "5. How should the following sentence be completed?\n",
      "One example of the machine learning [‚Ä¶] type models is the Support Vector Machine algorithm.\n",
      "Clustering\n",
      "Regression\n",
      "(accroch√©) Classification\n",
      "Correct. Logistic Regression is a well-established algorithm for classification.\n",
      "6. You have a Pandas DataFrame entitled df_sales that contains the sales data from each day. You DataFrame contains these columns: year, month, day_of_month, sales_total. Which of the following codes should you choose if your goal is to return the average sales_total value?\n",
      "1 / 1 point\n",
      "(accroch√©) df_sales['sales_total'].mean()\n",
      "mean(df_sales['sales_total'])\n",
      "df_sales['sales_total'].avg()\n",
      "Correct\n",
      "This code will return the average of the sales_total column values.\n",
      "7.\n",
      "Question 7\n",
      "When you use the Support Vector Machine algorithm, what type of machine learning model is possible to train?\n",
      "1 / 1 point\n",
      "Regression\n",
      "Clustering\n",
      "(accroch√©) Classification\n",
      "Correct. Logistic Regression is a well-established algorithm for classification.\n",
      "8. You are able to associate the K-Means clustering algorithm with the following machine learning type:\n",
      "1 / 1 point\n",
      "Reinforcement learning\n",
      "(accroch√©) Unsupervised machine learning\n",
      "Supervised machine learning\n",
      "Correct. Clustering is a form of unsupervised machine learning in which the training data does not include known labels.\n",
      "9. Your deep neural network is in the process of training. You decided to set 30 epochs to the training process configuration.\n",
      "In this scenario, what would happen to the model‚Äôs behavior?\n",
      "0 / 1 point\n",
      "The training data is split into 30 subsets, and each subset is passed through the network\n",
      "(accroch√©) The entire training dataset is passed through the network 30 times\n",
      "The first 30 rows of data are used to train the model, and the remaining rows are used to validate it\n",
      "10. The layer described below is used to reduce the number of feature values that are extracted from images, while still retaining the key differentiating features.\n",
      "1 / 1 point\n",
      "Flattening layer\n",
      "(accroch√©) Pooling layer\n",
      "Convolutional layer\n",
      "Correct. After extracting feature values from images, pooling (or downsampling) layers are used to reduce the number of feature values while retaining the key differentiating features that have been extracted.\n",
      "11. You want to set up a new Azure subscription. The subscription doesn‚Äôt contain any resources.\n",
      "Your goal is to create an Azure Machine Learning workspace.\n",
      "Considering this scenario, which are three possible ways to obtain this result? Keep in mind that every correct answer presents a complete solution.\n",
      "1 / 1 point\n",
      "Navigate to Azure Machine Learning studio and create a workspace.\n",
      "(accroch√©) Use the Azure Command Line Interface (CLI) with the Azure Machine Learning extension to call the az group create function with ‚Äìname and ‚Äìlocation parameters, and then the az ml workspace create function, specifying Cw and Cg parameters for the workspace name and resource group.\n",
      "Correct\n",
      "This is one way to achieve the goal.\n",
      "(accroch√©) Use an Azure Resource Management template that includes a Microsoft.MachineLearningServices/ workspaces resource and its dependencies.\n",
      "Correct\n",
      "This is one way to achieve the goal.\n",
      "Run Python code that uses the Azure ML SDK library and calls the Workspace.get method with name, subscription_id, and resource_group parameters.\n",
      "(accroch√©) Run Python code that uses the Azure ML SDK library and calls the Workspace.create method with name, subscription_id, resource_group, and location parameters.\n",
      "Correct\n",
      "This is one way to achieve the goal.\n",
      "12.\n",
      "Question 12\n",
      "You decide to use GPU-based training to develop a deep learning model on Azure Machine Learning service that is able to recognize image.\n",
      "The context where you have to configure the model needs to allow real-time GPU-based inferencing.\n",
      "Considering that you have to set up compute resources for model inferencing, what is the most suitable compute type?\n",
      "1 / 1 point\n",
      "Field Programmable Gate Array\n",
      "Machine Learning Compute\n",
      "(accroch√©) Azure Kubernetes Service\n",
      "Azure Container Instance\n",
      "Correct\n",
      "You can use Azure Machine Learning to deploy a GPU-enabled model as a web service. Deploying a model on Azure Kubernetes Service (AKS) is a viable option. The AKS cluster provides a GPU resource that is used by the model for inference.\n",
      "13.\n",
      "Question 13\n",
      "You decide to use the code below for the deployment of a model as an Azure Machine Learning real-time web service:\n",
      "# ws, model, inference_config, and deployment_config defined previously\n",
      "service = Model.deploy(ws, ‚Äòclassification-service‚Äô, [model], inference_config, deployment_config)\n",
      "service.wait_for_deployment(True)\n",
      "Your deployment does not succeed.\n",
      "You have to troubleshoot the deployment failure in order to determine what actions were taken while deploying and to identify the one action that encountered a problem and didn‚Äôt succeed.\n",
      "For this scenario, which of the following code snippets should you use?\n",
      "1 / 1 point\n",
      "(accroch√©) service.get_logs()\n",
      "service.serialize()\n",
      "service.update_deployment_state()\n",
      "service.state\n",
      "Correct\n",
      "You can print out detailed Docker engine log messages from the service object.\n",
      "You can view the log for ACI, AKS, and Local deployments.\n",
      "14.\n",
      "Question 14\n",
      "Yes or No?\n",
      "In order to explain the model‚Äôs predictions, you have to calculate the importance of all the features, taking into account the overall global relative importance value, but also the measure of local importance for a certain set of predictions.\n",
      "You decide to obtain the global and local feature importance values that you need by using an explainer.\n",
      "Solution: Configure a PFIExplainer. Is this solution effective?\n",
      "1 / 1 point\n",
      "Yes\n",
      "(accroch√©) No\n",
      "Correct\n",
      "The PFIExplainer doesn't support local feature importance explanations.\n",
      "15.\n",
      "Question 15\n",
      "After installing the Azure Machine Learning Python SDK, you decide to use it to configure on your subscription a workspace entitled ‚Äúaml-workspace‚Äù.\n",
      "What code should you write in Python for this task?\n",
      "0 / 1 point\n",
      "(accroch√©) from azureml.core import Workspace\n",
      " ws = Workspace.create(name='aml-workspace',\n",
      " subscription_id='123456-abc-123...',\n",
      " resource_group='aml-resources',\n",
      " create_resource_group=True,\n",
      " location='eastus'\n",
      " )\n",
      "from azureml.core import Workspace\n",
      " ws = Workspace.create(name='aml-workspace',\n",
      " subscription_id='123456-abc-123...',\n",
      " resource_group='aml-resources',\n",
      " location='eastus'\n",
      " )\n",
      "azureml.core import Workspace\n",
      " ws = Workspace.create(name='aml-workspace',\n",
      " subscription_id='123456-abc-123...',\n",
      " resource_group='aml-resources',\n",
      " create_resource_group=False,\n",
      " location='eastus'\n",
      " )\n",
      "16.\n",
      "Question 16\n",
      "What Python command should you choose in order to view the models previously registered in the Azure ML studio by using the Model object?\n",
      "1 / 1 point\n",
      "from azureml.core import Model\n",
      "for model in List.Model(ws):\n",
      "print(model.name, 'version:', model.version)\n",
      "from azureml.core import Model\n",
      "for model in Model.list(ws):\n",
      "get(model.name, 'version:', model.version)\n",
      "(accroch√©) from azureml.core import Model\n",
      "for model in Model.list(ws):\n",
      "print(model.name, 'version:', model.version)\n",
      "from azureml.core import Model\n",
      "for model in Model.object(ws):\n",
      "print(model.name, 'version:', model.version)\n",
      "17. If you want to extract a dataset after its registration, what are the most suitable methods you should choose from the Dataset class?\n",
      "1 / 1 point\n",
      "(accroch√©) get_by_name\n",
      "Correct\n",
      "This method will retrieve a dataset using its name.\n",
      "(accroch√©) get_by_id\n",
      "Correct\n",
      "This method will retrieve a dataset using its id.\n",
      "find_by_name\n",
      "find_by_id\n",
      "18. If you want to visualize the environments that you registered in your workspace, what are the most appropriate SDK commands that you should choose?\n",
      "1 / 1 point\n",
      "from azureml.core import Environment\n",
      "env_names = Environment_list(workspace=ws)\n",
      "for env_name in env_names:\n",
      "print('Name:',env_name)\n",
      "from azureml.core import Environment\n",
      "env_names = Environment.list(workspace=ws)\n",
      "for each env_name in env_names:\n",
      "print('Name:',env_name)\n",
      "from azureml.core import Environment\n",
      "env_names = Environment.list(workspace=ws)\n",
      "for env_name of env_names:\n",
      "print('Name:',env_name)\n",
      "(accroch√©) from azureml.core import Environment\n",
      "env_names = Environment.list(workspace=ws)\n",
      "for env_name in env_names:\n",
      "print('Name:',env_name)\n",
      "Correct\n",
      "These commands will show you the registered environments in your workspace.\n",
      "19.\n",
      "Question 19\n",
      "What object needs to be defined if your task is to create a schedule for your pipeline?\n",
      "1 / 1 point\n",
      "ScheduleSync\n",
      "ScheduleConfig\n",
      "(accroch√©) ScheduleRecurrence\n",
      "ScheduleTimer\n",
      "Correct. To schedule a pipeline to run at periodic intervals, you must define a ScheduleRecurrence that determines the run frequency, and use it to create a Schedule.\n",
      "20.\n",
      "Question 20\n",
      "If you want to set up a parallel run step, which of the SDK commands below should you choose?\n",
      "1 / 1 point\n",
      "parallelrun_step = ParallelRunStep(\n",
      " name='batch-score',\n",
      " parallel.run.config=parallel_run_config,\n",
      " inputs=[batch_data_set.as_named_input('batch_data')],\n",
      " output=output_dir,\n",
      " arguments=[],\n",
      " allow_reuse=True\n",
      "(accroch√©) parallelrun_step = ParallelRunStep(\n",
      " name='batch-score',\n",
      " parallel_run_config=parallel_run_config,\n",
      " inputs=[batch_data_set.as_named_input('batch_data')],\n",
      " output=output_dir,\n",
      " arguments=[],\n",
      " allow_reuse=True\n",
      "parallelrun_step = ParallelRunStep(\n",
      " name='batch-score',\n",
      " parallel_run_config=parallel.run.config,\n",
      " inputs=[batch_data_set.as_named_input('batch_data')],\n",
      " output=output_dir,\n",
      " arguments=[],\n",
      " allow_reuse=True\n",
      "parallelrun.step = ParallelRunStep(\n",
      " name='batch-score',\n",
      " parallel_run_config=parallel_run_config,\n",
      " inputs=[batch_data_set.as_named_input('batch_data')],\n",
      " output=output_dir,\n",
      " arguments=[],\n",
      " allow_reuse=True\n",
      "21. What Python code should you write if your goal is to extract the primary metric for a regression task?\n",
      "1 / 1 point\n",
      "from azureml.train.automl.utilities import catch_primary_metrics\n",
      "catch_primary_metrics(‚Äòregression')\n",
      "from azureml.train.automl.utilities import pull_primary_metrics\n",
      "pull_primary_metrics(‚Äòregression')\n",
      "(accroch√©) from azureml.train.automl.utilities import get_primary_metrics\n",
      "get_primary_metrics('regression')\n",
      "from azureml.train.automl.utilities import feed_primary_metrics\n",
      "feed_primary_metrics('regression')\n",
      "22. Your task is to extract local feature importance from a TabularExplainer.\n",
      "What code should you write in the SDK to achieve this goal?\n",
      "1 / 1 point\n",
      "local.tab_explanation = tab_explainer_explain_local(X_test[0:5])\n",
      "local_tab_features = local_tab_explanation.get_ranked_local_names()\n",
      "local_tab_importance = local_tab_explanation.get_ranked_local_values()\n",
      "local_tab_explanation = tab_explainer.explain_local(X_test[0:5])\n",
      "local_tab_features = local_tab_explanation.get_feature_local_names()\n",
      "local_tab_importance = local_tab_explanation.get_ranked_local_values()\n",
      "local_tab_explanation = tab_explainer.explain_local(X_test[0:5])\n",
      "local_tab_features = local_tab_explanation.get_feature_importance_dict ()\n",
      "local_tab_importance = local_tab_explanation.get_ranked_local_values()\n",
      "(accroch√©) local_tab_explanation = tab_explainer.explain_local(X_test[0:5])\n",
      "local_tab_features = local_tab_explanation.get_ranked_local_names()\n",
      "local_tab_importance = local_tab_explanation.get_ranked_local_values()\n",
      "23.\n",
      "Question 23\n",
      "Your task is to train a binary classification model in order for it to be able to target the correct subjects in a marketing campaign.\n",
      "What actions should you take if you want to ensure that your model is fair and will not be inclined to ethnic discrimination?\n",
      "1 / 1 point\n",
      "Remove the ethnicity feature from the training dataset.\n",
      "(accroch√©) Compare disparity between selection rates and performance metrics across ethnicities.\n",
      "Evaluate each trained model with a validation dataset, and use the model with the highest accuracy score. An accurate model is inherently fair.\n",
      "Correct\n",
      "By using ethnicity as a sensitive field, and comparing disparity between selection rates and performance metrics for each ethnicity value, you can evaluate the fairness of the model.\n",
      "24. Your task is to back fill a dataset monitor for the previous 5 months based on changes made in data on a monthly basis.\n",
      "What code should you write in the SDK to achieve this goal?\n",
      "1 / 1 point\n",
      "(accroch√©) import datetime as dt\n",
      "backfill = monitor.backfill( dt.datetime.now() - dt.timedelta(months=5), dt.datetime.now())\n",
      "import datetime as dt\n",
      "backfill = monitor_backfill( dt.datetime.now(), dt.timedelta(months=5), dt.datetime.now())\n",
      "import datetime as dt\n",
      "backfill = monitor.backfill( dt.datetime.now(), dt.timedelta(months=5), dt.datetime.now())\n",
      "import datetime as dt\n",
      "backfill = monitor_backfill( dt.datetime.now() - dt.timedelta(months=5), dt.datetime.now())\n",
      "25. You decided to use the AirBnB Housing dataset and the Linear Regression algorithm for which you want to tune the Hyperparameters.\n",
      "At this point, for the Boston data set you have executed a test split and for the linear regression you have built a pipeline.\n",
      "You now want to test the maximum number of iterations by using the ParamGridBuilder() and you can do this no matter if you want to use an intercept with the y axis or fi you want to standardize the features.\n",
      "Considering this scenario, what code should you write?\n",
      "1 / 1 point\n",
      "from pyspark.ml.tuning import ParamGridBuilder\n",
      "paramGrid = (ParamGridBuilder(lr)\n",
      ".addGrid(lr.maxIter, [1, 10, 100])\n",
      ".addGrid(lr.fitIntercept, [True, False])\n",
      ".addGrid(lr.standardization, [True, False])\n",
      ".create()\n",
      ")\n",
      "from pyspark.ml.tuning import ParamGridBuilder\n",
      "paramGrid = (ParamGridBuilder(lr)\n",
      ".addGrid(lr.maxIter, [1, 10, 100])\n",
      ".addGrid(lr.fitIntercept, [True, False])\n",
      ".addGrid(lr.standardization, [True, False])\n",
      ".run()\n",
      ")\n",
      "(accroch√©) from pyspark.ml.tuning import ParamGridBuilder\n",
      "paramGrid = (ParamGridBuilder()\n",
      ".addGrid(lr.maxIter, [1, 10, 100])\n",
      ".addGrid(lr.fitIntercept, [True, False])\n",
      ".addGrid(lr.standardization, [True, False])\n",
      ".build()\n",
      ")\n",
      "from pyspark.ml.tuning import ParamGridBuilder\n",
      "paramGrid = (ParamGridBuilder()\n",
      ".addGrid(lr.maxIter, [1, 10, 100])\n",
      ".addGrid(lr.fitIntercept, [True, False])\n",
      ".addGrid(lr.standardization, [True, False])\n",
      ".search()\n",
      ")\n",
      "Correct\n",
      "This is the correct code for this task.\n",
      "26.\n",
      "Question 26\n",
      "You decided to use Python code interactively in your Conda environment. You have all the required Azure Machine Learning SDK and MLflow packages in the environment.\n",
      "In order to log metrics in your Azure Machine Learning experiment entitled mlflow-experiment, you have to use MLflow.\n",
      "To give the correct answer, you have to replace the code comments that are bolded with some suitable code options that you find in the answer area.\n",
      "Considering this, what snippet should you choose to complete the code?\n",
      "import mlflow\n",
      "from azureml.core import Workspace\n",
      "ws = Workspace.from_config()\n",
      "#1 Set the MLflow logging target\n",
      "#2 Configure the experiment\n",
      "with #3 Begin the experiment run\n",
      "   #4 Log my_metric with value 1.00 (‚Äòmy_metric‚Äô, 1.00)\n",
      "print(‚ÄúFinished!‚Äù)\n",
      "1 / 1 point\n",
      "#1 mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri()), #2 mlflow.get_run('mlflow-experiment), #3 mlflow.start_run(), #4 run.log()\n",
      "(accroch√©) #1 mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri()), #2 mlflow.set_experiment('mlflow-experiment), #3 mlflow.start_run(), #4 mlflow.log_metric\n",
      "#1 mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri()), #2 mlflow.get_run('mlflow-experiment), #3 mlflow.start_run(), #4 mlflow.log_metric\n",
      "#1 mlflow.tracking.client = ws, #2 mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri()), #3 mlflow.active_run(), #4 mlflow.log_metric\n",
      "Correct\n",
      "#1 mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri()) In the following code, the get_mlflow_tracking_uri() method assigns a unique tracking URI address to the workspace, ws, and set_tracking_uri() points the MLflow tracking URI to that address.\n",
      "#2 mlflow.set_experiment(experiment_name) Set the MLflow experiment name with set_experiment() and start your training run with start_run().\n",
      "#3 mlflow.start_run()\n",
      "#4 mlflow.log_metric - Then use log_metric() to activate the MLflow logging API and begin logging your training run metrics.\n",
      "27.\n",
      "Question 27\n",
      "For your experiment in Azure Machine Learning you decide to run the following code:\n",
      "from azureml.core import Workspace, Experiment, Run\n",
      "from azureml.core import RunConfig, ScriptRunConfig\n",
      "ws = Workspace.from_config()\n",
      "run_config = RunConfiguration()\n",
      "run_config.target=‚Äôlocal‚Äô\n",
      "script_config = ScriptRunConfig(source_directory=‚Äô./script‚Äô, script=‚Äôexperiment.py‚Äô, run_config=run_config)\n",
      "experiment = Experiment(workspace=ws, name=‚Äôscript experiment‚Äô)\n",
      "run = experiment.submit(config=script_config)\n",
      "run.wait_for_completion()\n",
      "The experiment run generates several output files that need identification.\n",
      "In order to retrieve the output file names, you must write some code. Which of the following code snippets should you choose to complete the script?\n",
      "0 / 1 point\n",
      "files = run.get_fine_names()\n",
      "files = run.get_details_with_logs()\n",
      "files = run.get_metrics()\n",
      "(accroch√©) files = run.get_properties()\n",
      "28.\n",
      "Question 28\n",
      "Which of the options listed below is able to show if you have missing values in the dataset when you want to find out the number of observations in the data set in the process of explanatory data analysis?\n",
      "1 / 1 point\n",
      "Mean\n",
      "Standard deviation\n",
      "(accroch√©) Count\n",
      "Correct\n",
      "Count gives us the number of observed values, indicating the size of the dataset and whether there are missing values.\n",
      "29.\n",
      "Question 29\n",
      "You are able to use the the MlflowClient object as the pathway in order to query previous runs in a programmatic manner.\n",
      "What code should you write in Python to achieve this?\n",
      "1 / 1 point\n",
      "from mlflow.pipelines import MlflowClient\n",
      "client = MlflowClient()\n",
      "list.experiments()\n",
      "from mlflow.tracking import MlflowClient\n",
      "client = MlflowClient()\n",
      "list.client_experiments()\n",
      "from mlflow.pipelines import MlflowClient\n",
      "client = MlflowClient()\n",
      "client.list_experiments()\n",
      "(accroch√©) from mlflow.tracking import MlflowClient\n",
      "client = MlflowClient()\n",
      "client.list_experiments()\n",
      "30.\n",
      "Question 30\n",
      "Which of the non-exhaustive cross validation techniques listed below enables you to assign data points in a random way to the training set and the test set?\n",
      "0 / 1 point\n",
      "Repeated random sub-sampling validation\n",
      "(accroch√©) K-fold cross-validation\n",
      "Holdout cross-validation\n",
      "31.\n",
      "Question 31\n",
      "Your task is to clean up the deployments and terminate the ‚Äúdev‚Äù ACI webservice by making use of the Azure ML SDK after your work with Azure Machine Learning has ended.\n",
      "What is the most suitable method in order to achieve this goal?\n",
      "1 / 1 point\n",
      "dev_webservice.terminate()\n",
      "dev_webservice.flush()\n",
      "dev_webservice.remove()\n",
      "(accroch√©) dev_webservice.delete()\n",
      "Correct. Because ACI manages compute resources on your behalf, deleting the \"dev\" ACI webservice will remove all resources associated with the \"dev\" model deployment\n",
      "32. Your task is to store in the Azure ML workspace a model for whose training you ran an experiment. You want to do this so that other experiments and services can be applied to the model.\n",
      "Considering this scenario, what action should you take to achieve the result?\n",
      "1 / 1 point\n",
      "Save the model as a file in a compute instance\n",
      "Save the model as a file in a Key Vault instance\n",
      "(accroch√©) Register the model in the workspace\n",
      "Save the experiment script as a notebook\n",
      "Correct\n",
      "To store a model in the workspace, you have to register it.\n",
      "33.\n",
      "Question 33\n",
      "Which of the following methods are the ACI services and AKS services default authentication ones?\n",
      "0 / 1 point\n",
      "(accroch√©) Disabled for ACI services\n",
      "Disabled for AKS services\n",
      "(accroch√©) Key-based for AKS services\n",
      "Correct\n",
      "By default, authentication is set to key-based authentication for AKS services (for which primary and secondary keys are automatically generated).\n",
      "Token-based for AKS services.\n",
      "(Incorrect) Token-based for ACI services\n",
      "34. You decided to use Azure Machine Learning and your goal is to train a Diabetes Model and build a container image for it.\n",
      "You choose to make use of the scikit-learn ElasticNet linear regression model.\n",
      "You want to use Azure Kubernetes Service (AKS) for the model deployment to production.\n",
      "For deploying the model, you configured an AKS cluster.\n",
      "At this point, you have deployed the image of the model to the desired AKS cluster.\n",
      "After using different hyperparameters to train the new model, your goal is to deploy to the AKS cluster the new image of the model.\n",
      "What code should you write for this task?\n",
      "1 / 1 point\n",
      "prod_webservice.create (image=model_image_updated)\n",
      "prod_webservice.wait_for_deployment(show_output = True)\n",
      "prod_webservice.deploy (image=model_image_updated)\n",
      "prod_webservice.wait_for_deployment(show_output = True)\n",
      "(accroch√©) prod_webservice.update(image=model_image_updated)\n",
      "prod_webservice.wait_for_deployment(show_output = True)\n",
      "prod_webservice.delete (image=model_image_updated)\n",
      "prod_webservice.wait_for_deployment(show_output = True)\n",
      "Correct\n",
      "This is the correct code for this task.\n",
      "35. You create a machine learning model by using the Azure Machine Learning designer. You publish the model as a real-time service on an Azure Kubernetes Service (AKS) inference compute cluster. You make no change to the deployed endpoint configuration.\n",
      "You need to provide application developers with the information they need to consume the endpoint. Which two values should you provide to application developers? Each correct answer presents part of the solution.\n",
      "The name of the inference pipeline for the endpoint\n",
      "(accroch√©) The key for the endpoint\n",
      "(accroch√©) The URL of the endpoint\n",
      "The name of the AKS cluster where the endpoint is hosted\n",
      "The run ID of the inference pipeline experiment for the endpoint\n",
      "\\section{V√©rifiez vos connaissances}\n",
      "1. Quelle est la diff√©rence entre les mod√®les de r√©gression classique et les mod√®les de classification ?\n",
      "Les mod√®les de r√©gression fournissent des √©tiquettes telles que ¬´ cerise ¬ª/¬´ banane ¬ª, alors que les mod√®les de classification calculent des nombres continus\n",
      "Les mod√®les de classification et les mod√®les de r√©gression lin√©aire sont deux noms d√©signant la m√™me chose.\n",
      "(accroch√©) Les mod√®les de classification fournissent des √©tiquettes telles que ¬´ cerise ¬ª/¬´ banane ¬ª, alors que les mod√®les de r√©gression calculent des nombres continus\n",
      "2. Comment pouvons-nous am√©liorer les performances des mod√®les dans le monde r√©el ?\n",
      "En ajoutant des caract√©ristiques\n",
      "(accroch√©) L‚Äôajout et la suppression de caract√©ristiques peuvent √™tre utiles, en fonction de la situation\n",
      "En supprimant des caract√©ristiques\n",
      "3. Quelle est l‚Äôune des raisons pour lesquelles la r√©gression logistique utilise la perte logarithmique plut√¥t qu‚Äôune fonction de co√ªt plus intuitive ?\n",
      "(accroch√©) La perte logarithmique est plus stricte √† l‚Äô√©gard des erreurs de mod√®le m√™me si elles sont proches de la r√©alit√©.\n",
      "C‚Äôest la seule fa√ßon de calculer l‚Äôerreur pour les √©tiquettes cat√©goriques.\n",
      "La perte logarithmique est plus tol√©rante √† l‚Äô√©gard d‚Äôune erreur de mod√®le si celle-ci est proche de la r√©alit√©.\n",
      "------------------------------------\n",
      "Initiation au D√©tecteur d‚Äôanomalies\n",
      "https://learn.microsoft.com/fr-fr/training/modules/intro-to-anomaly-detector/4a-exercise\n",
      "------------------------------------\n",
      "La d√©tection d‚Äôanomalie est une technique d‚Äôintelligence artificielle utilis√©e pour d√©terminer si les valeurs d‚Äôune s√©rie sont comprises dans les param√®tres attendus.\n",
      "Le D√©tecteur d‚Äôanomalies fait partie de la cat√©gorie Services de d√©cision d‚ÄôAzure Cognitive Services.\n",
      "La limite est d√©finie √† l‚Äôaide d‚Äôune valeur de sensibilit√©. Par d√©faut, la limite sup√©rieure et la limite inf√©rieure de la d√©tection d‚Äôanomalie sont calcul√©es √† l‚Äôaide de concepts nomm√©s expectedValue (valeur attendue), upperMargin (marge haute) et lowerMargin (marge basse). Si une valeur d√©passe l‚Äôune des deux limites, elle est identifi√©e comme une anomalie. Vous pouvez ajuster les limites en appliquant une marginScale √† la marge sup√©rieure et √† la marge inf√©rieure, comme le montre la formule suivante.\n",
      "upperBoundary = expectedValue + (100 ‚Äì marginScale) √ó upperMargin\n",
      "Vous pouvez utiliser toutes les donn√©es num√©riques que vous avez enregistr√©es au fil du temps. Les principaux aspects des donn√©es envoy√©es sont la granularit√©, un horodateur et la valeur enregistr√©e pour cet horodateur.\n",
      "{\n",
      "    \"granularity\": \"hourly\",\n",
      "    \"series\": [\n",
      "      {\n",
      "        \"timestamp\": \"2021-03-01T01:00:00Z\",\n",
      "        \"value\": -10.56\n",
      "      },\n",
      "      {\n",
      "        \"timestamp\": \"2021-03-02T02:00:00Z\",\n",
      "        \"value\": -8.30\n",
      "      },\n",
      "      {\n",
      "        \"timestamp\": \"2021-03-02T03:00:00Z\",\n",
      "        \"value\": -10.30\n",
      "      },\n",
      "      {\n",
      "        \"timestamp\": \"2021-03-02T04:00:00Z\",\n",
      "        \"value\": 5.95\n",
      "      },\n",
      "    ]\n",
      "}\n",
      "Le service prend en charge au maximum 8 640 points de donn√©es.\n",
      "S‚Äôil peut y avoir des valeurs manquantes dans votre s√©quence de donn√©es, tenez compte des recommandations suivantes.\n",
      "    L‚Äô√©chantillonnage se produit √† quelques minutes d‚Äôintervalle, et il manque moins de 10 % du nombre attendu de points. Dans ce cas, l‚Äôimpact devrait √™tre n√©gligeable sur les r√©sultats de la d√©tection.\n",
      "    S‚Äôil manque plus de 10 %, il existe des solutions pour ¬´ remplir ¬ª le jeu de donn√©es. Vous pouvez utiliser une m√©thode d‚Äôinterpolation lin√©aire pour compl√©ter les valeurs manquantes dans le jeu de donn√©es. Elle comble les lacunes avec des valeurs r√©parties uniform√©ment.\n",
      "------------------------------------\n",
      "La d√©tection par lots est mieux utilis√©e lorsque vos donn√©es contiennent les √©l√©ments suivants :\n",
      "    Donn√©es de s√©rie chronologique √† tendance stable affichant des pics ou des creux occasionnels\n",
      "    Donn√©es de s√©rie chronologique saisonni√®re affichant des anomalies occasionnelles\n",
      "        Le caract√®re saisonnier est consid√©r√© comme un pattern dans les donn√©es, qui se produit √† intervalles r√©guliers\n",
      "Il cr√©e un mod√®le en utilisant l‚Äôensemble du jeu de donn√©es, il fait des predictions √† chaque point de donn√©es du jeu de donn√©es nouveaux\n",
      "------------------------------------\n",
      "D√©tection en temps r√©el\n",
      "La d√©tection en temps r√©el utilise des donn√©es de streaming en comparant des points de donn√©es vus pr√©c√©demment au dernier point de donn√©es pour d√©terminer si votre dernier est une anomalie.\n",
      "------------------------------------\n",
      "Cr√©er une ressource D√©tecteur d'anomalies (https://portal.azure.com/)\n",
      "Commen√ßons par cr√©er une ressource D√©tecteur d‚Äôanomalies dans votre abonnement Azure :\n",
      "    Sous un autre onglet de navigateur, ouvrez le portail Azure √† l‚Äôadresse https://portal.azure.com en vous connectant avec votre compte Microsoft.\n",
      "    Cliquez sur le bouton ÔºãCr√©er une ressource, recherchez D√©tecteur d‚Äôanomalies, puis cr√©ez une ressource D√©tecteur d‚Äôanomalies avec les param√®tres suivants :\n",
      "        Abonnement : votre abonnement Azure.\n",
      "        Groupe de ressources : s√©lectionnez un groupe de ressources ou cr√©ez-en un nouveau.\n",
      "        R√©gion : choisissez n‚Äôimporte quelle r√©gion disponible\n",
      "        Nom : entrez un nom unique.\n",
      "        Niveau tarifaire : F0 gratuit\n",
      "    Examinez et cr√©ez la ressource, puis attendez la fin du d√©ploiement. Acc√©dez ensuite √† la ressource d√©ploy√©e.\n",
      "    Affichez la page Cl√©s et point de terminaison de votre ressource D√©tecteur d'anomalies. Vous aurez besoin du point de terminaison et des cl√©s pour vous connecter √† partir d‚Äôapplications clientes.\n",
      "# Lancer le script\n",
      ".\\detect-anomalies.ps1\n",
      "------------------------------------\n",
      "1. Qu‚Äôentend-on par donn√©es saisonni√®res ?\n",
      "Des donn√©es d√©termin√©es en fonction de la date ou de l‚Äôann√©e √† laquelle elles ont √©t√© enregistr√©es.\n",
      "L‚Äô√©cart par d√©faut entre les valeurs pour chaque p√©riode enregistr√©e.\n",
      "(accroch√©) Des donn√©es qui se produisent √† intervalles r√©guliers.\n",
      "Correct. Une s√©rie chronologique saisonni√®re est consid√©r√©e comme un pattern dans les donn√©es, qui se produit √† intervalles r√©guliers (par exemple toutes les heures, tous les jours ou tous les mois).\n",
      "2. √Ä quoi sert-il de sp√©cifier la granularit√© d‚Äôun objet de donn√©es JSON ?\n",
      "(accroch√©) Cela permet d‚Äôindiquer le pattern d‚Äôenregistrement des donn√©es.\n",
      "Correct. La granularit√© est sp√©cifi√©e ainsi : toutes les heures, tous les jours, toutes les semaines, etc.\n",
      "Elle indique au service comment segmenter les r√©sultats retourn√©s pour r√©vision, ind√©pendamment du pattern des donn√©es de s√©rie chronologique.\n",
      "Elle permet d‚Äôindiquer la plage de valeurs acceptables.\n",
      "3. Comment le service D√©tecteur d‚Äôanomalies √©value-t-il la pr√©sence d‚Äôanomalies dans des donn√©es en temps r√©el ?\n",
      "Elle collecte toutes les valeurs dans une fen√™tre de temps et les √©value en une seule fois.\n",
      "(accroch√©) Elle √©value la valeur actuelle par rapport √† la pr√©c√©dente.\n",
      "Correct. Elle √©value les points de donn√©es d√©j√† vus pour d√©terminer si le dernier constitue une anomalie.\n",
      "Elle utilise une interpolation √† partir de la valeur actuelle et de la valeur pr√©c√©dente pour pr√©dire la valeur attendue.\n",
      "------------------------------------\n",
      "1. Qu'est-ce qui est vrai pour les tenseurs ?\n",
      "Les tenseurs sont un type cha√Æne repr√©sentant un vecteur.\n",
      "Les tenseurs sont une valeur math√©matique dans Python pour repr√©senter des coordonn√©es GPS.\n",
      "(accroch√©) Les tenseurs sont des structures de donn√©es sp√©cialis√©es similaires aux tableaux et aux matrices.\n",
      "------------------------------------\n",
      "1. Quelle est la diff√©rence entre un DataSet PyTorch et un DataLoader PyTorch ?\n",
      "Un DataSet est con√ßu pour travailler avec des lots de donn√©es tandis qu'un DataLoader est con√ßu pour r√©cup√©rer des √©l√©ments de donn√©es individuels.\n",
      "Un DataSet est con√ßu pour r√©cup√©rer des √©l√©ments de donn√©es individuels, tandis qu‚Äôun DataLoader est con√ßu pour fonctionner avec des lots de donn√©es.\n",
      "Correct, un DataSet est con√ßu pour r√©cup√©rer des √©l√©ments de donn√©es individuels, tandis qu‚Äôun DataLoader est con√ßu pour fonctionner avec des lots de donn√©es.\n",
      "La classe DataLoader est le parent de DataSet.\n",
      "La classe DataSet est le parent de DataLoader.\n",
      "2. Les transformations dans PyTorch sont con√ßues pour :\n",
      "Effectuer une manipulation des donn√©es pour qu‚Äôelles soient adapt√©es √† l‚Äôapprentissage\n",
      "C‚Äôest correct.\n",
      "Convertir des tenseurs d‚Äôentr√©e en un tenseur de sortie qui contient une pr√©diction\n",
      "Convertir des √©l√©ments de donn√©es en repr√©sentations visuelles\n",
      "------------------------------------\n",
      "1.\n",
      "Quelle est la taille du tenseur pour repr√©senter 2 secondes d‚Äôun clip vid√©o 320x200 √† 30 images par seconde ?\n",
      "30x200x320\n",
      "60x200x320\n",
      "Vous devez prendre en compte les couleurs\n",
      "60x3x200x320\n",
      "Tr√®s bien !\n",
      "2x200x320\n",
      "------------------------------------\n",
      "1. Vous souhaitez effectuer l‚Äôapprentissage d‚Äôun mod√®le de classification du diab√®te avec la biblioth√®que scikit-learn. Vous voulez vous concentrer sur l‚Äôexp√©rimentation du mod√®le et r√©duire l‚Äôeffort n√©cessaire pour journaliser les r√©sultats du mod√®le. Quelle m√©thode de journalisation devez-vous utiliser ?\n",
      "Journalisation automatique\n",
      "Correct. Vous pouvez utiliser la journalisation automatique avec scikit-learn. La journalisation automatique permet de r√©duire l‚Äôeffort n√©cessaire pour journaliser les r√©sultats du mod√®le.\n",
      "Journalisation personnalis√©e\n",
      "Combinaison de la journalisation automatique et de la journalisation personnalis√©e.\n",
      "2. Lorsque vous utilisez le suivi MLflow pour l‚Äôapprentissage d‚Äôun mod√®le dans un notebook ex√©cut√© sur le calcul Azure Machine Learning, sous quel onglet du studio pouvez-vous consulter les r√©sultats du mod√®le ?\n",
      "Donn√©es\n",
      "Mod√®les\n",
      "Incorrect. L‚Äôonglet Mod√®les indique les mod√®les inscrits.\n",
      "travaux\n",
      "Correct. Les travaux affichent les ex√©cutions de l‚Äôexp√©rience MLflow, y compris toutes les m√©tadonn√©es et tous les param√®tres, m√©triques et artefacts journalis√©s.\n",
      "1.\n",
      "Vous envisagez de cr√©er une application qui utilise le service Speech pour transcrire les enregistrements audio d‚Äôappels t√©l√©phoniques en texte, puis envoie le texte transcrit au service de langage pour en extraire les phrases cl√©s. Vous souhaitez g√©rer l‚Äôacc√®s et la facturation des services d‚Äôapplication dans une seule ressource Azure. Quel type de ressource Azure devez-vous cr√©er ?\n",
      "Speech\n",
      "Incorrect. Cette ressource prend en charge la transcription vocale, mais pas l‚Äôextraction de phrases cl√©s.\n",
      "Langage\n",
      "Cognitive Services\n",
      "Correct. Cette ressource prend en charge √† la fois les services Speech et les services de langage.\n",
      "2.\n",
      "Vous voulez utiliser le service Speech pour cr√©er une application qui lit l‚Äôobjet des e-mails entrants √† voix haute. Quelle API devez-vous utiliser ?\n",
      "Reconnaissance vocale\n",
      "Synth√®se vocale\n",
      "Correct. L‚ÄôAPI Synth√®se vocale convertit le texte en parole audible.\n",
      "Traduction\n",
      "1.\n",
      "Qu‚Äôest-ce qu‚Äôun r√©seau neuronal ?\n",
      "Un syst√®me informatique con√ßu d‚Äôapr√®s le cerveau et le syst√®me nerveux humain.\n",
      "Correct ! Un r√©seau neuronal est un syst√®me informatique con√ßu d‚Äôapr√®s le cerveau et le syst√®me nerveux humain.\n",
      "Un syst√®me complexe de serveurs informatiques interconnect√©s.\n",
      "Un bundle de logiciels install√©s sur un ordinateur.\n",
      "2.\n",
      "√Ä quoi fait r√©f√©rence la pr√©cision dans un mod√®le d‚Äôintelligence artificielle ?\n",
      "Au pourcentage de temps durant lequel un mod√®le a effectu√© une pr√©diction incorrecte.\n",
      "Au pourcentage de temps durant lequel le mod√®le a effectu√© une pr√©diction correcte.\n",
      "Correct ! Dans ce contexte, la pr√©cision fait r√©f√©rence √† la fr√©quence √† laquelle le mod√®le a effectu√© des pr√©dictions correctes.\n",
      "Au nombre d‚Äôimages dont vous avez besoin pour effectuer l‚Äôapprentissage du mod√®le afin qu‚Äôil soit parfait.\n",
      "3.\n",
      "Comment pouvez-vous augmenter la pr√©cision d‚Äôun mod√®le d‚Äôintelligence artificielle ?\n",
      "En entra√Ænant le mod√®le cinq fois de plus.\n",
      "En r√©duisant le nombre d‚Äô√©poques.\n",
      "En ajoutant des images suppl√©mentaires et en augmentant le nombre d‚Äô√©poques.\n",
      "Bonne r√©ponse ! Vous pouvez augmenter la justesse d‚Äôun mod√®le d‚Äôintelligence artificielle en ajoutant des images et des √©poques lors de l‚Äôentra√Ænement du mod√®le.\n",
      "1.\n",
      "Pourquoi avons-nous choisi un arbre de d√©cision pour notre algorithme Machine Learning ?\n",
      "Un arbre de d√©cision est l‚Äôalgorithme le plus complexe et le plus pr√©cis.\n",
      "Un arbre de d√©cision est facile √† visualiser. C‚Äôest bien parce que le mod√®le ne peut effectuer que deux options : oui ou non.\n",
      "Correct ! Nous avons choisi un arbre de d√©cision, car un arbre de d√©cision est facile √† visualiser. Il est facile √† utiliser car le mod√®le n‚Äôa que deux choix.\n",
      "Un arbre de d√©cision poss√®de un grand nombre de branches, et le mod√®le peut faire de nombreux choix.\n",
      "2.\n",
      "Quel est l‚Äôint√©r√™t de diviser votre jeu de donn√©es ?\n",
      "Rendre le mod√®le plus juste en √©liminant les donn√©es incorrectes\n",
      "Tester diff√©rents algorithmes avec diff√©rentes donn√©es\n",
      "Disposer de donn√©es diff√©rentes pour l‚Äôentra√Ænement et pour le test de votre mod√®le\n",
      "Bonne r√©ponse ! Si vous entra√Ænez et testez votre mod√®le Machine Learning avec les m√™mes donn√©es, il sera seulement capable de vous indiquer les donn√©es dont vous disposez. Il ne permettra pas d‚Äôobtenir des pr√©dictions justes.\n",
      "------------------------------------\n",
      "1.\n",
      "Vous envisagez de cr√©er un espace de travail Azure Databricks et d‚Äôutiliser la vue de l‚Äôentit√© SQL dans le portail Azure Databricks. Parmi les niveaux tarifaires suivants, lequel pouvez-vous s√©lectionner ?\n",
      "Enterprise\n",
      "Incorrect. Il n‚Äôexiste aucun niveau Entreprise pour Azure Databricks.\n",
      "Standard\n",
      "Premium\n",
      "Correct. Le niveau Premium est requis pour l‚Äôentit√© SQL.\n",
      "2.\n",
      "Vous devez utiliser Spark pour traiter des donn√©es dans des fichiers, en les pr√©parant pour l‚Äôanalyse. Quelle vue d‚Äôentit√© devez-vous utiliser dans le portail Azure Databricks ?\n",
      "Science des donn√©es et engineering donn√©es\n",
      "Correct. L‚Äôentit√© Science des donn√©es et d‚Äôengineering donn√©es est optimis√©e pour faciliter les t√¢ches d‚Äôengineering donn√©es telles que le traitement des donn√©es.\n",
      "Machine learning\n",
      "SQL\n",
      "3.\n",
      "Vous avez cr√©√© un espace de travail Azure Databricks dans lequel vous pr√©voyez d‚Äôutiliser du code dans des notebooks pour traiter les donn√©es. Que devez-vous cr√©er dans l‚Äôespace de travail ?\n",
      "Un entrep√¥t SQL\n",
      "Incorrect. Un entrep√¥t SQL est utilis√© pour interroger des donn√©es dans des tables.\n",
      "Un cluster Spark\n",
      "Correct. Un cluster Spark est n√©cessaire pour traiter les donn√©es en utilisant du code dans les notebooks.\n",
      "Une machine virtuelle Windows Server\n",
      "1.\n",
      "Vous souhaitez ins√©rer des donn√©es de la table Store.Product dans une table existante nomm√©e Sales.Offer. Quelle instruction devez-vous utiliser ?\n",
      "INSERT INTO Sales.Offer SELECT ProductID, Name, Price*0.9 FROM Store.Product;\n",
      "Correct. Utilisez l‚Äôinstruction INSERT ... SELECT pour ins√©rer les r√©sultats d‚Äôune requ√™te dans une table existante.\n",
      "SELECT ProductID, Name, Price*0.9 FROM Store.Product INTO Sales.Offer;\n",
      "INSERT INTO Sales.Offer (ProductID, Name, Price*0.9) VALUES (Store.Product);\n",
      "2.\n",
      "Vous devez d√©terminer la colonne IDENTITY la plus r√©cemment ins√©r√©e dans la table Sales.Invoice. Quelle instruction devez-vous utiliser ?\n",
      "SELECT SCOPE_IDENTITY() FROM Sales.Invoice;\n",
      "Incorrect. Utilisez IDENT_CURRENT pour trouver la valeur d‚Äôidentit√© actuelle d‚Äôune table sp√©cifique.\n",
      "SELECT IDENT_CURRENT(‚ÄôSales.Invoice‚Äô);\n",
      "Correct. Utilisez IDENT_CURRENT pour trouver la valeur d‚Äôidentit√© actuelle d‚Äôune table sp√©cifique.\n",
      "SELECT NEXT VALUE FOR Sales.Invoice;\n",
      "3.\n",
      "Vous devez augmenter de 10 % le prix de tous les produits de la cat√©gorie 2. Quelle instruction devez-vous utiliser ?\n",
      "UPDATE Store.Product SET Price = Price * 1.1, Category = 2;\n",
      "Incorrect. Utilisez UPDATE avec une clause WHERE pour mettre √† jour des lignes sp√©cifiques.\n",
      "UPDATE Store.Product SET Price = Price * 1.1 WHERE Category = 2;\n",
      "Correct. Utilisez UPDATE avec une clause WHERE pour mettre √† jour des lignes sp√©cifiques.\n",
      "SELECT Price * 1.1 INTO Store.Product FROM Store.Product WHERE Category = 2;\n",
      "1.\n",
      "Si les machines Windows et Linux acc√®dent √† un volume Azure NetApp Files, quelle est la meilleure option de protocole de fichier √† attribuer au volume ?\n",
      "NFSv4\n",
      "SMB3\n",
      "Incorrect. Les machines Windows peuvent uniquement acc√©der aux volumes Azure NetApp Files qui utilisent le protocole SMB3. Toutefois, le montage de volumes SMB dans Linux n√©cessite une configuration plus pouss√©e.\n",
      "NFSv3 et SMB3\n",
      "Correct. Azure NetApp Files prend en charge la cr√©ation de volumes qui utilisent NFSv3 et SMB3 simultan√©ment. Cette capacit√© permet aux machines Linux et Windows de monter le volume sans configuration suppl√©mentaire.\n",
      "2.\n",
      "Une application d‚Äôentreprise demande un d√©bit de 128 Mio/s et une taille de volume de 2 Tio. Quel niveau de service Azure NetApp Files doit √™tre s√©lectionn√© lors de la cr√©ation du pool de capacit√©s, en supposant que le pool utilise une QoS automatique ?\n",
      "Premium\n",
      "Correct. Le niveau Premium fournit jusqu‚Äô√† 64 Mio/s de d√©bit par Tio de capacit√© provisionn√©e. Ainsi, le provisionnement de 2 Tio pour le volume offre un d√©bit pouvant atteindre 128 Mio/s.\n",
      "Ultra\n",
      "Standard\n",
      "Incorrect. Le niveau Standard fournit un d√©bit allant jusqu‚Äô√† 16 Mio/s pour 1 Tio de capacit√© provisionn√©e. Ainsi, le provisionnement de 2 Tio pour le volume offre un d√©bit pouvant atteindre 32 Mio/s, soit moins que n√©cessaire.\n",
      "3.\n",
      "Supposons qu‚Äôun administrateur VDI qui est responsable de milliers de bureaux virtuels travaille sur une infrastructure. La possibilit√© de restaurer n‚Äôimporte quel profil utilisateur √† une configuration ant√©rieure constitue un point cl√© pour l‚Äôinfrastructure. Cette fonctionnalit√© est utile pour r√©soudre les probl√®mes. L‚Äôinfrastructure doit √©galement √™tre en mesure de r√©tablir un volume entier √† un √©tat ant√©rieur, ce qui peut aider l‚Äôentreprise √† surmonter une attaque par ransomware. Laquelle des fonctionnalit√©s Azure NetApp Files suivantes pouvez-vous utiliser √† cette fin ?\n",
      "Qualit√© de service\n",
      "NetApp Cloud Sync\n",
      "Instantan√©s\n",
      "Correct. Un instantan√© est une image √† un point dans le temps d‚Äôun volume qui vous permet de restaurer des fichiers et des r√©pertoires dans un √©tat ant√©rieur et de r√©tablir l‚Äôensemble du volume √† une configuration ant√©rieure.\n",
      "4.\n",
      "Supposons qu‚Äôun administrateur informatique a √©t√© invit√© √† √©tudier la viabilit√© du d√©placement des applications d‚Äôentreprise de la soci√©t√© vers Azure et de l‚Äôutilisation d‚ÄôAzure NetApp Files pour le stockage partag√© des applications. La contrainte principale √† laquelle il est confront√© est un budget minimal pour effectuer la migration r√©elle. En raison de cette contrainte, la migration doit √™tre effectu√©e avec peu ou pas de modifications du code, des donn√©es ou de la configuration de l‚Äôapplication. Parmi les options suivantes, laquelle d√©crit le mieux ce type de migration ?\n",
      "Latence faible\n",
      "Incorrect. La latence est le temps n√©cessaire pour acc√©der √† un emplacement de stockage sp√©cifique et n‚Äôa rien √† voir avec la migration de charges de travail vers le cloud.\n",
      "Migration lift-and-shift\n",
      "Correct. Une migration ¬´ lift-and-shift ¬ª vous permet de faire passer votre charge de travail dans le cloud sans avoir √† changer les composants, la configuration ou le code de votre application.\n",
      "D√©l√©gation de sous-r√©seau\n",
      "5.\n",
      "Supposons qu‚Äôun administrateur √©value Azure NetApp Files en tant que solution de stockage partag√©. Parmi les options suivantes, laquelle d√©crit le mieux un sc√©nario dans lequel il d√©conseille d‚Äôutiliser Azure NetApp Files ?\n",
      "Une charge de travail √† petite √©chelle et √† basses performances qui se compose principalement de contenu statique avec une demande relativement constante\n",
      "Correct. Azure NetApp Files n‚Äôest pas id√©al pour les petites charges de travail statiques. Azure NetApp Files convient pour les charges de travail √† grande √©chelle et hautes performances avec un contenu et une demande √©lastiques.\n",
      "Une application de simulation de calcul hautes performances n√©cessitant peu d‚ÄôIOPS et une latence faible\n",
      "Incorrect. Azure NetApp Files prend en charge jusqu‚Äô√† 450 000 IOPS et une latence inf√©rieure √† la milliseconde. Il est donc id√©al pour ce type d‚Äôapplication.\n",
      "Un d√©ploiement de Microsoft SQL Server massif\n",
      "1.\n",
      "Vous avez √©t√© invit√© √† choisir le r√©seau que vous souhaitez d√©ployer pour votre application. Lesquelles des consid√©rations suivantes sont valables :\n",
      "(accroche√©) Vous choisissez la 5G, car vous avez besoin d‚Äôune latence tr√®s faible.\n",
      "La 5G avec le syst√®me MEC priv√© Azure offre une faible latence pour les applications.\n",
      "Vous choisissez la technologie Wi-Fi, car vous avez besoin d‚Äôune faible latence.\n",
      "Vous choisissez la 5G, car elle est utilisable dans tous les cas.\n",
      "M√™me lorsque la 5G est enti√®rement d√©ploy√©e, plusieurs types de r√©seau sont cens√©s coexister.\n",
      "2.\n",
      "Votre entreprise a d√©cid√© d‚Äôadopter la technologie 5G pour IoT. Quels sont les avantages de l‚Äôutilisation du syst√®me MEC priv√© Azure pour la 5G ?\n",
      "Le syst√®me MEC priv√© Azure peut √™tre utilis√© pour la voix et les donn√©es.\n",
      "Le syst√®me MEC priv√© Azure peut √™tre utilis√© pour les applications complexes comme les voitures autonomes.\n",
      "(accroche√©) Le syst√®me MEC priv√© d‚ÄôAzure regroupe un portefeuille de services de Microsoft afin d‚Äôimpl√©menter des technologies 5G dans l‚Äôentreprise.\n",
      "Il r√©unit un portefeuille de services qui vous aident √† d√©ployer un service 5G de bout en bout.\n",
      "3.\n",
      "Vous souhaitez d√©ployer la technologie 5G dans un stade o√π la couverture du signal doit √™tre possible pour un grand nombre de capteurs. Quelle caract√©ristique de la 5G serait la plus appropri√©e ici ?\n",
      "La 5G est s√©curis√©e.\n",
      "La 5G est rapide.\n",
      "La vitesse n‚Äôest pas directement pertinente pour la couverture du signal.\n",
      "(accroche√©) La 5G permet une densit√© de capteurs √©lev√©e.\n",
      "La 5G permet une densit√© des capteurs √©lev√©e dans une zone g√©ographique.\n",
      "1.\n",
      "Lorsque l‚Äôon combine la sortie de deux ensembles, comment les op√©rateurs UNION et UNION ALL traitent-ils les valeurs NULL ?\n",
      "Les lignes qui contiennent des valeurs NULL ne sont pas retourn√©es, car les valeurs NULL ne peuvent pas √™tre compar√©es.\n",
      "Incorrect. Les op√©rateurs UNION et UNION ALL retournent les lignes qui contiennent des valeurs NULL.\n",
      "Les valeurs NULL repr√©sentent des valeurs inconnues, qui ne peuvent pas √™tre compar√©es. Les op√©rateurs UNION et UNION ALL retournent une erreur si les ensembles contiennent des valeurs NULL.\n",
      "Une valeur NULL d‚Äôun ensemble est trait√©e comme √©tant √©gale √† une valeur NULL d‚Äôun autre ensemble.\n",
      "Correct. Les valeurs NULL sont compar√©es et trait√©es comme des doublons si elles apparaissent dans les deux ensembles.\n",
      "2.\n",
      "Il existe des jeux de r√©sultats de requ√™te employ√© et client, qui contiennent tous deux des colonnes ID (int) et pays/r√©gion (nvarchar(20)). Quelqu‚Äôun souhaite retourner la liste des pays/r√©gions qui apparaissent dans les deux jeux de r√©sultats. Quel op√©rateur d‚Äôensemble doit-il utiliser ?\n",
      "EXCEPT\n",
      "INTERSECT\n",
      "Correct. L‚Äôop√©rateur d‚Äôensemble INTERSECT retourne les lignes qui se trouvent dans les deux jeux de r√©sultats.\n",
      "OUTER APPLY\n",
      "3.\n",
      "Quel type de r√©sultat l‚Äôop√©rateur APPLY retourne-t-il ?\n",
      "Table\n",
      "Correct. APPLY retourne un r√©sultat table plut√¥t qu‚Äôun r√©sultat scalaire ou multivaleur.\n",
      "Scalaire\n",
      "Agr√©gat\n",
      "1.\n",
      "Parmi les commandes Azure Cloud Shell/Azure CLI suivantes, laquelle permet de cr√©er un compte Stockage Azure ?\n",
      "az group create\n",
      "az account create\n",
      "az storage account create\n",
      "Correct ! Cette commande cr√©e un compte de stockage.\n",
      "az storage create\n",
      "2.\n",
      "Quelle est la diff√©rence entre la pr√©cision et le rappel quand vous mesurez la justesse d‚Äôun mod√®le Machine Learning ?\n",
      "La pr√©cision mesure approximativement les faux positifs. La pr√©cision mesure approximativement les faux n√©gatifs.\n",
      "Correct ! Techniquement, la pr√©cision correspond au (nombre de vrais positifs)/(nombre de vrais positifs + nombre de faux positifs), et le rappel correspond au (nombre de vrais positifs)/(nombre de vrais positifs + nombre de faux n√©gatifs).\n",
      "La pr√©cision mesure approximativement les faux n√©gatifs. La pr√©cision mesure approximativement les faux positifs.\n",
      "La pr√©cision correspond √† la moyenne des taux de faux positifs calcul√©s dans une plage de seuils.\n",
      "Le rappel correspond √† la moyenne des taux de faux positifs calcul√©s dans une plage de seuils.\n",
      "Incorrect. La pr√©cision et le rappel sont un peu plus simples que cela.\n",
      "3.\n",
      "Lorsque vous d√©ployez une application de fonction, pourquoi est-il pr√©f√©rable de choisir le plan App Service plut√¥t que le plan Consommation ?\n",
      "Les applications de fonction qui sont h√©berg√©es dans un plan App Service prennent en charge l‚Äôex√©cution en parall√®le. Les applications de fonction qui sont h√©berg√©es dans le plan Consommation ne prennent pas en charge l‚Äôex√©cution en parall√®le.\n",
      "Les plans App Service qui h√©bergent des applications dans Azure Functions ne sont pas factur√©s.\n",
      "Les fonctions qui sont h√©berg√©es dans un plan App Service sont factur√©es uniquement quand elles sont ex√©cut√©es.\n",
      "Incorrect. En fait, cet √©nonc√© s‚Äôapplique au mod√®le Consommation. Le mod√®le App Service ex√©cute continuellement une instance de calcul pour prendre en charge vos applications de fonction.\n",
      "Les applications de fonction qui sont h√©berg√©es dans un plan App Service s‚Äôex√©cutent d√®s qu‚Äôelles sont d√©clench√©es.\n",
      "Correct. Lors de l‚Äôutilisation du mod√®le Consommation, il peut s‚Äôav√©rer n√©cessaire de faire tourner une machine pendant quelques minutes en vue d‚Äôex√©cuter votre fonction d√®s son d√©clenchement. Avec le plan App Service, l‚Äôapplication de fonction s‚Äôex√©cute imm√©diatement.\n",
      "4.\n",
      "Quand vous d√©ployez une base de donn√©es SQL dans Azure SQL Database, pourquoi faut-il ajouter une adresse IP client √† la strat√©gie de s√©curit√© ?\n",
      "Pour permettre √† d‚Äôautres services Azure de se connecter √† la base de donn√©es SQL.\n",
      "Pour permettre aux applications s‚Äôex√©cutant sur votre ordinateur de se connecter √† la base de donn√©es\n",
      "Correct ! Votre adresse IP client est l‚Äôadresse IP de votre propre ordinateur. Le fait de l‚Äôajouter aux r√®gles de s√©curit√© de la base de donn√©es permet √† votre ordinateur de s‚Äôy connecter.\n",
      "Pour permettre √† Microsoft de conna√Ætre l‚Äôadresse IP de votre ordinateur dans le cadre des mises √† jour Windows.\n",
      "5.\n",
      "Sur quels syst√®mes d‚Äôexploitation Power BI Desktop s‚Äôex√©cute-t-il ?\n",
      "Windows uniquement\n",
      "Correct ! Power BI Desktop s‚Äôex√©cute uniquement sur Windows, mais vous pouvez consulter des rapports Power BI sur n‚Äôimporte quelle plateforme.\n",
      "Windows et macOS\n",
      "Windows, macOS et Linux\n",
      "Incorrect. Power BI Desktop s‚Äôex√©cute uniquement sur Windows, mais vous pouvez consulter des rapports Power BI sur n‚Äôimporte quelle plateforme.\n",
      "macOS et Linux\n",
      "1.\n",
      "Qu‚Äôest-il n√©cessaire de sp√©cifier avec la fonction RANK ?\n",
      "PARTITION BY\n",
      "CURRENT ROW\n",
      "ORDER BY\n",
      "Correct. ORDER BY doit √™tre sp√©cifi√© avec la fonction RANK.\n",
      "2.\n",
      "Dans quel ordre les mots cl√©s ROW, OVER et PARTITION BY se produisent-ils dans une requ√™te ?\n",
      "PARTITION BY, OVER, ROW\n",
      "Ce n‚Äôest pas correct. OVER est la clause. PARTITION BY et ROW ou RANGE sont les arguments.\n",
      "ROW, OVER, PARTITION BY\n",
      "OVER PARTITION BY, ROW\n",
      "Correct. OVER est la clause. PARTITION BY et ROW ou RANGE sont les arguments.\n",
      "3.\n",
      "Quel type de fonction de fen√™tre est PERCENT_RANK() ?\n",
      "Fonction analytique\n",
      "1.\n",
      "Quel est l‚Äôobjectif de l‚Äôentra√Ænement d‚Äôun mod√®le ?\n",
      "L‚Äôobjectif est de le rendre plus rapide.\n",
      "L‚Äôobjectif est de trouver les param√®tres W et B qui donneront la meilleure pr√©diction.\n",
      "Correct !\n",
      "L‚Äôobjectif est de trouver le meilleur optimiseur et la meilleure fonction de perte pour nos besoins.\n",
      "L‚Äôobjectif est de classifier chacun des exemples d‚Äôentr√©e.\n",
      "Correct. PERCENT_RANK est similaire √† la fonction CUME_DIST. Elle est class√©e comme √©tant une fonction analytique.\n",
      "Fonction de classement\n",
      "Fonction d‚Äôagr√©gation\n",
      "------------------------------------\n",
      "1.\n",
      "Lors de l‚Äôentra√Ænement de la t√¢che de classification d‚Äôimages sur les images avec la forme 32x32x3, quelle forme est l‚Äôentr√©e pour la couche neuronale Dense ?\n",
      "32x32x3\n",
      "1 024\n",
      "La dimension du tenseur d‚Äôentr√©e doit correspondre au nombre d‚Äôentr√©es disponibles, par exemple 32323\n",
      "3 072\n",
      "Correct, le tenseur d‚Äôentr√©e est juste aplati en un vecteur\n",
      "2.\n",
      "Notre jeu de donn√©es contient des images de taille 32x32x3. Que devrions-nous faire pour entra√Æner un r√©seau neuronal Dense sur ces images ?\n",
      "Utiliser la couche Flatten comme premi√®re couche du r√©seau pour reformer les images\n",
      "Changer la forme des √©l√©ments du jeu de donn√©es d‚Äôentra√Ænement pour qu‚Äôils soient des vecteurs de longueur 3072 et utiliser un r√©seau Dense d‚Äôune seule couche\n",
      "N‚Äôimporte laquelle des solutions ci-dessus fonctionnera\n",
      "Correct, ces deux solutions sont valides.\n",
      "3.\n",
      "Nous souhaitons surveiller la justesse du mod√®le sur le jeu de donn√©es de validation au cours de l‚Äôentra√Ænement. Que devons-nous faire ?\n",
      "Sp√©cifier metrics=['acc'] dans un appel √† model.compile\n",
      "Sp√©cifier metrics=['acc'] dans un appel √† model.fit\n",
      "Fournir un jeu de donn√©es de validation avec le param√®tre validation_data dans model.fit\n",
      "Ce n‚Äôest pas tout\n",
      "Options (a) et (c)\n",
      "Correct, vous devez vous assurer que la m√©trique est sp√©cifi√©e et que le jeu de donn√©es de validation est fourni\n",
      "Options (b) et (c)\n",
      "------------------------------------\n",
      "1.\n",
      "Vous disposez d‚Äôune trame de donn√©es ou d‚Äôun tibble, avec la dimension 20, 2. Qu‚Äôest-ce que cela vous dit √† son sujet ?\n",
      "Le tibble est compos√© de 20 lignes et de 2 colonnes.\n",
      "Correct ! Une dimension de 20, 2 signifie que le tibble a 2 colonnes, chacune avec 20 √©l√©ments. Cela lui donne une structure rectangulaire de 20 lignes et 2 colonnes.\n",
      "Le tibble contient 2 colonnes, avec les valeurs 2 et 20.\n",
      "Le tibble contient 20 lignes, toutes avec la valeur 2.\n",
      "2.\n",
      "Vous disposez d‚Äôune trame de donn√©es nomm√©e df_sales, qui contient des donn√©es de ventes quotidiennes. La trame de donn√©es affiche les colonnes year, month, day_of_month et sales_total. Vous souhaitez trouver la valeur moyenne de sales_total. Quel code devez-vous utiliser ?\n",
      "df_sales %>% pull(sales_total) %>% avg()\n",
      "mean(sales_total$df_sales)\n",
      "mean(df_sales$sales_total)\n",
      "Correct ! L‚Äôaccesseur ($) extrait les √©l√©ments de la colonne sales_total de la trame de donn√©es df_sales. Les √©l√©ments sont ensuite transmis √† la fonction mean(), qui calcule la moyenne.\n",
      "3.\n",
      "Vous disposez d‚Äôune trame de donn√©es qui affiche des donn√©es sur les ventes quotidiennes de cr√®me glac√©e. Vous utilisez la fonction cor de R pour comparer les colonnes avg_temp et units_sold, et obtenez un r√©sultat de 0,97. Qu‚Äôest-ce que ce r√©sultat indique ?\n",
      "Le jour o√π la valeur maximale de units_sold a √©t√© atteinte, la valeur de avg_temp √©tait de 0,97.\n",
      "Les jours avec des valeurs avg_temp √©lev√©es ont tendance √† co√Øncider avec les jours o√π les valeurs de units_sold sont √©galement √©lev√©es.\n",
      "Correct ! La fonction cor retourne la corr√©lation et une valeur proche de 1 indique une corr√©lation positive.\n",
      "La valeur units_sold est, en moyenne, √©gale √† 97 pour cent de la valeur avg_temp.\n",
      "------------------------------------\n",
      "Qu'est-ce qui se trouve sont sur les axes x et y d'un trac√© ROC?\n",
      "(accroch√©) axe des x : taux FP, axe des y : taux TP\n",
      "axe des x : nombre de FP, axes dees y : nombre de TP\n",
      "axe des x : nombre de TP, axes dees y : nombre de FP\n",
      "------------------------------------\n",
      "Qu'est-ce que la zone sous la courbe pour un trac√© ROC nous indique?\n",
      "Le fonctionnement du modele √† son seuil de d√©cision optimal\n",
      "Quel est le seuil de d√©cision optimal?\n",
      "(accroche) Elle fournit un r√©sum√© sur la fa√ßon dont on modele fonctionne sur\n",
      "------------------------------------\n",
      "Les r√©sultats de l'API OCR se d√©composent par r√©gion, par ligne, puis par mot, tandis que les r√©sultants de l'API Read sont d√©compos√©s par page, ligne, puis mot.\n",
      "------------------------------------\n",
      "La classe de base pour tous les modules de r√©seau neuronal dans PyTorch est torch.nn.Module\n",
      "(accroche) Vrai\n",
      "Faux\n",
      "------------------------------------\n",
      "Vous devez r√©g√©n√©r la cl√© d'abonnement principle pour une ressource Cognitive Services utilis√©e par une application. Que devez-vous faire en premier pour √©viter les interruptions de service de l'application?\n",
      "(accrocher) Modifier l'application pour qu'elle utilise la cl√© secondaire\n",
      "Modifier le point de terminaison de la ressource\n",
      "------------------------------------\n",
      "Vous souhaitez stocker de maniere s√©curis√©e les cl√©s d'abonnement d'une ressource Cognitive Services, afin que les applications autoris√©es puissent les r√©cup√©rer en cas de besoin. Quel type de ressource Azure devez-vous approvisionner?\n",
      "Stockage Azure\n",
      "(accroch√©) Azure Key Vault\n",
      "------------------------------------\n",
      "Azure Databricks offre des types des runtimes:\n",
      "0. Databricks Runtime : comprend Apache Spark, des composants\n",
      "------------------------------------\n",
      "Des services d'Azure:\n",
      "0. Azure App Service : cr√©er vos front-ends des site web\n",
      "1. Azure Functions : cr√©er une logique d'application pilot√©e par les √©v√©nements qui s'ex√©cute uniquement lorsque vous en avez besoin\n",
      "2. Azure Virtual Desktop : fournir rapidement un systeme d'exploitation et un environment logiciel personnalis√©s. Un service de virtualisation des postes de travail et des applications qui s'ex√©cute dans le cloud.\n",
      "Avec l'informatique serverless, Azure g√®re l'infrastructure serveur ainsi que l'allocation et d√©sallocation des resources en fonction de la demande.\n",
      "------------------------------------\n",
      "Vous avez publi√© votre application Conversational Language Understanding. De quelles informations un d√©veloppeur d'applications clientes a besoin pour obenir des pr√©dictions?\n",
      "(accroch√©) Le point de terminaison et la cl√© pour la ressource de pr√©diction de l'application\n",
      "------------------------------------\n",
      "Vous devez provisionner une ressource Azure qui sera utilis√©e pour cr√©er une nouvelle application Language Understanding. Quel type de ressource Azure devez-vous cr√©er?\n",
      "Service de language personnalis√©\n",
      "(accroch√©) Service Language\n",
      "Cognitive Services\n",
      "------------------------------------\n",
      "Vous cr√©ez une application Conversational Language Understanding pour g√©rer une horloge internationale. Vous voulez que les utilisateurs puissent demander l'heure actuelle dans une ville sp√©cifi√©e, par exemple 'Quelle heure est-il √† Londres?'. Que devez-vous faire?\n",
      "(accroch√©) D√©finir une entit√© 'ville' et une intention 'ObtenirHeure' avec des √©nonc√©s qui indiquent l'intention 'ville'\n",
      "------------------------------------\n",
      "Parmi les services suivants, lesquels doivent √™tre utilis√©s quand la principale pr√©occupation est d'effectuer un travail en r√©sponse √† un √©v√©nement (souvent via une command REST) qui necessite une r√©ponse en quelques secondes?\n",
      "(accroch√©) Azure Functions\n",
      "------------------------------------\n",
      "Votre entreprise dispose d'une √©quipe de t√©l√©travailleurs qui doivent utiliser des logiciels Windows pour d√©velopper les appplications de l'entreprise, mais les membres de votre equipe utilisent differents systems d'exploitation tels que macOS, Linux, et Windows. Quel service de calcul Azure peut √™tre utile dans ce sc√©nairo?\n",
      "Azure App Service\n",
      "(accroch√©) Azure Virtual Desktop\n",
      "------------------------------------\n",
      "Quelles sont les ressources de calcul Azure qui peuvent √™tre d√©ploy√©es pour g√©rer un groupe des machines virtuelles identiques?\n",
      "(accroch√©) Groupes identiques de machines virtuelles\n",
      "Groupes √† haute disponibilite de machines virtuelles\n",
      "Zone de disponibilit√©\n",
      "------------------------------------\n",
      "1.\n",
      "Quel outil peut √™tre utilis√© pour la planification agile lors de l‚Äôutilisation d‚ÄôAzure DevOps ?\n",
      "Azure Boards\n",
      "Correct. Utilisez Azure Boards pour le suivi des √©l√©ments de travail, la visualisation et la cr√©ation de rapports.\n",
      "Azure Repos\n",
      "Azure Pipelines\n",
      "2.\n",
      "Quelle activit√© peut faire partie de l‚Äôint√©gration continue ?\n",
      "Supervision\n",
      "V√©rification lint\n",
      "Correct. Avec le linting, vous pouvez v√©rifier les erreurs programmatiques ou stylistiques dans vos scripts.\n",
      "Planification\n",
      "------------------------------------\n",
      "1. Qu‚Äôadvient-il des transactions imbriqu√©es lors de la restauration de la transaction externe ?\n",
      "La transaction interne est ex√©cut√©e.\n",
      "La transaction interne emp√™che la restauration de la transaction externe. Les transactions interne et externe sont ex√©cut√©es.\n",
      "Ce n‚Äôest pas correct. Si la transaction externe est restaur√©e, la transaction interne n‚Äôest pas ex√©cut√©e. La transaction interne n‚Äôemp√™chera pas la restauration de la transaction externe.\n",
      "La transaction interne est √©galement restaur√©e.\n",
      "Correct. Toutes les transactions internes sont restaur√©es lorsque la transaction externe est restaur√©e.\n",
      "2. Lequel des mots cl√©s T-SQL suivants est utilis√© pour contr√¥ler les transactions ?\n",
      "BEGIN TRANSACTION\n",
      "Correct. Les mots cl√©s BEGIN TRANSACTION sont utilis√©s pour d√©marrer une transaction explicite.\n",
      "BEGIN TRY\n",
      "BREAK\n",
      "3. Que teste XACT_STATE ?\n",
      "Indique s‚Äôil existe des transactions imbriqu√©es.\n",
      "√âtat de la requ√™te actuelle.\n",
      "Correct. XACT_STATE teste l‚Äô√©tat de la requ√™te actuelle.\n",
      "Renvoie le num√©ro de l‚Äôerreur qui a provoqu√© l‚Äô√©chec de la transaction.\n",
      "4. Quel est le niveau d‚Äôisolation de transaction par d√©faut pour Azure SQL Database ?\n",
      "READ_COMMITTED_SNAPSHOT_ON\n",
      "Correct. READ_COMMITTED_SNAPSHOT_ON est le niveau d‚Äôisolation de transaction par d√©faut pour Azure SQL Database.\n",
      "READ_COMMITTED_SNAPSHOT_OFF\n",
      "XACT_ABORT\n",
      "------------------------------------\n",
      "1.\n",
      "Quelle est la premi√®re chose qu‚Äôun scientifique des donn√©es doit faire lorsqu‚Äôun √©l√©ment de travail lui est attribu√© pour am√©liorer un mod√®le (qui est d√©j√† en production) ?\n",
      "Cr√©er un d√©p√¥t.\n",
      "Cr√©ez un probl√®me.\n",
      "Cr√©er une branche dans le d√©p√¥t.\n",
      "Correct. En fonction d‚Äôun √©l√©ment de travail ou d‚Äôun probl√®me attribu√©, un scientifique des donn√©es doit cr√©er une branche.\n",
      "2.\n",
      "Quand un scientifique des donn√©es doit-il commiter quand il travaille en local dans Visual Studio Code ?\n",
      "Une fois que toutes les modifications ont √©t√© apport√©es.\n",
      "Apr√®s un petit changement.\n",
      "Correct. Il est recommand√© de commiter de petites modifications et de le faire souvent.\n",
      "Pour charger toutes les modifications apport√©es au d√©p√¥t principal.\n",
      "------------------------------------\n",
      "1.\n",
      "Parmi les √©l√©ments suivants, lequel a √©t√© utilis√© pour cr√©er un m√©canisme de chargement des donn√©es d‚Äôimage dans un compte de stockage Azure en tant que donn√©es blob ?\n",
      "Cr√©ation d‚Äôune table dans le compte de stockage Azure\n",
      "Cr√©ation d‚Äôun conteneur dans le compte de stockage Azure\n",
      "Correct. Un conteneur a √©t√© utilis√© pour charger des donn√©es d‚Äôimage dans un compte de stockage Azure en tant que donn√©es blob.\n",
      "Cr√©ation d‚Äôun partage de fichiers dans le compte de stockage Azure.\n",
      "2.\n",
      "Quel est l‚Äôobjectif de l‚Äôinstance de calcul cr√©√©e dans notre instance Azure Machine Learning Studio ?\n",
      "Pour fournir √† un environnement de d√©veloppement la possibilit√© d‚Äôex√©cuter du code Python et d‚Äôex√©cuter des notebooks Jupyter en direct\n",
      "Correct. L‚Äôinstance de calcul nous permettra de d√©velopper et d‚Äôex√©cuter du code personnalis√© √† partir d‚Äôun ordinateur pr√©configur√© accessible dans le cloud.\n",
      "Pour nous permettre de stocker et de r√©cup√©rer des donn√©es d‚Äôimage √† des fins de formation et de validation\n",
      "Pour permettre la gestion des workflows de Machine Learning\n",
      "3.\n",
      "Quelles valeurs sont requises pour cr√©er un magasin de donn√©es Azure Machine Learning de type Azure Blob Storage ?\n",
      "Uniquement le nom du compte de stockage et le nom du conteneur d‚Äôobjets Blob\n",
      "Incorrect. La cl√© de compte (acc√®s) ou un jeton SAS valide est √©galement requis pour cr√©er un magasin de donn√©es Azure Machine Learning de type Azure Blob Storage.\n",
      "Nom du compte de stockage, nom du partage de fichiers et cl√© du compte (acc√®s).\n",
      "Nom du compte de stockage, nom du conteneur d‚Äôobjets blob et cl√© du compte (acc√®s).\n",
      "Correct. Ces valeurs sont requises pour cr√©er un magasin de donn√©es Azure Machine Learning de type Azure Blob Storage.\n",
      "------------------------------------\n",
      "1.\n",
      "Dans ce module, nos donn√©es d‚Äôimage ont √©t√© r√©f√©renc√©es avec un magasin de donn√©es attach√© √† un...\n",
      "Stockage Blob Azure dans un compte de stockage Azure\n",
      "Correct. Une ressource de Stockage Blob Azure existante a √©t√© r√©f√©renc√©e par notre magasin de donn√©es.\n",
      "Pipeline de donn√©es Azure Synapse Analytics\n",
      "Partage de fichiers dans un compte de stockage Azure.\n",
      "2.\n",
      "L‚Äô√©tiquetage assist√© par ML n‚Äô√©tait pas n√©cessaire dans ce module, quel est son int√©r√™t dans un projet d‚Äô√©tiquetage de donn√©es ?\n",
      "L‚Äô√©tiquetage assist√© par ML cr√©e un mod√®le pouvant pr√©-√©tiqueter les donn√©es dans de nouveaux √©chantillons d‚Äôimages dont l‚Äôexactitude peut √™tre v√©rifi√©e par la suite par les membres de l‚Äô√©quipe.\n",
      "Correct. Cette fonctionnalit√© est un grand avantage qui peut r√©duire la dur√©e d‚Äô√©tiquetage des donn√©es d‚Äôimage dans les nouveaux √©chantillons.\n",
      "L‚Äô√©tiquetage assist√©e par ML peut d√©terminer des objets dans une image √† partir d‚Äôun mod√®le existant qui d√©tecte divers objets communs.\n",
      "Vous permet d‚Äôenvoyer des donn√©es sans √©tiquette pour qu‚Äôelles soient √©tiquet√©es par un service tiers utilisant des personnes pour faire l‚Äô√©tiquetage.\n",
      "Incorrect. Le comportement d√©crit n‚Äôest pas une fonctionnalit√© de l‚Äô√©tiquetage assist√© par ML.\n",
      "3.\n",
      "La raison pour laquelle nous avons √©tiquet√© 10 images dans notre jeu de donn√©es est de r√©pondre aux conditions suivantes :\n",
      "10 est le nombre total d‚Äôimages qui composent notre jeu de donn√©es\n",
      "10 est le nombre maximal d‚Äôimages pouvant √™tre utilis√©es pour entra√Æner un mod√®le de d√©tection d‚Äôobjets.\n",
      "Les exp√©riences de d√©tection d‚Äôobjets Azure ML Studio demandent un minimum de 10 √©chantillons √©tiquet√©s pour r√©ussir √† entra√Æner notre mod√®le de d√©tection d‚Äôobjets\n",
      "Correct. Si nous fournissons moins d‚Äôimages, nous recevons une erreur pendant la tentative d‚Äôentra√Ænement d‚Äôun mod√®le de d√©tection d‚Äôobjets √† partir de notre jeu de donn√©es export√©.\n",
      "1.\n",
      "Le Kit de d√©veloppement logiciel (SDK) Python AzureML nous a permis de nous connecter et d‚Äôinteragir avec notre espace de travail Azure Machine Learning studio par ...\n",
      "Fourniture d‚Äôun fichier config.json qui a sp√©cifi√© les d√©tails √† connecter √† l‚Äôespace de travail appropri√©.\n",
      "Correct. Le fichier config.json a pour valeur subscription_id, resource_group et workspace_name de l‚Äôespace de travail Machine Learning Studio.\n",
      "Fournir une cha√Æne de connexion dans une cellule de connexion dans le bloc-notes Jupyter.\n",
      "Utilisation de nos informations d‚Äôidentification Azure qui ont √©t√© transmises de mani√®re transparente lors de l‚Äôacc√®s au notebook Jupyter.\n",
      "2.\n",
      "Le Kit de d√©veloppement logiciel (SDK) Python AzureML nous a permis de provisionner une instance de calcul dans notre espace de travail Azure Machine Learning Studio. Cette instance peut ensuite √™tre r√©f√©renc√©e dans le code Python pour envoyer des t√¢ches AutoML √† ex√©cuter sur cet ordinateur en tant que cible.\n",
      "Vrai\n",
      "Correct. Le Kit de d√©veloppement logiciel (SDK) Python AzureML peut automatiser diff√©rentes t√¢ches, notamment l‚Äôapprovisionnement d‚Äôune instance de calcul et l‚Äôenvoi d‚Äôexp√©riences.\n",
      "Faux\n",
      "3.\n",
      "Azure AutoML vous permet d‚Äôajuster les hyperparam√®tres pour d√©couvrir automatiquement les param√®tres optimaux de votre mod√®le.\n",
      "Faux\n",
      "Vrai\n",
      "Correct. Azure AutoML peut utiliser des valeurs d‚Äôhyperparam√®tre par d√©faut ou permettre un balayage de diff√©rentes valeurs d‚Äôhyperparam√®tre pour d√©couvrir un param√®tre optimal via l‚Äôit√©ration.\n",
      "1. Supposons qu‚Äôun utilisateur ex√©cute ce script de lot T-SQL pour ins√©rer trois lignes. Apr√®s ex√©cution, il obtient une erreur. Combien de lignes sont cr√©√©es ? INSERT INTO HumanResources.PossibleSkills (SkillName, Category, Credit) VALUES('Database Administration', 'IT Professional', 5);INSERT INTO HumanResources.PossibleSkills (SkillName, Category, Credit) VALUES('C#.NET', 'Developer', 4);INSERT INTO HumanResources.PossibleSkills (SkillName, Category, Credit) VALUES('Project Management', 'Management', 'Two');GO\n",
      "0\n",
      "1\n",
      "(accroche) 2\n",
      "Correct. Deux lignes sont cr√©√©es. Il n‚Äôy a aucune erreur de syntaxe dans ce lot. SQL peut donc commencer √† ex√©cuter l‚Äôinstruction. Les deux premi√®res instructions INSERT sont ex√©cut√©es avant que l‚Äôerreur ne se produise.\n",
      "2. Un utilisateur souhaite remplir une table en cr√©ant 15 lignes suppl√©mentaires. Avant de cr√©er les lignes, il doit v√©rifier que la table existe. Parmi les mots cl√©s T-SQL suivants, lequel doit-il utiliser ?\n",
      "IF\n",
      "Correct. Il utilise l‚Äôinstruction IF pour v√©rifier que la table existe avant de commencer √† ins√©rer les lignes.\n",
      "WHILE\n",
      "INSERT\n",
      "Incorrect. L‚Äôinstruction INSERT est utilis√©e pour ins√©rer les 15 lignes dans la table.\n",
      "3. Une variable peut-elle √™tre d√©clar√©e dans un lot et r√©f√©renc√©e dans plusieurs lots ?\n",
      "Oui\n",
      "Incorrect. Les variables sont locales dans l‚Äô√©tendue du lot o√π elles sont d√©clar√©es.\n",
      "Non\n",
      "Correct. Les variables sont locales dans l‚Äô√©tendue du lot o√π elles sont d√©clar√©es.\n",
      "Parfois\n",
      "------------------------------------\n",
      "1. Un scientifique des donn√©es souhaite exp√©rimenter en effectuant l‚Äôapprentissage d‚Äôun mod√®le Machine Learning et en le suivant avec Azure Machine Learning. Quel outil doit √™tre utilis√© pour effectuer l‚Äôapprentissage du mod√®le en ex√©cutant un script dans son environnement de pr√©dilection ?\n",
      "Azure Machine Learning studio\n",
      "Le kit de d√©veloppement logiciel (SDK) Python.\n",
      "Correct. Le scientifique des donn√©es conna√Æt probablement d√©j√† Python et peut facilement utiliser le kit SDK Python pour ex√©cuter le script d‚Äôapprentissage.\n",
      "l‚Äôinterface de ligne de commande Azure.\n",
      "2. Un mod√®le Machine Learning permettant de pr√©dire les ventes a √©t√© d√©velopp√©. Chaque semaine, de nouvelles donn√©es de ventes sont ing√©r√©es. Le mod√®le doit alors faire l‚Äôobjet d‚Äôun nouvel apprentissage sur les derni√®res donn√©es pour pouvoir g√©n√©rer la nouvelle pr√©vision. Quel outil doit √™tre utilis√© pour effectuer un nouvel apprentissage du mod√®le chaque semaine ?\n",
      "Azure Machine Learning studio\n",
      "Le kit de d√©veloppement logiciel (SDK) Python.\n",
      "Incorrect. Bien que le kit SDK Python puisse √™tre utilis√©, Azure CLI offre davantage d‚Äôoptions pour d√©clencher et automatiser des travaux Azure Machine Learning.\n",
      "l‚Äôinterface de ligne de commande Azure.\n",
      "Correct. L‚Äôinterface Azure CLI est con√ßue pour automatiser les t√¢ches. Si vous utilisez des fichiers YAML pour d√©finir le mode d‚Äôapprentissage du mod√®le, les t√¢ches de Machine Learning s‚Äôav√®rent reproductibles, coh√©rentes et fiables.\n",
      "     \n",
      "------------------------------------\n",
      "1. Un scientifique des donn√©es doit avoir acc√®s √† l‚Äôespace de travail Azure Machine Learning pour ex√©cuter un script en tant que travail. Quel r√¥le doit √™tre utilis√© pour donner au scientifique des donn√©es l‚Äôacc√®s n√©cessaire √† l‚Äôespace de travail ?\n",
      "Lecteur.\n",
      "Scientifique des donn√©es AzureML.\n",
      "Correct. Un scientifique des donn√©es AzureML est autoris√© √† envoyer un travail.\n",
      "Op√©rateur de calcul AzureML.\n",
      "Incorrect. Un scientifique des donn√©es AzureML est autoris√© √† envoyer un travail.\n",
      "2. Le scientifique des donn√©es souhaite ex√©cuter un script unique pour effectuer l‚Äôapprentissage d‚Äôun mod√®le. Quel type de travail est le mieux adapt√© pour ex√©cuter un script unique ?\n",
      "Commande\n",
      "Correct. Un travail de commande permet d‚Äôex√©cuter un script unique.\n",
      "Pipeline\n",
      "Sweep\n",
      "1. Supposons que vous voulez ex√©cuter une appliance r√©seau sur une machine virtuelle. Quelle option de charge de travail devez-vous choisir ?\n",
      "Usage g√©n√©ral\n",
      "Optimis√© pour le calcul\n",
      "Les machines virtuelles optimis√©es pour le calcul sont con√ßues pour avoir un ratio processeur/m√©moire √©lev√©. Convient pour les serveurs web avec un trafic moyen, les appliances r√©seau, les processus de traitement par lots et les serveurs d‚Äôapplication.\n",
      "√Ä m√©moire optimis√©e\n",
      "Optimis√© pour le stockage\n",
      "2. Vrai ou faux : Les mod√®les Resource Manager sont des fichiers JSON ?\n",
      "Vrai\n",
      "Les mod√®les Azure Resource Manager sont des fichiers JSON qui d√©finissent les ressources n√©cessaires au d√©ploiement de votre solution. Le mod√®le peut ensuite √™tre utilis√© pour recr√©er facilement plusieurs versions de votre infrastructure, comme des versions de pr√©production et de production.\n",
      "Faux\n",
      "1.\n",
      "Combien d‚Äôespaces de travail Azure Machine Learning l‚Äô√©quipe doit-elle cr√©er ?\n",
      "Un\n",
      "Correct. Avec une si petite √©quipe, un seul espace de travail suffit.\n",
      "Deux\n",
      "Trois\n",
      "2.\n",
      "Quand devons-nous r√©entra√Æner le mod√®le ?\n",
      "Toutes les semaines.\n",
      "Lorsque les m√©triques du mod√®le sont inf√©rieures au point de r√©f√©rence.\n",
      "Correct. La chose la plus importante est que le mod√®le fonctionne comme pr√©vu. Lorsque les performances du mod√®le sont compromises, nous devons r√©entra√Æner le mod√®le.\n",
      "En cas de d√©rive de donn√©es.\n",
      "Incorrect. Il est indiqu√© que les nouvelles donn√©es ne sont pas consid√©r√©es comme fiables. Actuellement, nous ne devons pas nous appuyer sur la surveillance des donn√©es pour d√©terminer quand r√©entra√Æner le mod√®le.\n",
      "1.\n",
      "Un scientifique des donn√©es souhaite lire les donn√©es stock√©es dans un r√©f√©rentiel GitHub accessible au public. Les donn√©es seront lues dans un notebook Jupyter dans l‚Äôespace de travail Azure Machine Learning pour une exp√©rimentation rapide. Quel protocole doit √™tre utilis√© pour lire les donn√©es dans le notebook ?\n",
      "azureml\n",
      "http(s)\n",
      "Correct. Ce protocole est utilis√© lors de l‚Äôacc√®s aux donn√©es stock√©es dans un emplacement http(s) accessible au public.\n",
      "abfs(s)\n",
      "2.\n",
      "Quel type de ressource de donn√©es un utilisateur doit-il cr√©er lorsque le sch√©ma change fr√©quemment et que les donn√©es sont utilis√©es dans de nombreux travaux diff√©rents ?\n",
      "Fichier URI\n",
      "Dossier URI\n",
      "MLTable\n",
      "Correct. MLTable est id√©al lorsque le sch√©ma change fr√©quemment. Ensuite, il vous suffit d‚Äôapporter des modifications dans un seul emplacement au lieu de plusieurs.\n",
      "1.\n",
      "Un scientifique des donn√©es souhaite effectuer l'apprentissage d‚Äôun mod√®le Machine Learning pour pr√©dire les ventes d‚Äôarticles de supermarch√© afin d‚Äôajuster l‚Äôoffre √† la demande projet√©e. Quel type de t√¢che Machine Learning le mod√®le effectuera-t-il ?\n",
      "Classification.\n",
      "r√©gression ;\n",
      "Incorrect. La r√©gression pr√©dit une valeur num√©rique.\n",
      "Pr√©vision de s√©rie chronologique\n",
      "Correct. La pr√©vision de s√©ries chronologiques est utilis√©e pour pr√©dire les ventes futures.\n",
      "2.\n",
      "Le scientifique des donn√©es a re√ßu des donn√©es pour effectuer l'apprentissage d‚Äôun mod√®le afin de pr√©dire les ventes d‚Äôarticles de supermarch√©. Le scientifique des donn√©es souhaite it√©rer rapidement sur plusieurs options de caract√©risation et d‚Äôalgorithmes en fournissant uniquement les donn√©es et en modifiant certaines configurations. Quel outil serait le mieux utilis√© dans cette situation ?\n",
      "Concepteur\n",
      "Machine Learning automatis√©\n",
      "Correct. Vous n‚Äôaurez qu‚Äô√† fournir les donn√©es et le Machine Learning automatis√© it√©rera sur diff√©rents algorithmes et approches de caract√©risation.\n",
      "Cognitive Services\n",
      "1.\n",
      "Pour d√©clencher un pipeline Azure Machine Learning avec l‚Äôinterface CLI (v2), un ing√©nieur Machine Learning utilise GitHub Actions. Dans quel r√©pertoire le workflow doit-il √™tre stock√© ?\n",
      ".github/workflows/\n",
      "Correct. GitHub reconna√Æt les workflows de ce r√©pertoire √† utiliser pour des actions.\n",
      ".gitignore/\n",
      ".pipelines/\n",
      "Incorrect. Stockez les fichiers YAML pour Azure Pipelines dans ce r√©pertoire lorsque vous utilisez Azure DevOps.\n",
      "2.\n",
      "Un pipeline Azure Machine Learning pour entra√Æner un mod√®le est d√©clench√© avec Azure Pipelines. Tous les travaux dans Azure Pipelines ont √©t√© correctement ex√©cut√©s, mais aucun nouveau mod√®le n‚Äôest trouv√© dans les sorties sp√©cifi√©es. O√π le scientifique des donn√©es doit-il aller pour trouver le message d‚Äôerreur ?\n",
      "Onglet Pipelines dans Azure DevOps.\n",
      "Onglet Exp√©riences dans Azure Machine Learning.\n",
      "Correct. Les messages d‚Äôerreur sont stock√©s avec la sortie d‚Äôune ex√©cution d‚Äôexp√©rience.\n",
      "Onglet Mod√®les dans Azure Machine Learning.\n",
      "Incorrect. Seuls les mod√®les entra√Æn√©s et inscrits sont visibles sous l‚Äôonglet Mod√®les.\n",
      "1.\n",
      "Quelle est la premi√®re √©tape √† effectuer pour partager un fichier image en tant qu‚Äôobjet blob dans le Stockage Azure ?\n",
      "Cr√©er un conteneur Stockage Azure pour stocker l‚Äôimage\n",
      "Cr√©ation d‚Äôun compte Azure Storage.\n",
      "C‚Äôest correct. Vous devez cr√©er un compte de stockage Azure avant de pouvoir utiliser les fonctionnalit√©s du Stockage Azure.\n",
      "Charger le fichier image et cr√©er un conteneur\n",
      "Utiliser un jeton de signature d‚Äôacc√®s partag√© (SAS) pour restreindre l‚Äôacc√®s √† l‚Äôimage\n",
      "2.\n",
      "Quelle option du Stockage Azure convient le mieux au stockage des donn√©es √† des fins de sauvegarde et de restauration, de reprise d‚Äôactivit√© apr√®s sinistre et d‚Äôarchivage ?\n",
      "Stockage Fichier Azure\n",
      "Ce n‚Äôest pas correct. Le Stockage Blob Azure constitue la meilleure option pour stocker les fichiers et les archives de reprise d‚Äôactivit√©.\n",
      "Stockage sur disque Azure\n",
      "Stockage Blob Azure\n",
      "C‚Äôest correct. Le Stockage Blob Azure constitue la meilleure option pour stocker les fichiers et les archives de reprise d‚Äôactivit√©.\n",
      "1.\n",
      "Quelle est la premi√®re √©tape que nous vous recommandons d‚Äôeffectuer pour analyser des journaux dans Journaux Azure Monitor ?\n",
      "√âcrire une requ√™te KQL pour r√©cup√©rer toutes les donn√©es pertinentes.\n",
      "Vous devez identifier les donn√©es pertinentes pour votre analyse avant d‚Äôutiliser KQL pour extraire les donn√©es.\n",
      "Examiner attentivement toutes les donn√©es de journaux dans votre espace de travail Log Analytics.\n",
      "D√©finir des objectifs d‚Äôanalyse et √©valuer les tables de votre espace de travail Log Analytics qui contiennent des donn√©es pertinentes pour votre analyse.\n",
      "Les donn√©es de journaux brutes contiennent une quantit√© consid√©rable d‚Äôinformations qui sont souvent difficiles √† comprendre. Une premi√®re √©tape plus efficace pour analyser les journaux dans Journaux Azure Monitor consiste √† rechercher la table qui contient des donn√©es sp√©cifiques en fonction d‚Äôobjectifs d‚Äôanalyse.\n",
      "------------------------\n",
      "2.\n",
      "Que pouvez-vous faire pour vous familiariser avec les donn√©es de journaux brutes que vous avez collect√©es dans une table ?\n",
      "Ex√©cuter des requ√™tes simples, comme take 10 et distinct <column name>, sur une table sp√©cifique ou utiliser l‚Äôinterface utilisateur Log Analytics pour lancer des recherches dans les donn√©es, les filtrer et les parcourir.\n",
      "Des requ√™tes simples, comme take 10 et distinct <column name>, vous permettent de vous concentrer sur de plus petites quantit√©s de donn√©es et de filtrer les valeurs r√©p√©t√©es, ce qui peut √™tre utile pour √©valuer des donn√©es brutes.\n",
      "Utiliser la fonction d‚Äôagr√©gation make_set() pour regrouper toutes les donn√©es de la table et tout voir au m√™me endroit.\n",
      "Exporter les donn√©es vers Excel ou un outil externe.\n",
      "------------------------\n",
      "3.\n",
      "Comment pouvez-vous enrichir les r√©sultats d‚Äôune requ√™te avec des donn√©es suppl√©mentaires qui ne sont pas disponibles dans la table que vous avez interrog√©e dans Log Analytics ?\n",
      "Utiliser l‚Äôop√©rateur KQL join pour r√©cup√©rer des informations d‚Äôune autre table.\n",
      "L‚Äôop√©rateur KQL join vous permet de mettre en corr√©lation les donn√©es de deux tables ayant une colonne en commun.\n",
      "Utiliser l‚Äôop√©rateur KQL import pour importer les donn√©es √† partir d‚Äôun autre emplacement.\n",
      "Ajouter une colonne aux r√©sultats de la requ√™te et remplir manuellement les donn√©es manquantes.\n",
      "------------------------\n",
      "1.\n",
      "Vous travaillez dans Visual Studio Code. Vous avez clon√© un d√©p√¥t GitHub dans Visual Studio Code et vous modifiez le code dans un notebook Jupyter. Pour tester le code, vous souhaitez ex√©cuter une cellule dans le notebook. Quelle calcul devez-vous utiliser ?\n",
      "Instance de calcul\n",
      "Correct. Vous pouvez utiliser une instance de calcul pour ex√©cuter un notebook dans Visual Studio Code.\n",
      "Cluster de calcul\n",
      "Cluster Azure Databricks\n",
      "------------------------\n",
      "2.\n",
      "Vous exp√©rimentez avec des pipelines bas√©s sur des composants dans le concepteur. Vous souhaitez it√©rer et exp√©rimenter rapidement, car vous essayez diff√©rentes configurations d‚Äôun pipeline. Vous utilisez un cluster de calcul. Pour r√©duire le temps de d√©marrage chaque fois que vous envoyez un pipeline, quel param√®tre devez-vous modifier ?\n",
      "Taille de calcul\n",
      "Incorrect. Vous ne devez pas modifier la taille de calcul lorsque vous souhaitez que le cluster de calcul reste disponible entre les ex√©cutions de travaux de pipeline.\n",
      "Temps d‚Äôinactivit√© avant scale-down\n",
      "Correct. En augmentant le temps d‚Äôinactivit√© avant un scale-down, vous pouvez ex√©cuter plusieurs pipelines cons√©cutivement sans que le cluster de calcul soit redimensionn√© √† z√©ro n≈ìud entre les travaux.\n",
      "Nombre maximal d'instances\n",
      "------------------------\n",
      "1.\n",
      "Lucas a form√© un mod√®le √† l‚Äôaide d‚ÄôAzure Databricks et veut maintenant le servir pour le scoring en temps r√©el. Quelle doit √™tre l‚Äôaction suivante ?\n",
      "G√©rer la version du mod√®le.\n",
      "Effectuer la transition du mod√®le √† la phase Archiv√©.\n",
      "Inscrire le mod√®le.\n",
      "Correct. L‚Äôinscription d‚Äôun mod√®le avec MLflow vous permet de servir le mod√®le pour le scoring en temps r√©el. Cela facilite l‚Äôutilisation du mod√®le form√©, car le processus de service g√©n√®re un wrapper et expose automatiquement une API REST pour le calcul de score.\n",
      "------------------------\n",
      "2.\n",
      "Une ex√©cution MLflow ex√©cute un script Python pour l‚Äôapprentissage d‚Äôun mod√®le. Le mod√®le est enregistr√© au cours de l‚Äôex√©cution, mais il doit √©galement √™tre enregistr√©. Qu‚Äôest-ce qui doit √™tre inclus dans le code pour inscrire le mod√®le lors de l‚Äôex√©cution ?\n",
      "register_model\n",
      "Incorrect. Cette m√©thode est utilis√©e lors de l‚Äôinscription d‚Äôun mod√®le directement √† partir d‚Äôune exp√©rience.\n",
      "registered_model_name\n",
      "Correct. Pendant une ex√©cution, vous pouvez inscrire un mod√®le en nommant registered_model_name.\n",
      "log_model\n",
      "------------------------\n",
      "3.\n",
      "Hanna dispose d‚Äôautorisations de lecture et souhaite faire passer un mod√®le de la phase de pr√©production √† celle de production par le biais de l‚Äôinterface utilisateur Azure Databricks. Que peut faire une personne disposant d‚Äôautorisations de lecture ?\n",
      "Effectuer la transition.\n",
      "Incorrect. Elle n‚Äôa pas les autorisations suffisantes pour effectuer la transition.\n",
      "Demander la transition.\n",
      "Correct. Tout utilisateur disposant d‚Äôautorisations de lecture ou de mieux peut demander une transition.\n",
      "Elle ne peut lire que la phase actuelle.\n",
      "------------------------\n",
      "1. Quel type de join contient toutes les colonnes et uniquement les lignes correspondantes des deux tables ?\n",
      "kind=leftouter\n",
      "kind=inner\n",
      "Correct. Le type inner contient une ligne dans la sortie pour chaque combinaison de lignes correspondantes dans les tables de gauche et de droite.\n",
      "kind=fullouter\n",
      "------------------------\n",
      "2. Quel op√©rateur retourne une table avec des lignes ajout√©es de plusieurs tables ?\n",
      "L‚Äôop√©rateur lookup\n",
      "L‚Äôop√©rateur join\n",
      "L‚Äôop√©rateur union\n",
      "Correct. L‚Äôop√©rateur union prend au moins deux tables et retourne une table avec toutes les lignes ajout√©es.\n",
      "------------------------\n",
      "3. Quelle fonction devez-vous utiliser pour capturer les r√©sultats d‚Äôune expression tabulaire ?\n",
      "La fonction materialize()\n",
      "Correct. La fonction materialize() capture le r√©sultat d‚Äôune expression tabulaire afin qu‚Äôil puisse √™tre r√©f√©renc√© plusieurs fois par la requ√™te sans recalcul.\n",
      "La fonction cache()\n",
      "Incorrect. Le langage de requ√™te Kusto n‚Äôa pas de fonction cache().\n",
      "Instruction let\n",
      "------------------------\n",
      "4. Chaque minute, un objet JSON est extrait d‚Äôun appareil IoT (Internet des objets). Quel est le type des donn√©es extraites ?\n",
      "Donn√©es structur√©es\n",
      "Donn√©es semi-structur√©es\n",
      "Correct. Un objet JSON est consid√©r√© comme semi-structur√©.\n",
      "Donn√©es non structur√©es\n",
      "------------------------\n",
      "2. Quand un scientifique des donn√©es extrait des objets JSON d‚Äôun appareil IoT et combine toutes les donn√©es transform√©es dans un fichier CSV, quel magasin de donn√©es doit-il utiliser de pr√©f√©rence ?\n",
      "Stockage Blob Azure\n",
      "Azure Data Lake Storage\n",
      "Correct. Vous pouvez stocker des fichiers CSV dans un lac de donn√©es sans aucune contrainte de capacit√©.\n",
      "Azure SQL Database\n",
      "------------------------\n",
      "Quelle transformation dans le flux de donn√©es de mappage est utilis√©e pour router des lignes de donn√©es vers diff√©rents flux en fonction de conditions de correspondance ?\n",
      "Recherche :\n",
      "Fractionnement conditionnel\n",
      "Correct. Une transformation de fractionnement conditionnel route les lignes de donn√©es vers diff√©rents flux en fonction de conditions de correspondance. La transformation de fractionnement conditionnel est similaire √† une structure de d√©cision CASE dans un langage de programmation.\n",
      "S√©lectionnez\n",
      "------------------------\n",
      "2. Quelle transformation est utilis√©e pour charger des donn√©es dans un magasin de donn√©es ou une ressource de calcul ?\n",
      "Fen√™tre\n",
      "Source.\n",
      "Incorrect. Une transformation de la source configure votre source de donn√©es pour le flux de donn√©es. Lors de la conception de flux de donn√©es, la premi√®re √©tape consiste toujours √† configurer une transformation de source.\n",
      "R√©cepteur\n",
      "Correct. Une transformation de r√©cepteur vous permet de choisir une d√©finition de jeu de donn√©es pour les donn√©es de sortie de destination. Vous pouvez utiliser autant de transformations de r√©ception que n√©cessaire pour votre flux de donn√©es.\n",
      "Le service peut √©galement analyser les donn√©es √† la recherche de modifications ayant eu lieu au fil du temps (on appelle cela la d√©rive de donn√©es) et d√©clencher une alerte.\n",
      "La derni√®re fa√ßon de publier vos mod√®les consiste √† t√©l√©charger le mod√®le au format ONNX (Open Neural Network Exchange),\n",
      "Azure Event Grid est un service d‚Äôingestion d‚Äô√©v√©nements qui peut alerter et automatiser les r√©ponses aux modifications apport√©es aux syst√®mes qu‚Äôil analyse.\n",
      "------------------------\n",
      "1.\n",
      "Parmi les fonctionnalit√©s suivantes, laquelle est disponible dans Azure ML Studio Designer ?\n",
      "Vue d‚Äôensemble et contr√¥les de s√©curit√© r√©seau\n",
      "Canevas visuels avec des contr√¥les glisser-d√©placer.\n",
      "Correct. Azure ML Designer fait parti d‚ÄôAzure ML studio. Il vous permet de cr√©er des pipelines ML en faisant glisser et en d√©posant des modules pour cr√©er des workflows ou des t√¢ches ex√©cut√©s dans un ordre particulier.\n",
      "Contr√¥le de version et stockage de mod√®le\n",
      "------------------------\n",
      "2.\n",
      "Laquelle des descriptions suivantes d√©crit pr√©cis√©ment un pipeline ?\n",
      "Environnement de codage pour le d√©ploiement et l‚Äôanalyse des mod√®les\n",
      "Ressource de niveau sup√©rieur pour la gestion de tous les composants que vous cr√©ez lorsque vous utilisez Azure Machine Learning\n",
      "Workflow d‚Äôun processus ou d‚Äôune t√¢che de Machine Learning compl√®te\n",
      "Correct. Les pipelines peuvent encapsuler une t√¢che telle que le nettoyage, l‚Äôextraction de donn√©es ou un workflow complet pour la formation et le d√©ploiement des mod√®les.\n",
      "------------------------\n",
      "3.\n",
      "Quelles sont les fonctionnalit√©s MLOps principales qui se trouvent dans Azure Machine Learning ?\n",
      "D√©ploiement de mod√®les plus rapide\n",
      "Environnements et pipelines de formation reproductibles\n",
      "Tous les √©l√©ments ci-dessus\n",
      "Correct. Azure ML incorpore tous ces principes dans ses fonctionnalit√©s pour vous aider √† cr√©er des mod√®les reproductibles et fiables.\n",
      "------------------------\n",
      "1. Un scientifique des donn√©es souhaite utiliser le Machine Learning automatis√© pour rechercher le mod√®le avec la meilleure m√©trique AUC_weighted. Quel param√®tre de la fonction de classification doit √™tre configur√© ?\n",
      "    task='AUC_weighted'\n",
      "    target_column_name='AUC_weighted'\n",
      "    primary_metric='AUC_weighted'\n",
      "    Correct. D√©finissez la m√©trique principale sur le score de performance pour lequel vous souhaitez optimiser le mod√®le.\n",
      "    2. Un scientifique des donn√©es a pr√©trait√© les donn√©es d‚Äôentra√Ænement, et souhaite utiliser le Machine Learning automatis√© pour it√©rer rapidement au sein de diff√©rents algorithmes. Les donn√©es ne doivent pas √™tre modifi√©es. Quel doit √™tre le mode de caract√©risation pour entra√Æner un mod√®le sans laisser le Machine Learning automatis√© apporter des modifications aux donn√©es ?\n",
      "    auto\n",
      "    custom\n",
      "    off\n",
      "    Correct. Si vous ne souhaitez pas que les donn√©es soient pr√©trait√©es, d√©sactivez la caract√©risation.\n",
      "1. Un scientifique des donn√©es exp√©rimente la formation du mod√®le. Apr√®s quelques it√©rations, un mod√®le semble adapt√© au d√©ploiement, mais n‚Äôest pas encore pr√™t pour la consommation. Un pipeline Azure est cr√©√© pour effectuer l‚Äôapprentissage du mod√®le. Dans quel environnement le mod√®le doit-il d‚Äôabord √™tre form√© ?\n",
      "Production\n",
      "Pr√©production\n",
      "D√©veloppement\n",
      "Correct. Une premi√®re √©tape s√ªre consiste √† effectuer l‚Äôapprentissage d‚Äôun mod√®le dans l‚Äôenvironnement de d√©veloppement, d√©clench√© par un pipeline Azure.\n",
      "2. Comment un ing√©nieur Machine Learning peut-il contr√¥ler le d√©placement d‚Äôun mod√®le du d√©veloppement vers la pr√©-production ?\n",
      "Ajouter un d√©clencheur.\n",
      "Ajoutez une v√©rification d‚Äôapprobation.\n",
      "Correct. Une v√©rification d‚Äôapprobation n√©cessite qu‚Äôune personne passe en revue un pipeline avant son ex√©cution.\n",
      "Ajoutez RBAC.\n",
      "1. Comment pouvez-vous identifier les types de donn√©es dans chaque colonne de votre jeu de donn√©es ?\n",
      "Utiliser l‚Äôop√©rateur getschema.\n",
      "Vrai. L‚Äôop√©rateur getschema renvoie le sch√©ma du jeu de donn√©es, qui contient chaque nom de colonne et son type de donn√©es.\n",
      "Utilisez l‚Äôop√©rateur render\n",
      "Mettez en surbrillance les colonnes et examinez le r√©sum√© dans la grille de r√©sultats.\n",
      "2. Comment pouvez-vous trouver facilement la valeur min/max et la moyenne d‚Äôune s√©lection de cellules enti√®res dans la grille de r√©sultats ?\n",
      "Triez la grille de r√©sultats en fonction de la colonne souhait√©e.\n",
      "Utilisez l‚Äôop√©rateur render pour tracer la colonne et √©valuez les r√©sultats.\n",
      "Mettez en surbrillance les cellules et examinez le r√©sum√© dans le coin inf√©rieur de la grille de r√©sultats.\n",
      "Vrai. Les cellules en surbrillance afficheront un r√©sum√© dans le coin inf√©rieur droit de la grille de r√©sultats.\n",
      "3. Comment pouvez-vous v√©rifier si une s√©rie chronologique manque des donn√©es ?\n",
      "Comptez le nombre de lignes pr√©sentes dans la s√©rie chronologique.\n",
      "Faux. Le comptage n‚Äôest un test significatif que si vous savez √† combien de lignes vous attendre.\n",
      "Prenez un √©chantillon de 10 lignes de donn√©es.\n",
      "Tracez le nombre d‚Äô√©v√©nements par rapport au temps pour voir si des donn√©es sont manquantes.\n",
      "Vrai. Cette visualisation vous aidera √† d√©terminer si des donn√©es sont manquantes\n",
      "1. Vous cr√©ez un point de terminaison de lot que vous souhaitez utiliser en vue de pr√©dire de nouvelles valeurs pour un volume important de fichiers de donn√©es. Vous voulez que le pipeline ex√©cute le script de scoring sur plusieurs n≈ìuds et assemble les r√©sultats. Quelle action de sortie devez-vous choisir pour le d√©ploiement ?\n",
      "summary_only\n",
      "append_row\n",
      "Correct. Vous devez utiliser append_row pour ajouter chaque pr√©diction √† un fichier de sortie.\n",
      "concurrency\n",
      "2. Plusieurs mod√®les sont d√©ploy√©s sur un point de terminaison de lot. Vous appelez le point de terminaison sans indiquer le mod√®le que vous souhaitez utiliser. Quel est le mod√®le d√©ploy√© qui va r√©ellement effectuer le scoring par lots ?\n",
      "Derni√®re version du mod√®le d√©ploy√©.\n",
      "Dernier mod√®le d√©ploy√©.\n",
      "Mod√®le d√©ploy√© par d√©faut.\n",
      "Correct. Le d√©ploiement par d√©faut sera utilis√© pour effectuer le scoring par lots r√©el lorsque le point de terminaison est appel√©\n",
      "------------------------\n",
      "1. Quel est l‚Äôavantage d‚Äôutiliser les tableaux de bord Azure Data Explorer ?\n",
      "Lien dynamique vers les donn√©es : les vignettes sont mises √† jour chaque fois que vos donn√©es changent.\n",
      "C‚Äôest vrai. Les tableaux de bord Azure Data Explorer sont dynamiques et mis √† jour chaque fois que vos donn√©es changent.\n",
      "Des capacit√©s de requ√™te suppl√©mentaires en plus du langage de requ√™te standard.\n",
      "Aucune autorisation de base de donn√©es n‚Äôest n√©cessaire.\n",
      "2. Apr√®s avoir ajout√© un param√®tre de tableau de bord, rien n‚Äôa chang√© dans les vignettes. Quelle est l‚Äô√©tape suivante ?\n",
      "Ajoutez une nouvelle vignette.\n",
      "Ajoutez le param√®tre en tant que filtre dans la requ√™te de vignette, puis choisissez une valeur pour le param√®tre.\n",
      "Vrai. Les param√®tres sont actifs uniquement quand ils sont utilis√©s dans la requ√™te de vignette.\n",
      "Ajoutez un filtre crois√©.\n",
      "3. Comment la liste de valeurs de param√®tres peut-elle √™tre remplie ?\n",
      "Automatiquement. La liste des valeurs est remplie une fois le nom g√©n√©r√©.\n",
      "La liste doit √™tre saisie manuellement ou g√©n√©r√©e par une requ√™te.\n",
      "Vrai. La liste peut √™tre saisie manuellement ou g√©n√©r√©e par une requ√™te.\n",
      "Il n‚Äôest pas n√©cessaire de g√©n√©rer une liste de valeurs de param√®tres.\n",
      "1. Est-ce que le Lecteur immersif fonctionne avec des images de t√©l√©phone ?\n",
      "Non, il peut √™tre incorpor√© uniquement dans une application.\n",
      "Incorrect. Le Lecteur immersif fonctionne sur votre t√©l√©phone par le biais de Microsoft Lens, application iOS et Android qui rend lisibles les images de tableaux blancs et de documents en permettant √† l‚Äôutilisateur d‚Äôacc√©der √† des fonctions de lecture √† voix haute, d‚Äôespacement du texte et de changement des couleurs.\n",
      "Oui, avec Microsoft Lens.\n",
      "Correct. Microsoft Lens est une application iOS et Android qui rend lisibles les images de tableaux blancs et de documents en permettant √† l‚Äôutilisateur d‚Äôacc√©der √† des fonctions de lecture √† voix haute, d‚Äôespacement du texte et de changement des couleurs.\n",
      "Oui, il vous suffit de le charger sur votre ordinateur.\n",
      "2. Combien de langues le Lecteur immersif peut-il traduire automatiquement ?\n",
      "Aucun.\n",
      "Toutes les langues connues.\n",
      "80 langues.\n",
      "Correct. La traduction int√©gr√©e propos√©e par le Lecteur immersif est disponible dans 80 langues, et les utilisateurs peuvent traduire des mots, des phrases ou un document entier.\n",
      "3. Quel avantage offre la fonction Cat√©gories grammaticales ?\n",
      "Les cat√©gories grammaticales, comme les substantifs et les verbes, sont √©tiquet√©es et peuvent √™tre mises en √©vidence avec des couleurs diff√©rentes.\n",
      "Correct. Les cat√©gories grammaticales peuvent aider les utilisateurs √† apprendre la grammaire, tout en renfor√ßant leur compr√©hension et leur attention en utilisant diff√©rentes couleurs pour mettre en √©vidence les mots.\n",
      "Les mots sont d√©coup√©s en syllabes.\n",
      "Il explique ce que sont les cat√©gories grammaticales\n",
      "------------------------\n",
      "     \n",
      "1.\n",
      "Quels sont les besoins utilisateur les plus adapt√©s √† l‚Äôutilisation de HDInsight Interactive Query ?\n",
      "Lorsque vous souhaitez utiliser MapReduce sur des donn√©es non structur√©es avec des contr√¥les d‚Äôacc√®s en fonction du r√¥le.\n",
      "Lorsque vous souhaitez utiliser des requ√™tes de type SQL sur des donn√©es structur√©es avec des contr√¥les au niveau des lignes et des colonnes.\n",
      "Interactive Query offre des requ√™tes de type SQL sur des donn√©es structur√©es, avec des contr√¥les au niveau des lignes et des colonnes.\n",
      "Lorsque vous souhaitez utiliser des requ√™tes de type SQL sur des donn√©es √† haut niveau de concurrence pour des calculs sur de longues p√©riodes.\n",
      "2.\n",
      "Quels sont les formats de fichier pris en charge par Interactive Query ?\n",
      ".xml, .doc, .log\n",
      ".json, .csv, .txt\n",
      "Les fichiers .JSON, .csv et .txt sont pris en charge par Interactive Query.\n",
      ".pdf, .dbk, .md\n",
      "3.\n",
      "Quel sc√©nario est le mieux adapt√© √† HDInsight Interactive Query ?\n",
      "Traitement par lots\n",
      "Le traitement par lots consiste √† lire les donn√©es √† partir d‚Äôun emplacement, √† les transformer et √† les √©crire √† un autre emplacement. Interactive Query est id√©al pour interroger les donn√©es en l‚Äô√©tat, sans avoir √† les transformer outre mesure.\n",
      "Diffusion de donn√©es\n",
      "requ√™tes ad hoc ;\n",
      "Les sc√©narios de requ√™te ad hoc requi√®rent des r√©ponses rapides aux requ√™tes utilisateur interactives. Un bon sc√©nario pour Interactive Query\n",
      "4.\n",
      "Pourquoi Hive Warehouse Connector est-il n√©cessaire ?\n",
      "Hive et Spark sont des types de cluster diff√©rents.\n",
      "Hive et Spark ont deux metastores diff√©rents. Un connecteur est n√©cessaire pour les relier entre eux.\n",
      "Hive et Spark ont des metastores diff√©rents et ont besoin d‚Äôun pont pour connecter les deux.\n",
      "Hive est destin√© aux donn√©es statiques et Spark est destin√© aux donn√©es de diffusion en continu.\n",
      "5.\n",
      "Pourquoi l‚Äôutilisation de Hive Warehouse Connector est-elle plus efficace et √©volutive que l‚Äôutilisation d‚Äôune connexion JDBC standard de Spark √† Hive ?\n",
      "Parce que la biblioth√®que charge des donn√©es entre le HiveServer et le pilote Spark en parall√®le\n",
      "La biblioth√®que ne charge pas de donn√©es entre le HiveServer et le pilote Spark.\n",
      "Parce que Hive Warehouse Connector est optimis√© pour les donn√©es de diffusion en continu\n",
      "Parce que la biblioth√®que charge les donn√©es de d√©mons LLAP dans des ex√©cuteurs Spark en parall√®le\n",
      "La biblioth√®que charge des donn√©es √† partir de d√©mons LLAP dans des ex√©cuteurs Spark en parall√®le, ce qui rend Hive Warehouse Connector efficace et √©volutif.\n",
      "------------------------\n",
      "1.\n",
      "Supposons que votre corpus de texte contient 80 000 mots diff√©rents. Qu‚Äôest-ce qui est g√©n√©ralement fait pour r√©duire la dimensionnalit√© du vecteur d‚Äôentr√©e au classificateur neuronal ?\n",
      "S√©lectionner 10 % des mots de fa√ßon al√©atoire et ignorer le reste\n",
      "Utiliser la couche convolutive avant la couche de classifieur enti√®rement connect√©\n",
      "Les couches convolutives ne r√©duisent pas la dimensionnalit√© des vecteurs d‚Äôentr√©e\n",
      "Utiliser la couche d‚Äôincorporation avant la couche de classifieur enti√®rement connect√©\n",
      "C‚Äôest correct\n",
      "S√©lectionner 10 % des mots les plus fr√©quemment utilis√©s et ignorer le reste\n",
      "------------------------\n",
      "1. Nous souhaitons former un r√©seau neuronal afin de g√©n√©rer de nouveaux mots dr√¥les pour un livre pour enfants. Quelle architecture puis-je utiliser ?\n",
      "LSTM au niveau du mot\n",
      "Les r√©seaux au niveau du mot op√®rent sur un vocabulaire pr√©d√©fini de mots et ne peuvent pas g√©n√©rer de nouveaux mots.\n",
      "LSTM au niveau du caract√®re\n",
      "Correct, les LSTM de niveau caract√®re capturent souvent des syllabes utilis√©es et placent ces s√©quences ensemble pour g√©n√©rer de nouveaux mots.\n",
      "RNN au niveau du mot\n",
      "Perceptron au niveau du caract√®re\n",
      "2. Le r√©seau neuronal r√©current est appel√© ainsi pour les raisons suivantes :\n",
      "Un r√©seau est appliqu√© √† chaque √©l√©ment d‚Äôentr√©e, et la sortie de l‚Äôapplication pr√©c√©dente est pass√©e √† la suivante\n",
      "Correct.\n",
      "Il est form√© par un processus r√©current\n",
      "Il se compose de couches qui incluent d‚Äôautres sous-r√©seaux\n",
      "3. Quelle est l‚Äôid√©e principale de l‚Äôarchitecture r√©seau LSTM ?\n",
      "Nombre fixe de blocs LSTM pour l‚Äôensemble du jeu de donn√©es\n",
      "Il contient de nombreuses couches de r√©seaux neuronaux r√©currents\n",
      "Gestion d‚Äô√©tat explicite avec oubli et d√©clenchement d‚Äô√©tat\n",
      "Dans LSTM, chaque bloc re√ßoit un √©tat de sortie. Il est manipul√© dans le bloc en fonction de l‚Äôentr√©e et de l‚Äô√©tat pr√©c√©dent.\n",
      "------------------------\n",
      "1.\n",
      "Le r√©seau neuronal r√©current est appel√© ainsi pour les raisons suivantes :\n",
      "Un r√©seau est appliqu√© √† chaque √©l√©ment d‚Äôentr√©e, et la sortie de l‚Äôapplication pr√©c√©dente est pass√©e √† la suivante\n",
      "C‚Äôest exact.\n",
      "Il est form√© par un processus r√©current\n",
      "Il se compose de couches qui incluent d‚Äôautres sous-r√©seaux.\n",
      "------------------------\n",
      "1. Qu‚Äôest-ce que le taux d‚Äô√©chantillonnage ?\n",
      "Fr√©quence mapp√©e au temps.\n",
      "Les canaux audio.\n",
      "√âchantillonnage du son analogique √† des intervalles de temps coh√©rents pour cr√©er une repr√©sentation num√©rique du son.\n",
      "Correct !\n",
      "2. Qu‚Äôest-ce que la forme d‚Äôonde ?\n",
      "Fr√©quence mapp√©e au temps.\n",
      "Incorrect, une fr√©quence associ√©e √† un instant T est un spectrogramme.\n",
      "Taux d‚Äô√©chantillonnage et fr√©quence visualis√©es.\n",
      "Correct ! Vous pouvez visualiser vos donn√©es √† l‚Äôaide d‚Äôune forme d‚Äôonde pour associer le taux d‚Äô√©chantillonnage et la fr√©quence.\n",
      "Les canaux audio.\n",
      "------------------------\n",
      "1.\n",
      "Lorsque vous r√©√©chantillonnez le son, vous...\n",
      "augmentez la taille.\n",
      "r√©duisez la taille.\n",
      "Correct ! Vous pouvez r√©duire la taille du fichier en r√©duisant le taux d‚Äô√©chantillonnage pour la piste audio.\n",
      "2.\n",
      "Qu‚Äôest-ce qu‚Äôun spectrogramme ?\n",
      "Il associe la fr√©quence √† un instant T d‚Äôun fichier audio.\n",
      "Correct !\n",
      "Les canaux audio.\n",
      "Taux d‚Äô√©chantillonnage et fr√©quence visualis√©es.\n",
      "3.\n",
      "La classification audio ne peut √™tre effectu√©e qu‚Äôavec la vision par ordinateur sur des spectrogrammes.\n",
      "Vrai\n",
      "Faux\n",
      "Correct ! Il existe plusieurs fa√ßons de cr√©er des mod√®les de classification audio.\n",
      "------------------------\n",
      "1.\n",
      "Le framework tidymodels a √©t√© utilis√© dans R pour former un mod√®le de r√©gression √† partir d‚Äôun jeu de donn√©es de donn√©es de ventes. Comment faire pour √©valuer le mod√®le pour vous assurer qu‚Äôil se pr√©dira correctement avec les nouvelles donn√©es ?\n",
      "Fractionner les donn√©es de mani√®re al√©atoire en deux sous-ensembles. Utiliser un sous-ensemble pour effectuer l‚Äôapprentissage du mod√®le et l‚Äôautre pour l‚Äô√©valuer.\n",
      "Correct. Une m√©thode courante d‚Äôapprentissage et d‚Äô√©valuation de mod√®les consiste √† conserver un jeu de donn√©es d‚Äô√©valuation lors de l‚Äôapprentissage.\n",
      "Utiliser toutes donn√©es pour effectuer l‚Äôapprentissage du mod√®le. Puis utiliser toutes les donn√©es pour l‚Äô√©valuer.\n",
      "Effectuez l‚Äôapprentissage du mod√®le √† l‚Äôaide uniquement des colonnes de caract√©ristiques. Ensuite, √©valuez-le en utilisant uniquement la colonne d‚Äô√©tiquette.\n",
      "2.\n",
      "Une sp√©cification de mod√®le de r√©gression a √©t√© cr√©√©e √† l‚Äôaide de la fonction linear_reg() dans le package tidymodels. Que faut-il faire pour former le mod√®le ?\n",
      "Appelez la fonction predict() et sp√©cifiez la sp√©cification, la formule et les donn√©es du mod√®le.\n",
      "Appelez la fonction recipe() et sp√©cifiez la sp√©cification, la formule et les donn√©es du mod√®le.\n",
      "Appelez la fonction fit() et sp√©cifiez la sp√©cification, la formule et les donn√©es du mod√®le.\n",
      "Correct. Une fois qu‚Äôune sp√©cification de mod√®le est effectu√©e, la formation du mod√®le peut ensuite √™tre effectu√©e avec la fonction fit() ou fit_xy().\n",
      "3.\n",
      "Un mod√®le de r√©gression a √©t√© form√© √† l‚Äôaide du framework tidymodels. Lorsqu‚Äôil est √©valu√© avec des donn√©es de test, le mod√®le obtient un R-carr√© de 0,95. Qu‚Äôest-ce que cette m√©trique vous apprend sur le mod√®le ?\n",
      "Le mod√®le a une pr√©cision de 95 %.\n",
      "Le mod√®le d√©crit la majeure partie de la variance entre les valeurs pr√©dites et r√©elles.\n",
      "Correct. La m√©trique R-squared est une mesure de la quantit√© de la variance qui peut √™tre expliqu√©e par le mod√®le.\n",
      "En moyenne, les pr√©dictions sont 0,95 sup√©rieures aux valeurs r√©elles.\n",
      "------------------------\n",
      "1.\n",
      "Vous envisagez d‚Äôutiliser le framework tidymodels pour former un mod√®le qui pr√©dit le risque de d√©faut de cr√©dit. Le mod√®le doit pr√©dire une valeur de 0 pour les demandes de pr√™t qui doivent √™tre approuv√©es automatiquement, et 1 pour les demandes pour lesquelles il existe un risque de valeur par d√©faut qui n√©cessite une prise en compte humaine. Quel type de mod√®le est requis ?\n",
      "Un mod√®le de classification binaire.\n",
      "Correct. Un mod√®le de classification binaire pr√©dit la probabilit√© pour deux classes.\n",
      "Un mod√®le de classification multiclasse.\n",
      "Un mod√®le de r√©gression lin√©aire.\n",
      "2.\n",
      "Vous avez form√© une sp√©cification de mod√®le de classification dans tidymodels. Vous souhaitez utiliser le mod√®le, logreg_cls_fit, pour retourner des √©tiquettes pour un nouveau jeu de donn√©es appel√© new_data. Quel code devez-vous utiliser ?\n",
      "predict(logreg_cls_fit, new_data)\n",
      "Correct. Utilisez la m√©thode parsnip::predict.model_fit() pour inf√©rer les √©tiquettes pour les nouvelles donn√©es.\n",
      "fit(logreg_cls_fit, new_data)\n",
      "fit_resamples(logreg_cls_fit, new_data)\n",
      "3.\n",
      "Vous formez un mod√®le de classification binaire √† l‚Äôaide du framework tidymodels. Lorsque vous l‚Äô√©valuez avec des donn√©es de test, vous d√©terminez que le mod√®le atteint une m√©trique Rappel globale de 0,81. Que signifie cette mesure ?\n",
      "Le mod√®le a correctement pr√©dit 81 pour cent des cas de test.\n",
      "81 pour cent des cas pr√©dits comme positifs par le mod√®le √©taient r√©ellement positifs.\n",
      "Incorrect. Vous trouverez ces informations √† l‚Äôaide de la m√©trique de pr√©cision.\n",
      "Le mod√®le a correctement identifi√© 81 pour cent des cas positifs comme √©tant positifs.\n",
      "Correct. La m√©trique de rappel indique le pourcentage de cas positifs r√©els que le classifieur a correctement identifi√©s.\n",
      "------------------------\n",
      "1.\n",
      "Un scientifique des donn√©es souhaite ex√©cuter un script en tant que travail de commande pour entra√Æner un mod√®le PyTorch, en d√©finissant les hyperparam√®tres de taille de lot et de taux d‚Äôapprentissage sur les valeurs sp√©cifi√©es √† chaque ex√©cution du travail. Que doit faire le scientifique des donn√©es ?\n",
      "Cr√©er plusieurs fichiers de script : un pour chaque combinaison de taille de lot et de taux d‚Äôapprentissage que vous voulez utiliser.\n",
      "D√©finir les propri√©t√©s de taille de lot et de taux d‚Äôapprentissage du travail de commande avant de soumettre le travail.\n",
      "Ajouter des arguments pour la taille de lot et le taux d‚Äôapprentissage au script, puis les d√©finir dans la propri√©t√© command du travail de commande.\n",
      "Correct. Pour utiliser des valeurs diff√©rentes √† chaque fois, d√©finir des arguments dans le script et les passer √† l‚Äôaide du param√®tre arguments du travail de commande.\n",
      "2.\n",
      "Un scientifique des donn√©es a entra√Æn√© un mod√®le dans un notebook. Le mod√®le doit √™tre r√©entra√Æn√© chaque semaine sur de nouvelles donn√©es. Que doit faire le scientifique des donn√©es pour que le code soit pr√™t pour la production ?\n",
      "Copier et coller le code de chaque cellule dans un script.\n",
      "Convertir le code en une seule fonction dans un script qui lit les donn√©es et entra√Æne le mod√®le.\n",
      "Incorrect. Un script comprenant plusieurs fonctions est plus facile √† tester et √† g√©rer, notamment par d‚Äôautres personnes.\n",
      "Convertir le code en plusieurs fonctions dans un script qui lisent les donn√©es et entra√Ænent le mod√®le.\n",
      "Correct. Il est pr√©f√©rable d‚Äôutiliser un script compos√© de plusieurs fonctions pour les charges de travail de production.\n",
      "------------------------\n",
      "1.\n",
      "Un scientifique des donn√©es forme un mod√®le de r√©gression et souhaite suivre les performances du mod√®le en stockant l‚Äôerreur quadratique moyenne (RMSE) √† l‚Äôex√©cution de l‚Äôexp√©rimentation. Quelle m√©thode peut √™tre utilis√©e pour enregistrer le RMSE ?\n",
      "mlflow.log_param()\n",
      "mlflow.log_artifact()\n",
      "mlflow.log_metric()\n",
      "Correct. Utiliser mlflow.log_metric() pour enregistrer une m√©trique comme RMSE.\n",
      "2.\n",
      "Quand un scientifique des donn√©es active la journalisation MLflow, o√π se trouvent toutes les ressources du mod√®le ?\n",
      "Dans le dossier model sous Outputs + logs.\n",
      "Correct. Les ressources de mod√®le comme le fichier de mod√®le pickle sont stock√©es dans le dossier model sous Outputs + logs.\n",
      "Dans le dossier outputs, sous Outputs + logs.\n",
      "Dans le dossier model sous Metrics.\n",
      "------------------------\n",
      "1.\n",
      "Vous avez entra√Æn√© un mod√®le √† l‚Äôaide du SDK Python pour Azure Machine Learning. Vous souhaitez d√©ployer le mod√®le pour obtenir des pr√©diction en temps r√©el. Vous souhaitez g√©rer l‚Äôinfrastructure sous-jacente utilis√©e par le point de terminaison. Quel type de point de terminaison devez-vous cr√©er ?\n",
      "Un point de terminaison en ligne manag√©.\n",
      "Incorrect. Si vous utilisez un point de terminaison en ligne manag√©, Azure Machine Learning g√®re toute l‚Äôinfrastructure.\n",
      "Un point de terminaison de traitement par lots.\n",
      "Un point de terminaison en ligne Kubernetes.\n",
      "Correct. Vous devez utiliser un point de terminaison en ligne Kubernetes si vous souhaitez g√©rer les clusters Kubernetes sous-jacents.\n",
      "2.\n",
      "Vous d√©ployez un mod√®le comme un service d‚Äôinf√©rence en temps r√©el. Quelles fonctions le script de scoring doit-il inclure pour le d√©ploiement ?\n",
      "main() et score()\n",
      "base() et train()\n",
      "init() et run()\n",
      "Correct. Vous devez impl√©menter les fonctions init et run dans le script d‚Äôentr√©e (scoring).\n",
      "------------------------\n",
      "1.\n",
      "Quel type d‚Äôalgorithme Machine Learning utiliseriez-vous pour entra√Æner un mod√®le qui pr√©dit la quantit√© de pr√©cipitations en pouces sur une journ√©e donn√©e ?\n",
      "classification ;\n",
      "r√©gression ;\n",
      "Correct. Un mod√®le de r√©gression pr√©dit une valeur num√©rique.\n",
      "Clustering\n",
      "2.\n",
      "Quelle classe Spark devez-vous utiliser pour explorer et nettoyer les donn√©es d‚Äôentra√Ænement d‚Äôun projet Machine Learning ?\n",
      "Dataframe\n",
      "C‚Äôest correct. Un dataframe est une excellente classe √† utiliser pour travailler avec des donn√©es.\n",
      "RDD\n",
      "Mod√®le\n",
      "3.\n",
      "Parmi les m√©triques suivantes, lesquelles utiliseriez-vous pour √©valuer un mod√®le de classification ?\n",
      "Erreur quadratique moyenne\n",
      "Silhouette\n",
      "Rappel\n",
      "C‚Äôest correct. Le rappel est une m√©trique utilis√©e pour √©valuer un mod√®le de clustering.\n",
      "------------------------\n",
      "1.\n",
      "Dans notre r√©pertoire actif, nous souhaitons trouver les trois fichiers comprenant le moins de lignes. Quelle commande devez-vous utiliser ?\n",
      "wc -l * > sort -n > head -n 3\n",
      "wc -l * | sort -n | head -n 1-3\n",
      "wc -l * | sort -n | head -n 3\n",
      "Correct. Cette commande compte les lignes d‚Äôun fichier, trie la sortie dans l‚Äôordre croissant (num√©rique) et affiche les trois premi√®res lignes.\n",
      "wc -l * | head -n 3 | sort -n\n",
      "2.\n",
      "Quelles sont les correspondances √©tablies par l‚Äôexpression r√©guli√®re Fr[ea]nc[eh] ?\n",
      "French, France, Frence, Franch\n",
      "Correct. Cette expression r√©guli√®re est construite de telle fa√ßon qu‚Äôelle √©tablit une correspondance avec les termes mal orthographi√©s Frence et Franch.\n",
      "Frenche, Franceh, Frenceh, Franche\n",
      "France, French\n",
      "Freanceh, Fraenche\n",
      "3.\n",
      "L‚Äôoption -v de la commande grep inverse les crit√®res sp√©ciaux. Ainsi, seules les lignes qui ne correspondent pas au mod√®le sont imprim√©es. Laquelle des commandes suivantes trouve tous les fichiers dans le r√©pertoire /data dont les noms se terminent par s.txtet qui ne contiennent pas la cha√Æne net ? shuttles.txt ou software.txt sont des exemples, mais pas planets.txt.\n",
      "find data -name *s.txt | grep -v net\n",
      "Incorrect. L‚Äôinterpr√©teur de commandes d√©veloppe *s.txt au lieu de passer l‚Äôexpression g√©n√©rique √† rechercher.\n",
      "grep -v 'net' $(find data -name '*s.txt')\n",
      "find data -name '*s.txt' | grep -v net\n",
      "Correct. Le fait de placer l‚Äôexpression de correspondance entre guillemets emp√™che le shell de la d√©velopper. Elle est donc transmise √† la commande find.\n",
      "Aucune des propositions ci-dessus\n",
      "4.\n",
      "Pour √©conomiser du stockage, vous souhaitez supprimer certains fichiers de donn√©es trait√©s et conserver uniquement vos fichiers bruts et votre script de traitement. Les fichiers bruts se terminent par .dat, et les fichiers trait√©s se terminent par .txt. Laquelle des solutions suivantes permet de supprimer tous les fichiers de donn√©es trait√©s, et aucun autre fichier ?\n",
      "rm ?.txt\n",
      "rm *.txt\n",
      "Correct. Cette expression supprime tous les fichiers qui se terminent par une extension .txt.\n",
      "rm * .txt\n",
      "rm *.*\n",
      "------------------------\n",
      "1.\n",
      "Quelle m√©thode devez-vous utiliser pour enregistrer la valeur d‚Äô√©valuation rmse de votre mod√®le dans une ex√©cution MLflow ?\n",
      "mlflow.log_metric\n",
      "Correct. Consigner les m√©triques de performances √† l‚Äôaide de la m√©thode mlflow.log_metric.\n",
      "mlflow.log_param\n",
      "mlflow.spark.log_model\n",
      "2.\n",
      "Vous avez enregistr√© un mod√®le dans une ex√©cution d‚Äôexp√©rience et vous pr√©voyez de le d√©ployer dans un service d‚Äôinf√©rence en temps r√©el. Que devez-vous faire ?\n",
      "Reproduire l‚Äôexp√©rience\n",
      "Inscrire le mod√®le\n",
      "Correct. Inscrire un mod√®le avant de le d√©ployer pour l‚Äôinf√©rence.\n",
      "Enregistrer le mod√®le en tant que fichier ONXX dans le syst√®me de fichiers DFFS.\n",
      "3.\n",
      "Vous souhaitez utiliser votre mod√®le pour pr√©dire les √©tiquettes en continu √† partir de donn√©es de caract√©ristiques quand elles sont stock√©es dans une table delta. Quel type d‚Äôinf√©rence devez-vous configurer ?\n",
      "Points de terminaison en temps r√©el\n",
      "Incorrect. Un point de terminaison en temps r√©el permet aux applications d‚Äôeffectuer l‚Äôinf√©rence √† la demande via une interface REST.\n",
      "Diffusion en continu\n",
      "Correct. Une solution d‚Äôinf√©rence de streaming traite les donn√©es d‚Äôune table delta et transmet les r√©sultats en continu √† une autre table.\n",
      "Batch\n",
      "------------------------\n",
      "1. Translator peut convertir du texte √† partir de quels types de fichiers et de donn√©es ?\n",
      "Fichiers PowerPoint et vid√©os MP4\n",
      "Cha√Ænes et documents.\n",
      "Correct. Translator peut convertir des cha√Ænes et des documents, comme des documents PDF et Word, d‚Äôune langue vers de nombreuses autres.\n",
      "Images JPG et PNG.\n",
      "2. Avez-vous besoin de sp√©cifier la langue source pour une traduction ?\n",
      "Non, la d√©tection automatique de la langue fonctionne pour toutes les langues.\n",
      "Oui, la d√©tection automatique de la langue n‚Äôest pas disponible pour Translator.\n",
      "Incorrect. Translator peut d√©tecter automatiquement la langue source pour certaines langues.\n",
      "Pour certaines langues, vous devez sp√©cifier la langue source, mais la d√©tection automatique de la langue fonctionne pour plus de 50 langues.\n",
      "Correct. Translator peut d√©tecter automatiquement la langue source pour certaines langues, ce qui signifie que vous ne devez pas toujours sp√©cifier la langue source.\n",
      "3.\n",
      "Quel est l‚Äôavantage de cr√©er un mod√®le de traduction personnalis√© ?\n",
      "Les mod√®les personnalis√©s peuvent √™tre adapt√©s aux terminologies et styles sp√©cifiques √† votre secteur d‚Äôactivit√© ou √† un domaine, ce qui permet une traduction plus pr√©cise.\n",
      "Correct. Les mod√®les personnalis√©s peuvent √™tre adapt√©s pour traduire du texte et des documents dans des terminologies et des styles sp√©cifiques d‚Äôun secteur d‚Äôactivit√© ou d‚Äôun domaine.\n",
      "Les mod√®les personnalis√©s peuvent extraire des donn√©es de photographies, en am√©liorant vos workflows existants.\n",
      "Les mod√®les personnalis√©s peuvent √™tre ajust√©s pour comprendre l‚Äô√©motion du document, ce qui permet √† un score de sentiment de fournir plus de donn√©es √† l‚Äôutilisateur final.\n",
      "------------------------\n",
      "1.\n",
      "Quels types d‚Äôanalytique sont propos√©s avec Azure Synapse ?\n",
      "Analytique descriptive et associative.\n",
      "Analytique pr√©dictive et prescriptive.\n",
      "Correct. Synapse offre √† la fois ces deux fonctionnalit√©s, ainsi que l‚Äôanalytique descriptive et de diagnostic.\n",
      "Analyse exploratoire et de diagnostic.\n",
      "2.\n",
      "Parmi les instructions suivantes, laquelle d√©crit le mieux une offre de services li√©s Azure Synapse Studio ?\n",
      "Le service li√© personnalis√© peut √™tre cr√©√© dans Synapse.\n",
      "Correct. Synapse offre la possibilit√© de cr√©er votre propre service li√© si vous ne trouvez pas ce dont vous avez besoin parmi les services li√©s disponibles.\n",
      "Plus de 2 000 services li√©s sont disponibles pour les sources de donn√©es et les applications.\n",
      "Incorrect. Synapse propose plus de 200 services li√©s.\n",
      "Un service li√© est disponible pour SAP et un pour OData.\n",
      "3.\n",
      "Parmi les instructions suivantes, laquelle d√©crit le mieux une m√©thode d‚Äôutilisation avec Azure Synapse Studio ?\n",
      "Les rapports Power BI doivent √™tre cr√©√©s s√©par√©ment de Azure Synapse Studio.\n",
      "La gestion et la surveillance des travaux ou des pipelines peuvent √™tre effectu√©es dans Azure Synapse Studio.\n",
      "Les scripts T-SQL et les notebooks personnalis√©s peuvent √™tre utilis√©s pour interagir avec les moteurs analytiques dans Azure Synapse Studio.\n",
      "Correct. Le sc√©nario de module a utilis√© un script T-SQL, mais vous pouvez √©galement utiliser des notebooks personnalis√©s.\n",
      "4.\n",
      "Quelles sont les meilleures options de donn√©es dans Synapse Analytics ?\n",
      "Synapse Analytics permet l'importation de donn√©es √† partir de plusieurs sources de donn√©es.\n",
      "Correct. Le sc√©nario de module implique deux sources de donn√©es, mais vous pouvez en ajouter d‚Äôautres.\n",
      "Synapse Analytics peut combiner des donn√©es √† partir d‚Äôun maximum de deux sources.\n",
      "Synapse Analytics fonctionne uniquement avec les donn√©es contenues dans les pools SQL.\n",
      "------------------------\n",
      "1.\n",
      "Quelle fonction devez-vous utiliser pour lancer des essais Hyperopt ?\n",
      "hyperopt.tpe.suggest\n",
      "Incorrect. La constante hyperopt.tpe.suggest est utilis√©e pour sp√©cifier un algorithme de recherche TPE.\n",
      "hyperopt.hp.choice\n",
      "hyperopt.fmin\n",
      "Correct. La fonction fmin contr√¥le le processus Hyperopt pour r√©duire une fonction objective.\n",
      "2.\n",
      "Lequel de ces objets d√©finit l‚Äôensemble de valeurs d‚Äôhyperparam√®tres qu‚ÄôHyperopt peut mixer lors de l‚Äôex√©cution des essais ?\n",
      "Fonction objective\n",
      "Incorrect. Une fonction objective ne d√©finit pas un ensemble de valeurs d‚Äôhyperparam√®tres possibles.\n",
      "Espace de recherche\n",
      "Correct. Un espace de recherche d√©finit un ensemble de valeurs d‚Äôhyperparam√®tres possibles.\n",
      "Algorithme de recherche\n",
      "3.\n",
      "Quelle classe devez-vous utiliser pour suivre les d√©tails de chaque ex√©cution de r√©glage des hyperparam√®tres lors de l‚Äôutilisation de Spark MLLib ?\n",
      "Essais\n",
      "Correct. La classe Essais effectue le suivi des d√©tails de chaque ex√©cution d‚Äô√©valuation.\n",
      "SparkTrials\n",
      "RDD\n",
      "------------------------\n",
      "1.\n",
      "Que fait AutoML ?\n",
      "Entra√Æne un mod√®le bas√© sur des donn√©es que vous sp√©cifiez en utilisant plusieurs algorithmes et hyperparam√®tres afin d‚Äôidentifier le meilleur mod√®le.\n",
      "Correct. AutoML teste plusieurs combinaisons d'entra√Ænement afin de trouver le mod√®le optimal pour vos donn√©es.\n",
      "Ex√©cute des scripts d‚Äôentra√Ænement de mod√®le en fonction d'une planification que vous sp√©cifiez pour automatiser les op√©rations Machine Learning.\n",
      "Entra√Æne et d√©ploie des mod√®les Machine Learning destin√©s √† √™tre utilis√©s dans les v√©hicules √† conduite autonome.\n",
      "2.\n",
      "Vous comptez utiliser AutoML dans l'interface utilisateur Azure Databricks. Que devez-vous faire en premier ?\n",
      "Entra√Æner un mod√®le de r√©f√©rence en utilisant la biblioth√®que Spark MLlib.\n",
      "Charger les donn√©es d'entra√Ænement dans une table de votre espace de travail Azure Databricks.\n",
      "Correct. Vous devez fournir les donn√©es d'entra√Ænement sous la forme d'une table dans le metastore Hive.\n",
      "Cr√©er un notebook vide.\n",
      "3.\n",
      "Vous souhaitez utiliser l'API AutoML pour entra√Æner un mod√®le qui pr√©dit le prix attendu d'une maison en fonction de la taille, du nombre de chambres et du code postal ? Quelle m√©thode devez-vous utiliser ?\n",
      "classify\n",
      "regress\n",
      "Correct. Un mod√®le de r√©gression pr√©dit une valeur num√©rique.\n",
      "forecast\n",
      "Incorrect. Un mod√®le de pr√©vision pr√©dit des valeurs en fonction du temps.\n",
      "------------------------\n",
      "1.\n",
      "Un script Python pour la formation d‚Äôun mod√®le est cr√©√© dans Azure Databricks et attach√© √† un cluster avec Databricks Runtime pour Machine Learning. Pour ex√©cuter le code et activer le MLflow automatis√© lors de l‚Äôoptimisation des hyperparam√®tres, quelle m√©thode doit √™tre utilis√©e ?\n",
      "ParamGridBuilder()\n",
      "CrossValidator\n",
      "Correct. Vous pouvez utiliser CrossValidator ou TrainValidationSplit pour optimiser les hyperparam√®tres avec MLflow automatis√©.\n",
      "RegressionEvaluator()\n",
      "2.\n",
      "Quels sont les arguments n√©cessaires pour ex√©cuter la fonction Hyperopt fmin() ?\n",
      "La m√©trique d‚Äô√©valuation, le mod√®le et les donn√©es.\n",
      "La fonction objective, l‚Äôespace de recherche et le mod√®le.\n",
      "La fonction objective, l‚Äôespace de recherche et l‚Äôalgorithme de recherche.\n",
      "Correct. La fonction objective fn, l‚Äôespace de recherche space et l‚Äôalgorithme de recherche algo sont des arguments pour la fonction fmin().\n",
      "------------------------\n",
      "1.\n",
      "Quelle est la fonction du terme ¬´ P ¬ª dans le contr√¥le PID ?\n",
      "Applique l‚Äôexpertise humaine √† une d√©cision.\n",
      "Pr√©dit l‚Äôimpact d‚Äôune d√©cision de contr√¥le.\n",
      "√âvite le d√©passement du contr√¥leur.\n",
      "Incorrect. Le ¬´ I ¬ª ou partie int√©grale du contr√¥leur PID est ce qui permet d‚Äô√©viter le d√©passement du syst√®me.\n",
      "Dirige le syst√®me vers l‚Äôobjectif cible.\n",
      "Un ¬´ P ¬ª correct signifie Proportionnel et il dirige les syst√®mes vers la cible.\n",
      "2. Quelle technique de th√©orie du contr√¥le comprend √©galement une routine d‚Äôoptimisation ?\n",
      "PID\n",
      "Ouvrir le contr√¥le en boucle\n",
      "Contr√¥le de transfert de flux\n",
      "Contr√¥le pr√©dictif du mod√®le (MPC)\n",
      "Correct. MPC contient un mod√®le du syst√®me ou du processus et un algorithme d‚Äôoptimisation en arri√®re-plan.\n",
      "3. Parmi les techniques suivantes, laquelle n‚Äôest PAS une technique d‚Äôintelligence automatis√©e ?\n",
      "Syst√®mes experts\n",
      "Incorrect. Les syst√®mes experts ou ¬´ manuels ¬ª sont une forme d‚Äôintelligence automatis√©e.\n",
      "R√©seaux neuronaux\n",
      "Correct. Les r√©seaux neuronaux ou les algorithmes Machine Learning appartiennent au groupe de l‚Äôintelligence autonome.\n",
      "Algorithmes d‚Äôoptimisation\n",
      "Th√©orie du contr√¥le\n",
      "4. Comment la th√©orie du contr√¥le d√©termine-t-elle la prochaine action √† entreprendre dans un syst√®me ?\n",
      "Recherchez les options possibles et s√©lectionnez-les en fonction de crit√®res objectifs.\n",
      "Essayez des actions et testez si elles sont plus proches ou plus √©loign√©es de l‚Äôobjectif.\n",
      "Incorrect. (Profond) L‚Äôapprentissage par renforcement est la technologie qui effectue des essais et des erreurs avec une fonction d‚Äôobjectif ou de r√©compense.\n",
      "Calculez l‚Äôaction suivante √† l‚Äôaide d‚Äô√©quations math√©matiques, de physique ou de chimie.\n",
      "Correct. La th√©orie du contr√¥le utilise les math√©matiques pour d√©terminer la meilleure action √† entreprendre.\n",
      "Recherchez les options d‚Äôune table.\n",
      "5. Parmi les phrases suivantes, laquelle d√©crit les points forts des algorithmes d‚Äôoptimisation ?\n",
      "Convient aux situations pour lesquelles vous n‚Äôavez pas beaucoup d‚Äôexpertise sur la fa√ßon de contr√¥ler le syst√®me.\n",
      "Correct. Les algorithmes d‚Äôoptimisation sont l‚Äôoutil id√©al √† explorer lorsque nous ne connaissons pas la t√¢che ou l‚Äôespace de recherche.\n",
      "Optimal pour comprendre les concepts et les strat√©gies n√©cessaires √† l‚Äôex√©cution de la t√¢che.\n",
      "G√©n√®re des d√©cisions rapidement avec peu de ressources informatiques requises.\n",
      "S‚Äôadapte bien aux conditions floues et incertaines.\n",
      "Incorrect. Les algorithmes d‚Äôoptimisation ne s‚Äôadaptent pas aux conditions floues ou/et incertaines.\n",
      "------------------------\n",
      "6. Quelle technique d‚Äôintelligence automatis√©e choisiriez-vous pour contr√¥ler la vitesse des rotors d‚Äôun drone ?\n",
      "Th√©orie du contr√¥le\n",
      "Correct. C‚Äôest la technologie la plus simple et la plus fiable pour le contr√¥le de bas niveau, ce qui est n√©cessaire pour contr√¥ler les rotors d‚Äôun drone.\n",
      "Syst√®mes experts\n",
      "Optimization\n",
      "Programmation proc√©durale\n",
      "------------------------\n",
      "1. Vous pr√©voyez d'utiliser un conteneur Cognitive Services sur un h√¥te Docker local. Parmi les affirmations suivantes, laquelle est vraie ?\n",
      "Les applications clientes doivent transmettre une cl√© d'abonnement au point de terminaison de la ressource Azure avant d'utiliser le conteneur.\n",
      "Le conteneur doit pouvoir se connecter au point de terminaison de la ressource Azure pour envoyer les donn√©es d'utilisation √† des fins de facturation.\n",
      "Correct. Les m√©triques d'utilisation du conteneur sont envoy√©es √† la ressource Azure Cognitive Services √† des fins de facturation.\n",
      "Toutes les donn√©es transmises au conteneur par l'application cliente sont achemin√©es vers le point de terminaison de la ressource Azure.\n",
      "------------------------\n",
      "2. Parmi les param√®tres suivants, lequel devez-vous sp√©cifier lors du d√©ploiement d'une image conteneur Cognitive Services ?\n",
      "CLUF\n",
      "Correct. Vous devez sp√©cifier un param√®tre EULA (CLUF) avec la valeur ¬´ Yes ¬ª pour accepter explicitement le contrat de licence.\n",
      "ResourceGroup\n",
      "SubscriptionName\n",
      "------------------------\n",
      "3. Vous pr√©voyez d‚Äôutiliser la fonctionnalit√© de d√©tection de la langue du service Langage de Cognitive Services dans un conteneur. Quelle image conteneur devez-vous d√©ployer ?\n",
      "mcr.microsoft.com/azure-cognitive-services/textanalytics\n",
      "mcr.microsoft.com/azure-cognitive-services\n",
      "mcr.microsoft.com/azure-cognitive-services/textanalytics/language\n",
      "Correct. Vous devez d√©ployer l'image sp√©cifique √† la d√©tection de la langue.\n",
      "------------------------\n",
      "1. Vous envisagez d‚Äôutiliser le param√©trage d‚Äôhyperparam√®tres pour rechercher des valeurs discr√®tes optimales pour un ensemble d‚Äôhyperparam√®tres. Vous souhaitez essayer toutes les combinaisons possibles d‚Äôun ensemble de valeurs discr√®tes sp√©cifi√©es. Quel type d‚Äô√©chantillonnage devez-vous utiliser ?\n",
      "√âchantillonnage al√©atoire\n",
      "√âchantillonnage par grille\n",
      "Correct. Vous devez utiliser un √©chantillonnage par grille pour tester l‚Äôensemble des combinaisons de valeurs d‚Äôhyperparam√®tres discrets.\n",
      "√âchantillonnage bay√©sien\n",
      "2. Vous utilisez le r√©glage des hyperparam√®tres pour effectuer l‚Äôapprentissage d‚Äôun mod√®le optimal bas√© sur une m√©trique cible nomm√©e ¬´ AUC ¬ª. Que devez-vous faire dans votre script de formation ?\n",
      "Importez le package de journalisation et utilisez une instruction logging.info() pour consigner l‚ÄôAUC.\n",
      "Incluez une instruction print() pour √©crire la valeur AUC dans le flux de sortie standard.\n",
      "Utilisez une instruction mlflow.log_metric() pour journaliser la valeur AUC.\n",
      "Correct. Votre script doit utiliser MLflow pour consigner la m√©trique principale sur l‚Äôex√©cution √† l‚Äôaide du m√™me nom que celui sp√©cifi√© dans le travail de balayage.\n",
      "------------------------\n",
      "Vous cr√©ez un pipeline qui comprend deux √©tapes. L‚Äô√©tape 1 pr√©pare certaines donn√©es et l‚Äô√©tape 2 utilise les donn√©es pr√©trait√©es pour effectuer l‚Äôapprentissage d‚Äôun mod√®le. Quelle option devez-vous utiliser comme entr√©e √† la deuxi√®me √©tape pour effectuer l‚Äôapprentissage du mod√®le ?\n",
      "pipeline_job_input\n",
      "prep_data.outputs.output_data\n",
      "Correct. prep_data.outputs.output_data est la sortie de l‚Äô√©tape qui pr√©pare les donn√©es.\n",
      "train_model.outputs.model_output\n",
      "2.\n",
      "Vous avez cr√©√© un pipeline que vous souhaitez ex√©cuter chaque semaine. Vous souhaitez adopter une approche simple pour cr√©er une planification. Quelle classe pouvez-vous utiliser pour cr√©er la planification qui s‚Äôex√©cute une fois par semaine ?\n",
      "RecurrencePattern\n",
      "JobSchedule\n",
      "RecurrenceTrigger\n",
      "Correct. Vous avez besoin de la classe RecurrenceTrigger pour cr√©er une planification qui s‚Äôex√©cute √† intervalles r√©guliers.\n",
      "Avec quel logiciel de gestion de version Azure Data Factory s'int√®gre-t-il ?\n",
      "Team Foundation Server.\n",
      "Source Safe.\n",
      "R√©f√©rentiels Git.\n",
      "Correct. Azure Data Factory vous permet de configurer un r√©f√©rentiel git avec Azure Repos ou GitHub. C‚Äôest un syst√®me de gestion de version qui facilite le suivi des modifications et la collaboration.\n",
      "2. Quelle fonctionnalit√© permet d‚Äôapporter des modifications sur les projets Azure Data Factory dans une branche personnalis√©e cr√©√©e avec la branche principale dans un r√©f√©rentiel Git ?\n",
      "Repo.\n",
      "Demande de tirage.\n",
      "Correct. Une fois que le d√©veloppeur est satisfait de ses modifications, il cr√©e une demande de tirage (pull) √† partir de sa branche de fonctionnalit√© vers la branche principale ou la branche de collaboration pour que ces modifications soient examin√©es par des pairs.\n",
      "Commiter.\n",
      "3. Quelle fonctionnalit√© dans les alertes peut √™tre utilis√©e pour d√©terminer la fa√ßon dont une alerte est d√©clench√©e ?\n",
      "Ajouter une r√®gle.\n",
      "Incorrect. Une r√®gle est la d√©finition principale de l‚Äôalerte qui comprend un nom de r√®gle et une description.\n",
      "Ajoutez une gravit√©.\n",
      "Ajouter des crit√®res.\n",
      "Correct. La fonctionnalit√© ¬´ Ajouter des crit√®res ¬ª vous permet de d√©terminer la fa√ßon dont une alerte est d√©clench√©e\n",
      "------------------------\n",
      "1. Quel composant Hadoop est utilis√© pour g√©rer les ressources sur un syst√®me Hadoop ?\n",
      "YARN\n",
      "Correct. Il s‚Äôagit du composant charg√© de g√©rer les ressources sur un cluster Hadoop.\n",
      "Spark\n",
      "MapReduce\n",
      "Inexact. MapReduce est un mod√®le de programmation qui vous permet de traiter et d‚Äôanalyser des donn√©es.\n",
      "2. Dans quel type de syst√®me de fichiers Apache Hadoop stocke-t-il des donn√©es ?\n",
      "Il n‚Äôa pas de stockage. Les donn√©es sont stock√©es en m√©moire.\n",
      "RDD\n",
      "HDFS\n",
      "Correct. HDFS est l‚Äôacronyme de ¬´ Hadoop Distributed File System ¬ª, magasin de donn√©es d‚Äôun syst√®me Hadoop.\n",
      "3. Laquelle des options suivantes est un framework de traitement parall√®le ?\n",
      "Apache Hive\n",
      "Apache Spark\n",
      "Correct. Apache Spark prend en charge le traitement en m√©moire, qui aide √† am√©liorer les performances des applications d‚Äôanalytique de Big Data.\n",
      "Apache Kafka\n",
      "4. Dans un cluster Hadoop sur HDInsight, lequel des n≈ìuds suivants est responsable du traitement des donn√©es ?\n",
      "N≈ìud principal\n",
      "N≈ìud Worker\n",
      "Correct. Les n≈ìuds Worker sont responsables du traitement des donn√©es dans un cluster.\n",
      "5. Lequel des sc√©narios suivants pour le traitement de Big Data permet √† une organisation de pr√©parer le Big Data √† une analyse plus pouss√©e ?\n",
      "Entrep√¥t de donn√©es\n",
      "Science des donn√©es\n",
      "Traitement par lots\n",
      "Correct. Les organisations utilisent des t√¢ches de traitement par lots pour pr√©parer le Big Data √† une analyse plus pouss√©e.\n",
      "1. Quel est le composant Azure Data Factory qui orchestre un travail de transformation ou ex√©cute une commande de d√©placement des donn√©es ?\n",
      "Services li√©s\n",
      "Groupes de donn√©es\n",
      "Activit√©s\n",
      "Correct. Les activit√©s contiennent la logique de transformation ou les commandes d‚Äôanalyse du travail d‚ÄôAzure Data Factory.\n",
      "2. Vous d√©placez des donn√©es d‚Äôun magasin Azure Data Lake Gen2 vers Azure Synapse Analytics. Quel runtime d‚Äôint√©gration Azure Data Factory est utilis√© dans une activit√© de copie de donn√©es ?\n",
      "Azure-SSIS\n",
      "Azure\n",
      "Correct. Quand vous d√©placez des donn√©es entre des technologies de plateforme de donn√©es Azure, le runtime d‚Äôint√©gration Azure est utilis√© lors de la copie des donn√©es entre deux plateformes de donn√©es Azure.\n",
      "Auto-h√©berg√©\n",
      "Incorrect. Le runtime d‚Äôint√©gration auto-h√©berg√© est utilis√© lors du d√©placement des donn√©es √† partir de r√©seaux priv√©s vers le cloud et vice versa\n",
      "Un scientifique des donn√©es a cr√©√© un script qui effectue l'apprentissage d‚Äôun mod√®le Machine Learning √† l‚Äôaide de la biblioth√®que open source scikit-learn. Le scientifique des donn√©es souhaite tester rapidement l‚Äôex√©cution du script sur le cluster de calcul existant, quel type d‚Äôenvironnement le scientifique des donn√©es doit-il utiliser ?\n",
      "Default\n",
      "Incorrect. Les environnements par d√©faut n‚Äôexistent pas.\n",
      "Organis√©\n",
      "Correct. Les environnements cur√©s sont id√©aux pour acc√©l√©rer le temps de d√©veloppement.\n",
      "Custom\n",
      "2. Un travail de commande √©choue avec le message d‚Äôerreur indiquant qu‚Äôun module est introuvable. Le scientifique des donn√©es a utilis√© un environnement cur√© et souhaite ajouter un package Python sp√©cifique pour cr√©er un environnement personnalis√© et ex√©cuter correctement le travail. Quel fichier doit √™tre cr√©√© avant de cr√©er l‚Äôenvironnement personnalis√© qui utilise un environnement cur√© comme r√©f√©rence ?\n",
      "Script d‚Äôentra√Ænement\n",
      "Image Docker\n",
      "Sp√©cification Conda\n",
      "Correct. Vous pouvez r√©pertorier les packages Python dans un fichier de sp√©cification conda.\n",
      "1. Quelle est la bonne m√©thode pour journaliser une m√©trique de mod√®le, _rmse, dans MLflow ?\n",
      "mlflow.log(\"RMSE\", _rmse)\n",
      "mlflow.log_artifact(\"RMSE\", _rmse)\n",
      "mlflow.log_metric(\"RMSE\", _rmse)\n",
      "Correct. Le module MLflow fournit des API ¬´ Fluent ¬ª et log_metric() est la bonne m√©thode pour journaliser une m√©trique de mod√®le.\n",
      "2. L√©on souhaite ex√©cuter une exp√©rience Azure Machine Learning dans Azure Databricks. Une exp√©rience MLflow est configur√©e et L√©on est sur le point de l‚Äôex√©cuter. Il se rend compte qu‚Äôil a oubli√© une √©tape. Qu‚Äôaurait-il fallu faire en premier ?\n",
      "Inscrire le mod√®le dans Azure Machine Learning.\n",
      "Incorrect. Il n‚Äôest pas n√©cessaire d‚Äôinscrire un mod√®le pour ex√©cuter une exp√©rience.\n",
      "Journaliser les m√©triques d‚Äôexp√©rience avec MLflow.\n",
      "Configurer l‚ÄôURI MLflow Tracking pour utiliser Azure Machine Learning.\n",
      "Correct. L‚ÄôURI MLflow Tracking doit √™tre pr√©alablement configur√© pour utiliser AML.\n",
      "3. Vous souhaitez ex√©cuter un pipeline Azure Machine Learning. La premi√®re √©tape du pipeline consiste √† pr√©traiter les donn√©es en ex√©cutant un script Python sur Azure Databricks Compute. La configuration est d√©finie et vous devez maintenant cr√©er la capacit√© de calcul. Quel type d‚Äôobjet devez-vous utiliser ?\n",
      "DatabricksAttachConfiguration\n",
      "ComputeTarget\n",
      "Correct. Une fois la configuration d√©finie, ComputeTarget doit √™tre utilis√© pour cr√©er la capacit√© de calcul.\n",
      "DatabricksCompute\n",
      "1. Plusieurs fichiers sont stock√©s dans un conteneur priv√© dans Stockage Blob Azure. Une ressource de donn√©es Azure Machine Learning inscrite existante pointe vers le dossier contenant les fichiers. Pour utiliser les fichiers du dossier comme entr√©e pour un travail Machine Learning, quel pr√©fixe doit √™tre utilis√© lors de la d√©finition de path dans le fichier YAML du travail ?\n",
      "https:\n",
      "wasbs:\n",
      "azureml:\n",
      "Correct. Utilisez azureml: lorsque vous faites r√©f√©rence √† une ressource de donn√©es inscrite existante.\n",
      "2. Si vous souhaitez ex√©cuter un workflow compos√© de plusieurs scripts Python qui doivent s‚Äôex√©cuter de mani√®re s√©quentielle, quel type de travail devez-vous sp√©cifier dans le fichier YAML du travail ?\n",
      "Commande\n",
      "Pipeline\n",
      "Correct. Utiliser un travail de pipeline pour ex√©cuter plusieurs scripts regroup√©s dans un workflow.\n",
      "Sweep\n",
      "------------------------\n",
      "1. Qu‚Äôest-ce qu‚Äôun connecteur pris en charge pour le param√©trage int√©gr√© ?\n",
      "Azure Data Lake Storage Gen2\n",
      "Azure Synapse Analytics\n",
      "Correct. Azure Synapse Analytics est un connecteur pris en charge pour le param√©trage int√©gr√© des services li√©s dans Azure Data Factory.\n",
      "Azure Key Vault\n",
      "2. Qu‚Äôest-ce qu‚Äôun exemple de cr√©ation de branche d‚Äôactivit√©s utilis√©e dans les flux de contr√¥le ?\n",
      "If-condition\n",
      "Correct. Un exemple de cr√©ation de branche d‚Äôactivit√©s est l‚Äôactivit√© The If-condition qui est similaire √† une instruction if fournie dans des langages de programmation.\n",
      "Until-condition\n",
      "Lookup-condition\n",
      "------------------------\n",
      "1.\n",
      "Quelle cible de calcul est utilis√©e lorsque AutoML s‚Äôex√©cute via le pool Spark dans Synapse Analytics ?\n",
      "Calcul local.\n",
      "Correct. Lorsque vous n‚Äôex√©cutez pas votre exp√©rience sur les ressources de calcul d‚ÄôAzure Machine Learning, l‚Äôenvironnement d‚Äôex√©cution est consid√©r√© comme un calcul local.\n",
      "Calcul distant.\n",
      "Calcul cloud.\n",
      "Incorrect. Il n‚Äôexiste aucune cible de calcul de ce type pour Azure Machine Learning.\n",
      "2.\n",
      "Qu‚Äôest-ce qui peut aider √† s‚Äôassurer que les mod√®les AutoML prennent en charge le format ONNX ?\n",
      "D√©finir enable_onnx_compatible_models sur False dans AutoMLConfig.\n",
      "Activer la compatibilit√© avec les mod√®les ONNX sur le portail lors de la configuration du mod√®le d‚Äôenrichissement.\n",
      "Correct. La compatibilit√© avec les mod√®les ONNX permet de s‚Äôassurer que le mod√®le prend en charge ONNX.\n",
      "Utiliser l‚Äôespace de travail Azure Machine Learning au lieu de l‚Äôespace de travail Azure Synapse.\n",
      "3.\n",
      "Parmi les affirmations suivantes sur la commande T-SQL PREDICT, laquelle est correcte ?\n",
      "Elle g√©n√®re une valeur pr√©dite ou des scores bas√©s sur un mod√®le stock√© dans les limites de l‚Äôentrep√¥t de donn√©es.\n",
      "Correct. Avec T-SQL PREDICT, vous pouvez mettre vos mod√®les Machine Learning entra√Æn√©s avec les donn√©es historiques et les scorer dans les limites s√©curis√©es de votre entrep√¥t de donn√©es.\n",
      "Elle ne prend pas en charge le format ONNX pour les mod√®les dans Azure SQL Managed Instance, Azure SQL Edge et Azure Synapse Analytics.\n",
      "Des autorisations sp√©ciales sont requises pour utiliser la commande PREDICT.\n",
      "------------------------\n",
      "1.\n",
      "Une personne malveillante peut bloquer votre site web en envoyant un volume important de trafic r√©seau √† vos serveurs. Quel service Azure peut aider Tailwind Traders √† prot√©ger son instance App Service contre ce type d‚Äôattaque ?\n",
      "Pare-feu Azure\n",
      "Groupes de s√©curit√© r√©seau\n",
      "Protection DDoS dans Azure\n",
      "DDoS Protection aide √† prot√©ger vos ressources Azure contre les attaques DDoS. Une attaque DDoS tente de saturer et d‚Äô√©puiser les ressources d‚Äôune application, afin de ralentir l‚Äôapplication ou de l‚Äôemp√™cher de r√©pondre aux utilisateurs l√©gitimes.\n",
      "2.\n",
      "Quelle est la meilleure fa√ßon pour Tailwind Traders de limiter tout le trafic sortant des machines virtuelles destin√© √† des h√¥tes connus ?\n",
      "Configurer Azure DDoS Protection pour limiter l‚Äôacc√®s r√©seau aux ports et h√¥tes de confiance.\n",
      "Cr√©er des r√®gles d‚Äôapplication dans le pare-feu Azure.\n",
      "Le pare-feu Azure vous permet de limiter le trafic HTTP/S sortant √† une liste sp√©cifi√©e de noms de domaines complets (FQDN).\n",
      "Veiller √† ce que toutes les applications en cours d‚Äôex√©cution communiquent uniquement avec des ports et des h√¥tes de confiance.\n",
      "3.\n",
      "Comment la soci√©t√© Tailwind Traders peut-elle impl√©menter le plus facilement possible une strat√©gie Refuser par d√©faut pour que les machines virtuelles ne puissent pas se connecter entre elles ?\n",
      "Allouer chaque machine virtuelle sur son propre r√©seau virtuel.\n",
      "Cr√©er une r√®gle de groupe de s√©curit√© r√©seau qui emp√™che l‚Äôacc√®s √† partir d‚Äôune autre machine virtuelle sur le m√™me r√©seau.\n",
      "Une r√®gle de groupe de s√©curit√© r√©seau vous permet de filtrer le trafic √©chang√© avec les ressources par adresse IP source ou de destination, port ou protocole.\n",
      "Configurer Azure DDoS Protection pour limiter l‚Äôacc√®s r√©seau au sein du r√©seau virtuel.\n",
      "------------------------\n",
      "1.\n",
      "Quelle √©tape recommanderiez-vous √† l‚Äô√©quipe d‚Äôeffectuer en premier pour comparer le co√ªt d‚Äôex√©cution de ces environnements sur Azure et dans son centre de donn√©es ?\n",
      "Il s‚Äôagit simplement d‚Äôenvironnements de test : les d√©marrer et regarder la facture √† la fin du mois.\n",
      "Partir du principe que les co√ªts d‚Äôex√©cution dans le cloud sont √† peu pr√®s les m√™mes que dans le centre de donn√©es.\n",
      "Ex√©cuter la calculatrice du co√ªt total de possession.\n",
      "L‚Äôex√©cution de la calculatrice du co√ªt total de possession est un bon choix de d√©part, car elle fournit une comparaison pr√©cise des co√ªts d‚Äôex√©cution de charges de travail dans le centre de donn√©es et sur Azure, certifi√©e par une soci√©t√© de recherche ind√©pendante.\n",
      "2.\n",
      "Quel est le meilleur moyen de garantir que l‚Äô√©quipe de d√©veloppement ne provisionne pas trop de machines virtuelles en m√™me temps ?\n",
      "Ne rien faire. Laisser l‚Äô√©quipe de d√©veloppement utiliser ce dont elle a besoin.\n",
      "Appliquer des limites de d√©pense √† l‚Äôabonnement Azure de l‚Äô√©quipe de d√©veloppement.\n",
      "Si vous d√©passez votre limite de d√©pense, les ressources actives sont lib√©r√©es. Vous pouvez ensuite d√©cider d‚Äôaugmenter votre limite ou de provisionner moins de ressources.\n",
      "Donner verbalement au responsable du d√©veloppement un budget et le tenir responsable des d√©passements.\n",
      "3.\n",
      "Quel est le moyen le plus efficace pour l‚Äô√©quipe de test de r√©duire les co√ªts des machines virtuelles le week-end, quand les testeurs ne travaillent pas ?\n",
      "Supprimer les machines virtuelles avant le week-end et cr√©er un ensemble la semaine suivante.\n",
      "Si vous supprimez vos machines virtuelles quand elles ne sont pas utilis√©es, vous perdez √©galement tous les disques durs associ√©s. La recr√©ation de l‚Äôenvironnement au d√©but de chaque semaine peut prendre du temps.\n",
      "Lib√©rer les machines virtuelles inutilis√©es.\n",
      "Quand vous lib√©rez des machines virtuelles, les disques durs et les donn√©es associ√©s sont conserv√©s dans Azure. Mais la consommation du processeur ou du r√©seau ne vous est pas factur√©e, ce qui peut r√©duire les co√ªts.\n",
      "Laisser tout fonctionner. Azure facture uniquement le temps processeur que vous utilisez.\n",
      "4.\n",
      "Les ressources dans les environnements Dev et Test sont pay√©es par diff√©rents services. Quelle est la meilleure fa√ßon de classer les co√ªts par service ?\n",
      "Appliquer √† chaque machine virtuelle une √©tiquette qui identifie le service √† facturer.\n",
      "Vous pouvez appliquer des √©tiquettes √† des groupes de ressources Azure pour organiser les donn√©es de facturation.\n",
      "R√©partir le co√ªt uniform√©ment entre les services.\n",
      "Garder une feuille de calcul listant les ressources de chaque √©quipe.\n",
      "------------------------\n",
      "1. Une entreprise d√©ploie la technologie 5G. Parmi les raisons suivantes, lesquelles sont une raison valable pour d√©ployer la 5G dans l‚Äôentreprise :\n",
      "L‚Äôentreprise doit d√©ployer des capteurs IoT n√©cessitant une faible latence et une haute densit√©\n",
      "Un besoin de faible latence dans les sc√©narios de haute densit√© de capteurs est un cas d‚Äôutilisation valide de la 5G\n",
      "L‚Äôentreprise doit connecter des capteurs au Wi-Fi\n",
      "L‚Äôentreprise doit utiliser plusieurs m√©canismes de connectivit√© de proximit√© comme le Bluetooth\n",
      "2. Le d√©ploiement de la 5G dans une entreprise qui veut garantir la connectivit√©. Laquelle de ces affirmations serait la plus pragmatique pour garantir la connectivit√© en 5G ?\n",
      "Elle doit envisager davantage de capteurs dans l‚Äôentreprise\n",
      "Elle doit envisager des connexions plus s√©curis√©es\n",
      "Elle doit tenir compte du LTE en plus de la 5G\n",
      "La r√©trocompatibilit√© avec le LTE assure une connectivit√© garantie m√™me si les d√©ploiements de la 5G sont retard√©s.\n",
      "3.\n",
      "Les serveurs de p√©riph√©rie aident dans Azure Private MEC. Quel est l‚Äôavantage de l‚Äôutilisation de serveurs en p√©riph√©rie dans Azure Private MEC ?\n",
      "Les serveurs en p√©riph√©rie aident √† pr√©traiter les donn√©es\n",
      "Les serveurs en p√©riph√©rie aident √† pr√©traiter les donn√©es afin que moins de donn√©es soient envoy√©es au serveur.\n",
      "Les serveurs en p√©riph√©rie acc√©l√®rent la connectivit√©\n",
      "Les serveurs en p√©riph√©rie n‚Äôacc√©l√®rent pas n√©cessairement la connectivit√©.\n",
      "Les serveurs en p√©riph√©rie aident √† se connecter au Wi-Fi et √† la 5G\n",
      "1. Les solutions 5G pour l‚Äôentreprise sont g√©n√©ralement le fruit d‚Äôune collaboration entre l‚Äôentreprise cliente, l‚Äôop√©rateur de r√©seau mobile et l‚Äôint√©grateur syst√®me. Quelle en est la raison principale ?\n",
      "Les solutions 5G pour l‚Äôentreprise ont besoin d‚Äôune faible latence\n",
      "Bien que les solutions 5G pour l‚Äôentreprise n√©cessitent une faible latence, ce n‚Äôest pas la raison principale d‚Äôune approche collaborative\n",
      "Les solutions 5G pour l‚Äôentreprise doivent √™tre r√©trocompatibles avec des r√©seaux plus anciens comme LTE\n",
      "Les solutions 5G pour l‚Äôentreprise prennent en charge le r√©seau 5G, ce qui conduit √† la n√©cessit√© d‚Äôune collaboration entre plusieurs partenaires\n",
      "Les solutions 5G pour l‚Äôentreprise doivent prendre en compte le r√©seau sous-jacent et les fonctionnalit√©s de l‚Äôop√©rateur de r√©seau mobile.\n",
      "2. Azure Private MEC est l‚Äôinterface principale des applications p√©riph√©riques et de la 5G pour l‚Äôentreprise. Laquelle de ces fonctions est l‚Äôobjectif principal d‚ÄôAzure Private MEC ?\n",
      "Azure Private MEC vous permet d‚Äôimpl√©menter une solution de bout en bout pour la 5G √† l‚Äôaide d‚Äôoutils familiers\n",
      "Azure Private MEC aide l‚Äô√©cosyst√®me des d√©veloppeurs en tirant parti des outils existants pour la 5G\n",
      "Azure Private MEC offre une s√©curit√© de bout en bout\n",
      "Azure Private MEC permet d‚Äôint√©grer des fournisseurs tiers\n",
      "3.\n",
      "L‚Äôanalytique p√©riph√©rique est utilis√©e dans les situations o√π le temps de r√©ponse doit √™tre rapide avec une latence tr√®s faible. Les donn√©es vid√©o sont √©galement captur√©es et envoy√©es dans le cloud. Quel type d‚Äôanalytique peut √™tre effectu√© dans le cloud sur la vid√©o stock√©e par l‚Äôentreprise ?\n",
      "Analytique p√©riph√©rique suppl√©mentaire qui compl√®te le travail effectu√© dans l‚Äôentreprise\n",
      "L‚Äôanalytique p√©riph√©rique n‚Äôest pas effectu√©e dans le cloud\n",
      "Tendances √† long terme tir√©es de la vid√©o collect√©e dans le cloud\n",
      "La vid√©o stock√©e peut √™tre utilis√©e pour analyser les tendances √† long terme\n",
      "Vous ex√©cutez des applications de vision par ordinateur\n",
      "1.\n",
      "Supposons que vous g√©rez des appareils qui prennent en charge plusieurs m√©canismes de connectivit√©. Vous devez continuellement am√©liorer les fonctionnalit√©s de l‚Äôappareil et r√©pondre aux menaces de s√©curit√©. Azure Sphere est appropri√© pour fournir des solutions de s√©curit√© pour les appareils IoT pour ce sc√©nario, car :\n",
      "Azure Sphere fonctionne avec un grand nombre de fabricants de mat√©riel.\n",
      "Les appareils Azure Sphere peuvent recevoir des mises √† jour des applications et du syst√®me d‚Äôexploitation par voie hertzienne √† l‚Äôaide de m√©canismes de connectivit√©.\n",
      "La possibilit√© de recevoir des mises √† jour par voie hertzienne aide √† r√©pondre aux menaces de s√©curit√© courantes.\n",
      "Azure Sphere prend en charge la connectivit√© cellulaire.\n",
      "2.\n",
      "Le syst√®me d‚Äôexploitation d‚ÄôAzure Sphere prend actuellement en charge deux types de connectivit√© de r√©seau local. Si vous ne souhaitez pas √™tre affect√© par des facteurs locaux tels que les murs, les armoires et les interf√©rences d‚Äôautres appareils √©lectroniques pour acc√©l√©rer la vitesse, quelle connectivit√© devez-vous utiliser ?\n",
      "Cellulaire\n",
      "Wi-Fi\n",
      "Ethernet\n",
      "La connectivit√© Ethernet n‚Äôest pas affect√©e par les facteurs locaux √† proximit√©.\n",
      "3.\n",
      "Azure Sphere ne prend pas en charge la s√©curit√© au-del√† des composants de connectivit√© du routeur et du modem cellulaire. Lorsque vous vous connectez Azure Sphere aux r√©seaux cellulaires, quelles sont les pr√©cautions suivantes √† suivre pour cr√©er un syst√®me √† l‚Äôaide d‚Äôun routeur mobile ?\n",
      "Les parties hors Azure Sphere de votre solution doivent √™tre correctement s√©curis√©es pour garantir que le syst√®me global est robuste contre les menaces de s√©curit√©.\n",
      "Vous devez √™tre conscient des fronti√®res de s√©curit√© au sein desquelles Azure Sphere vous prot√®ge. Au-del√† de ces fronti√®res, vous devez √™tre conscient des risques li√©s √† l‚Äôabsence de protection.\n",
      "Connectez des parties hors Azure Sphere de votre solution au r√©seau Ethernet pour communiquer en toute s√©curit√© avec Azure IoT Central.\n",
      "Cette option n‚Äôest pas r√©alisable en fonction des options de connectivit√© disponibles.\n",
      "Assurez-vous que les parties Azure Sphere du syst√®me restent s√©curis√©es, m√™me si les parties hors Azure de votre solution ne fournissent pas de s√©curit√©.\n",
      "1.\n",
      "Votre entreprise d√©cide d‚Äôexplorer l‚Äô√©ventail des solutions IoT industrielles. Vous voulez simuler le fonctionnement de diff√©rentes machines dans un environnement de production. Quelle alternative pouvez-vous recommander dans cette situation ?\n",
      "Acheter des donn√©es aupr√®s de sources externes.\n",
      "Simuler le fonctionnement d‚Äôun appareil p√©riph√©rique par le biais d‚Äôun module d√©ploy√© en p√©riph√©rie.\n",
      "La simulation de donn√©es au moyen d‚Äôun module de p√©riph√©rie offre une m√©thode flexible et relativement peu co√ªteuse pour reproduire le fonctionnement de capteurs sur le terrain.\n",
      "Utiliser des donn√©es historiques.\n",
      "2.\n",
      "Vous avez d√©ploy√© un module en p√©riph√©rie et vous vous attendez √† ce qu‚Äôil simule des donn√©es. Comment v√©rifiez-vous que le module est en cours d‚Äôex√©cution ?\n",
      "Vous affichez les donn√©es g√©n√©r√©es.\n",
      "Si le module est en cours d‚Äôex√©cution, il doit simuler des donn√©es comme n‚Äôimporte quel autre capteur sur le terrain.\n",
      "Vous v√©rifiez l‚Äô√©tat du module.\n",
      "Vous ex√©cutez un test pour conna√Ætre l‚Äô√©tat du module.\n",
      "3.\n",
      "Vous pouvez visualiser les donn√©es de temp√©rature g√©n√©r√©es par un appareil simul√©. Que pouvez-vous faire d‚Äôautre ?\n",
      "Examiner des donn√©es relatives √† la pression.\n",
      "Examiner les anomalies pr√©sentes dans les donn√©es de temp√©rature.\n",
      "V√©rifier que les donn√©es relatives aux conditions ambiantes sont simul√©es.\n",
      "Ce capteur peut √™tre install√© dans une salle de serveurs, dans une usine ou sur une √©olienne. L‚Äôanalyse des donn√©es ambiantes est donc pertinente.\n",
      "1. Parmi les affirmations suivantes, laquelle est vraie quand le mod√®le surajuste lors de l‚Äôentra√Ænement ?\n",
      "La justesse de l‚Äôentra√Ænement et de la validation commencent √† baisser\n",
      "La justesse de la validation augmente, la justesse de l‚Äôentra√Ænement arr√™te d‚Äôaugmenter\n",
      "(accrocher) La justesse de l‚Äôentra√Ænement continue d‚Äôaugmenter, la justesse de la validation commence √† baisser\n",
      "La justesse de la validation devient consid√©rablement inf√©rieure √† la justesse de l‚Äôentra√Ænement\n",
      "2. Nous avons d√©fini un mod√®le √† deux couches, mais il ne montre aucun avantage compar√© √† un mod√®le moncouche. Quel peut √™tre le probl√®me ?\n",
      "La taille de la couche masqu√©e est sup√©rieure √† la taille de la couche de sortie\n",
      "La taille de la couche masqu√©e est la m√™me que la taille de la couche de sortie\n",
      "(accrocher) Nous avons oubli√© de sp√©cifier la fonction d‚Äôactivation entre les couches\n",
      "Lorsque nous ne sp√©cifions pas une activation non lin√©aire, deux couches sont √©quivalentes √† une couche\n",
      "1.\n",
      "Comment le nombre de param√®tres dans une couche convolutive et une couche dense sont-ils corr√©l√©s ?\n",
      "Une couche convolutive contient plus de param√®tres\n",
      "Une couche convolutive contient de petits filtres qui ont les m√™mes poids pour l‚Äôimage enti√®re\n",
      "Une couche convolutive contient moins de param√®tres\n",
      "Correct, une couche convolutive contient de petits filtres qui ont les m√™mes poids pour l‚Äôimage enti√®re\n",
      "2.\n",
      "Si la taille d‚Äôune image d‚Äôentr√©e est 320x200x3, quelle est la taille du tenseur apr√®s avoir appliqu√© une couche convolutive 5x5 avec 16 filtres ?\n",
      "316x196x16\n",
      "Bonne r√©ponse\n",
      "316x196x3\n",
      "320x200x3x16\n",
      "320x200x48\n",
      "3.\n",
      "Quelles couches appliquez-nous pour r√©duire consid√©rablement la dimension spatiale dans le CNN multicouche ?\n",
      "Convolution\n",
      "Aplatir\n",
      "MaxPooling\n",
      "Les couches de regroupement (comme MaxPooling ou AveragePooling) sont utilis√©es pour r√©duire la dimension, g√©n√©ralement par un facteur de 2\n",
      "4.\n",
      "Quelle couche est utilis√©e entre la base convolutive du r√©seau et le classifieur lin√©aire final ?\n",
      "Convolution\n",
      "(accrocher) Aplatir\n",
      "L‚Äôaplatissement est utilis√© pour remodeler les tenseurs spatiaux en un vecteur lin√©aire\n",
      "MaxPooling\n",
      "Sigmoid\n",
      "1. Pour l‚Äôapprentissage de transfert, nous utilisons un r√©seau VGG-16 pr√©entra√Æn√© sur 1 000 classes. Quel est le nombre de classes pouvant √™tre utilis√©es dans notre r√©seau ?\n",
      "(accrocher) Quelconque\n",
      "Le nombre de classes dans un r√©seau pr√©entra√Æn√© n‚Äôest pas important, car nous effectuons l‚Äôapprentissage de notre propre classifieur final\n",
      "1 000\n",
      "2\n",
      "inf√©rieur √† 1 000\n",
      "------------------------\n",
      "1. Quelle caract√©ristique des fonctions Azure pour IoT permet de d√©ployer des applications IoT √† grande √©chelle ?\n",
      "(accrocher) Les fonctions Azure pour IoT peuvent g√©rer les fortes augmentations et baisses de demande.\n",
      "Azure Functions pour IoT est s√©curis√©.\n",
      "Les fonctions Azure pour IoT peuvent g√©rer de grands volumes de donn√©es.\n",
      "2. Une fonction Azure comprend deux parties : les d√©clencheurs et les liaisons. Quel avantage apportent ensemble les d√©clencheurs et les liaisons ?\n",
      "Les d√©clencheurs et les liaisons permettent de cr√©er une solution scalable.\n",
      "(accrocher) Les d√©clencheurs et les liaisons √©vitent d‚Äôavoir √† coder en dur les acc√®s aux autres services.\n",
      "Les d√©clencheurs et les liaisons fournissent une r√©ponse rapide aux √©v√©nements.\n",
      "3. Identifiez la caract√©ristique des fonctions Azure pour IoT garantissant que vous √™tes factur√© uniquement pour les ressources que vous utilisez.\n",
      "Azure Functions pour IoT est plus rapide et utilise donc moins de ressources.\n",
      "Azure Functions peut √™tre g√©r√© √† l‚Äôaide d‚Äôun tableau de bord.\n",
      "(accrocher) Vous n‚Äôavez pas besoin de pr√©-allouer les ressources √† l‚Äôavance.\n",
      "------------------------\n",
      "1. Laquelle des d√©clarations suivantes caract√©rise-t-elle Azure Functions et l‚Äôinformatique sans serveur ?\n",
      "Vous pouvez apporter vos propres conteneurs.\n",
      "Vous pouvez automatiser votre processus m√©tier.\n",
      "(accrocher) Vous pouvez int√©grer des services √† l‚Äôaide de d√©clencheurs et de liaisons.\n",
      "Vous pouvez incorporer des services Azure dans la fonction et utiliser un d√©clencheur pour ex√©cuter votre code.\n",
      "2. Supposons que vous √™tes responsable de la gestion de la fiabilit√© des donn√©es vocales provenant de diff√©rents types d‚Äôappareils IoT connect√©s √† un service IoT Hub. Pourquoi un service IoT Hub est-il appropri√© pour ce sc√©nario ?\n",
      "(accrocher) Un service IoT Hub fournit une identit√© unique √† chaque appareil.\n",
      "Un service IoT Hub connecte en toute s√©curit√© l‚Äôappareil au IoT en impl√©mentant une authentification par appareil.\n",
      "Un service IoT Hub effectue le suivi d‚Äô√©v√©nements tels que la cr√©ation d‚Äôappareils, les d√©faillances d‚Äôappareil et les connexions d‚Äôappareils.\n",
      "Un service IoT Hub est h√©berg√© dans le cloud.\n",
      "3. Supposons que vous √™tes responsable de l‚Äôimpl√©mentation de solutions d‚Äôintelligence artificielle avec un appareil IoT en tant que fonction bas√©e sur les √©v√©nements. Vous souhaitez explorer la possibilit√© d‚Äôinteragir avec Cognitive Services. Quelle solution pr√©coniseriez-vous pour impl√©menter ce sc√©nario ?\n",
      "Vous pouvez configurer une cl√© API Cognitive Services pour d√©clencher la fonction et ex√©cuter votre code.\n",
      "Vous utilisez une cl√© API pour acc√©der au service. Elle ne d√©clenche pas la fonction.\n",
      "Vous pouvez √©crire une fonction qui peut √™tre d√©ploy√©e localement, puis ex√©cuter la fonction en appelant l‚ÄôAPI Cognitive Services.\n",
      "(accrocher) Vous pouvez √©crire votre code en tant que fonction Azure appel√©e par un d√©clencheur, et appeler le service cognitif dans la fonction.\n",
      "Cela vous donne la flexibilit√© n√©cessaire pour interagir avec votre API Cognitive Services.\n",
      "------------------------\n",
      "1. Comment d√©cririez-vous un code de fonction ?\n",
      "Un code de fonction est un ensemble de fonctions interd√©pendantes qui peuvent √™tre ex√©cut√©es sur le serveur.\n",
      "(accrocher) Un code de fonction est le contenu principal qui s‚Äôex√©cute et accomplit des travaux sans aucune d√©pendance sur le serveur.\n",
      "Un code de fonction est simplement un code d√©ploy√© dans l‚Äôenvironnement local pour accomplir un travail.\n",
      "2. Supposons que vous soyez charg√© de d√©ployer une API de reconnaissance vocale dans votre application de fonction. Dans quel ordre accompliriez-vous les √©tapes suivantes pour cr√©er une application de traduction vocale ?\n",
      "(accrocher) D√©clenchement de la fonction ‚Äì reconnaissance vocale ‚Äì √©limination des disfluences verbales ‚Äì traduction ‚Äì synth√®se vocale\n",
      "Vous devez d√©clencher la fonction, reconna√Ætre la parole pour la convertir en texte, √©liminer les disfluences verbales, traduire le texte, puis produire l‚Äôaudio par synth√®se vocale du texte traduit.\n",
      "D√©clenchement de la fonction ‚Äì √©limination des disfluences verbales ‚Äì traduction ‚Äì synth√®se vocale\n",
      "Reconnaissance vocale ‚Äì √©limination des disfluences verbales ‚Äì traduction ‚Äì synth√®se vocale\n",
      "3. Supposons que vous souhaitiez d√©velopper une application √† l‚Äôaide de l‚ÄôAPI Cognitive Services dans la fonction Azure. Comment acc√©dez-vous √† l‚ÄôAPI Cognitive Services √† partir de votre application ?\n",
      "Vous pouvez acc√©der directement √† l‚ÄôAPI Cognitive Services √† l‚Äôint√©rieur de la fonction d‚ÄôAzure une fois que celle-ci a √©tabli la connexion.\n",
      "Vous devez g√©n√©rer une cl√© API √† chaque fois pour tenter la connexion et l‚Äôacc√®s √† l‚ÄôAPI Cognitive Services.\n",
      "(accrocher) Vous cr√©ez un compte de service cognitif qui g√©n√®re une cl√© API utilisable pour acc√©der √† l‚ÄôAPI de service\n",
      "Vous avez besoin d‚Äôune cl√© API pour acc√©der √† l‚ÄôAPI Cognitive Services dans la fonction\n",
      "------------------------\n",
      "1. Laquelle des descriptions suivantes d√©crit le mieux le fonctionnement de la traduction vocale ?\n",
      "La traduction vocale reconna√Æt la parole en provenance du microphone, la convertit en un grand nombre de fichiers audio, puis re√ßoit de mani√®re asynchrone les r√©sultats de la transcription.\n",
      "(accrocher) La traduction vocale reconna√Æt la parole en provenance du microphone, la convertit en fichier audio, normalise le texte, puis la traduit en fichier audio.\n",
      "Elle reconna√Æt la parole en provenance du microphone, la convertit en fichier audio, puis la synth√©tise vers un haut-parleur.\n",
      "2. Comment d√©cririez-vous une application de fonction ?\n",
      "Une application de fonction est un runtime de fonction destin√© √† ex√©cuter le code de la fonction.\n",
      "Une application de fonction est une application en conteneur qui peut √™tre appel√©e √† l‚Äôaide d‚Äôun d√©clencheur.\n",
      "(accrocher) Une application de fonction est une collection d‚Äôune ou plusieurs fonctions qui sont g√©r√©es ensemble.\n",
      "1. Parmi les commandes suivantes, lesquelles sont utilis√©es pour superviser l‚Äô√©tat d‚Äôun d√©ploiement sur la p√©riph√©rie ?\n",
      "az iot edge deployment summary\n",
      "(accrocher) az iot edge deployment show\n",
      "Elle affiche les d√©tails d‚Äôun d√©ploiement\n",
      "az iot edge deployment status\n",
      "------------------------\n",
      "1. Dans le contexte de la solution Vision sur Edge, vous d√©ployez plusieurs modules p√©riph√©riques sur votre appareil p√©riph√©rique. Lequel des √©l√©ments suivants est charg√© de d√©finir l‚Äôemplacement √† partir duquel les m√©dias doivent √™tre captur√©s, la fa√ßon dont ils doivent √™tre trait√©s et l‚Äôemplacement o√π les r√©sultats doivent √™tre remis ?\n",
      "Module web\n",
      "(accrocher) Module Live Video Analytics\n",
      "Vous d√©finissez le graphique multim√©dia sur le module Live Video Analytics qui analyse les images provenant de la cam√©ra et les envoie au module d‚Äôinf√©rence\n",
      "Module de pr√©diction\n",
      "------------------------\n",
      "1. Si vous disposez de votre propre mod√®le Machine Learning et que vous souhaitez l‚Äôempaqueter en tant qu‚Äôimage Docker, o√π d√©finissez-vous les √©tapes de g√©n√©ration du processus de g√©n√©ration d‚Äôimage ?\n",
      "Code source de votre application\n",
      "Registre Docker\n",
      "(accrocher) Dockerfile\n",
      "Un fichier Dockerfile est un fichier texte brut contenant toutes les commandes n√©cessaires pour g√©n√©rer une image\n",
      "------------------------\n",
      "1. Si vous √™tes un client et que vous souhaitez utiliser une plateforme qui vous permette de d√©ployer diff√©rents mod√®les Machine Learning pour diff√©rents sc√©narios, Vision sur Edge est un mod√®le de solution appropri√©. Parce que :\n",
      "Vous pouvez facilement d√©ployer des mod√®les sur vos cam√©ras existantes\n",
      "C‚Äôest correct, mais cette fonctionnalit√© ne suffit pas pour d√©ployer des mod√®les Machine Learning\n",
      "La solution Vision sur Edge utilise Live Video Analytics pour cr√©er des applications vid√©o\n",
      "(accrocher) Vous pouvez cr√©er vos mod√®les et les d√©ployer sur votre appareil p√©riph√©rique\n",
      "------------------------\n",
      "1. Supposons que votre corpus de texte contient 80 000 mots diff√©rents. Parmi les affirmations suivantes, laquelle choisiriez-vous pour r√©duire la dimensionnalit√© du vecteur d‚Äôentr√©e au classifieur neuronal ?\n",
      "S√©lectionnez 10 % des mots de fa√ßon al√©atoire et ignorez le reste.\n",
      "Utiliser la couche convolutive avant la couche de classifieur enti√®rement connect√©\n",
      "(accrocher) Utiliser la couche d‚Äôincorporation avant la couche de classifieur enti√®rement connect√©\n",
      "S√©lectionner 10 % des mots les plus fr√©quemment utilis√©s et ignorer le reste\n",
      "2. Nous souhaitons entra√Æner un r√©seau neuronal afin de g√©n√©rer de nouveaux mots dr√¥les pour un livre pour enfants. Quelle architecture puis-je utiliser ?\n",
      "LSTM au niveau du mot\n",
      "(accrocher) LSTM au niveau du caract√®re\n",
      "Correct, les LSTM de niveau caract√®re capturent souvent des syllabes utilis√©es et placent ces s√©quences ensemble pour g√©n√©rer de nouveaux mots.\n",
      "RNN au niveau du mot\n",
      "Perceptron au niveau du caract√®re\n",
      "3. Le r√©seau neuronal r√©current est appel√© ainsi pour les raisons suivantes :\n",
      "(accrocher) Un r√©seau est appliqu√© √† chaque √©l√©ment d‚Äôentr√©e, et la sortie de l‚Äôapplication pr√©c√©dente est pass√©e √† la suivante\n",
      "Il est form√© par un processus r√©current\n",
      "Il se compose de couches qui incluent d‚Äôautres sous-r√©seaux.\n",
      "4. Quelle est l‚Äôid√©e principale de l‚Äôarchitecture r√©seau LSTM ?\n",
      "Nombre fixe de blocs LSTM pour l‚Äôensemble du jeu de donn√©es\n",
      "Il contient de nombreuses couches de r√©seaux neuronaux r√©currents\n",
      "(accrocher) Gestion d‚Äô√©tat explicite avec oubli et d√©clenchement d‚Äô√©tat\n",
      "Dans LSTM, chaque bloc re√ßoit et g√©n√®re un √©tat, qui est manipul√© √† l‚Äôint√©rieur du bloc en fonction de l‚Äô√©tat d‚Äôentr√©e et de l‚Äô√©tat pr√©c√©dent.\n",
      "5. Quelle est l‚Äôid√©e principale de l‚Äôattention ?\n",
      "L‚Äôattention affecte un coefficient de pond√©ration √† chaque mot du vocabulaire pour montrer son importance.\n",
      "(accrocher) L‚Äôattention est une couche r√©seau qui utilise la matrice d‚Äôattention pour d√©terminer dans quelle mesure les √©tats d‚Äôentr√©e de chaque √©tape affectent le r√©sultat final.\n",
      "Correct. En examinant la matrice d‚Äôattention, nous pouvons √©valuer visuellement les mots qui jouent un r√¥le plus important dans diff√©rentes parties de la phrase.\n",
      "L‚Äôattention cr√©e une matrice de corr√©lation globale entre tous les mots du vocabulaire, en pr√©sentant leur co-occurrence\n",
      "------------------------\n",
      "1. Qu‚Äôest-ce que le taux d‚Äô√©chantillonnage ?\n",
      "Fr√©quence mapp√©e au temps.\n",
      "Les canaux audio.\n",
      "(accrocher) √âchantillonnage du son analogique √† des intervalles de temps coh√©rents pour cr√©er une repr√©sentation num√©rique du son.\n",
      "Correct !\n",
      "2. Qu‚Äôest-ce que la forme d‚Äôonde ?\n",
      "Fr√©quence mapp√©e au temps.\n",
      "(accrocher) Taux d‚Äô√©chantillonnage et fr√©quence visualis√©es.\n",
      "Correct ! Nous pouvons visualiser nos donn√©es √† l‚Äôaide d‚Äôune forme d‚Äôonde pour mapper le taux d‚Äô√©chantillonnage et la fr√©quence\n",
      "Les canaux audio.\n",
      "1. Lorsque vous r√©√©chantillonnez le son, vous...\n",
      "augmentez la taille.\n",
      "(accrocher) r√©duisez la taille.\n",
      "Correct ! Nous pouvons r√©duire la taille du fichier en r√©duisant le taux d‚Äô√©chantillonnage pour la piste audio.\n",
      "2. Qu‚Äôest-ce qu‚Äôun spectrogramme ?\n",
      "(accrocher) Mappe la fr√©quence sur le temps d‚Äôun fichier audio.\n",
      "Correct !\n",
      "Les canaux audio.\n",
      "Taux d‚Äô√©chantillonnage et fr√©quence visualis√©es.\n",
      "3. La classification audio ne peut √™tre effectu√©e qu‚Äôavec la vision par ordinateur sur des spectrogrammes.\n",
      "Vrai\n",
      "(accrocher) Faux\n",
      "Correct ! Il existe plusieurs fa√ßons de cr√©er des mod√®les de classification audio.\n",
      "1. Quelle est la diff√©rence entre Tensor et Variable dans TensorFlow ?\n",
      "Il n‚Äôy a aucune diff√©rence.\n",
      "Les tenseurs sont mutables, les variables sont immuables.\n",
      "Les variables sont mutables, les tenseurs sont immuables.\n",
      "Correct !\n",
      "1.\n",
      "Que nous permet de faire GradientTape ?\n",
      "Il nous permet d‚Äôenregistrer les op√©rations afin de pouvoir les relire plus tard.\n",
      "Il nous permet de calculer les d√©riv√©s des fonctions par rapport √† leurs tenseurs d‚Äôentr√©e.\n",
      "Correct !\n",
      "Il acc√©l√®re l‚Äôex√©cution.\n",
      "------------------------\n",
      "1. Quels sont les principaux avantages de l‚Äôex√©cution graphique ?\n",
      "Nous pouvons ex√©cuter notre mod√®le dans des environnements sans Python et nous obtenons de meilleures performances.\n",
      "Correct !\n",
      "Nous pouvons facilement d√©boguer notre code et l‚Äôex√©cuter o√π nous voulons.\n",
      "Nous pouvons √©crire moins de code et obtenir des pr√©dictions plus justes.\n",
      "------------------------\n",
      "1. Un scientifique des donn√©es entra√Æne et journalise un mod√®le avec MLflow. Quand le scientifique des donn√©es d√©ploie le mod√®le, le sch√©ma de l‚Äôentr√©e et de la sortie du mod√®le est incorrect. Que doit personnaliser le scientifique des donn√©es pour r√©soudre le probl√®me ?\n",
      "Personnaliser l‚Äôenvironnement du mod√®le.\n",
      "Changer la saveur du mod√®le.\n",
      "Incorrect. La saveur sp√©cifie le framework Machine Learning du mod√®le.\n",
      "Personnaliser la signature du mod√®le.\n",
      "Correct. La signature du mod√®le d√©finit les sch√©mas des entr√©es et sorties.\n",
      "2. Un scientifique des donn√©es a entra√Æn√© un mod√®le Deep Learning avec TensorFlow. Le mod√®le d√©ploy√© n√©cessite beaucoup de ressources de calcul et doit utiliser le serveur d‚Äôinf√©rence le plus optimal pour des charges de travail similaires. Quel type de mod√®le est compatible avec les d√©ploiements n√©cessitant beaucoup de ressources de calcul et sans code ?\n",
      "MLflow\n",
      "Triton\n",
      "Correct. Triton est id√©al pour les d√©ploiements n√©cessitant beaucoup de ressources de calcul.\n",
      "Custom\n",
      "------------------------\n",
      "1. Dans quelles circonstances un scientifique des donn√©es peut-il tirer le meilleur parti du calcul de processeur graphique ?\n",
      "Pour entra√Æner un mod√®le de pr√©vision sur des donn√©es de s√©rie chronologique.\n",
      "Pour entra√Æner un mod√®le de vision par ordinateur afin de classifier des images.\n",
      "C‚Äôest correct. Les algorithmes Deep Learning sont probablement ceux qui tirent le meilleur parti du processeur graphique en raison de la complexit√© de l‚Äôalgorithme et du besoin d‚Äôun grand jeu de donn√©es.\n",
      "Pour entra√Æner un mod√®le de r√©gression logistique afin de pr√©dire l‚Äôattrition clients.\n",
      "2. Quelle solution de stockage est recommand√©e pour entra√Æner un mod√®le de vision par ordinateur avec Azure Machine Learning ?\n",
      "Stockage Blob Azure\n",
      "Azure SQL Database\n",
      "Azure Data Lake Storage Gen2\n",
      "C‚Äôest correct. Les fichiers peuvent √™tre stock√©s en utilisant une structure de dossiers imbriqu√©s dans un lac de donn√©es en raison de l‚Äôespace de noms hi√©rarchique.\n",
      "------------------------\n",
      "1. Un scientifique des donn√©es souhaite entra√Æner un mod√®le Deep Learning. Pour qu‚Äôil puisse r√©aliser des exp√©riences avec des jeux de donn√©es et des algorithmes, quel calcul GPU doit √™tre mis √† sa disposition ?\n",
      "(accrocher) Un cluster de calcul basse priorit√©.\n",
      "C‚Äôest correct. Un cluster de calcul basse priorit√© effectue automatiquement un scale-down quand il est inactif et est plus √©conomique qu‚Äôun cluster d√©di√©.\n",
      "Un cluster de calcul d√©di√©.\n",
      "Ce n‚Äôest pas correct. Un cluster d√©di√© n‚Äôest pas l‚Äôoption la plus √©conomique.\n",
      "Une instance de calcul.\n",
      "2. Quelle approche devez-vous utiliser pour monitorer l‚Äôutilisation du GPU lors d‚Äôune ex√©cution Azure Machine Learning sp√©cifique ?\n",
      "Explorer les m√©triques de l‚Äôespace de travail Azure Machine Learning dans le portail Azure.\n",
      "Explorer l‚Äôonglet D√©tails de l‚Äôex√©cution dans Azure Machine Learning studio.\n",
      "(accrocher) Explorer l‚Äôonglet Monitoring de l‚Äôex√©cution dans Azure Machine Learning studio.\n",
      "C‚Äôest correct. L‚Äôonglet Monitoring indique l‚Äôutilisation moyenne du GPU pour l‚Äôex√©cution.\n",
      "------------------------\n",
      "1. Pour utiliser le d√©ploiement sans code avec Triton dans Azure Machine Learning, quel format de mod√®le doit √™tre sp√©cifi√© lors de l‚Äôinscription du mod√®le ?\n",
      "ONNX\n",
      "(accrocher) Triton\n",
      "PyTorch\n",
      "2. Pour quelle raison pourriez-vous convertir votre mod√®le au format ONNX ?\n",
      "(accrocher) Pour optimiser les performances de votre mod√®le pendant l‚Äôinf√©rence.\n",
      "C‚Äôest correct. Cela vous permet d‚Äôutiliser ONNX Runtime, qui offre des performances sup√©rieures lors de l‚Äôinf√©rence.\n",
      "Pour r√©duire le temps d‚Äôentra√Ænement.\n",
      "Pour distribuer l‚Äôinf√©rence de votre mod√®le sur diff√©rents appareils GPU.\n",
      "------------------------\n",
      "1. Un ing√©nieur en Machine Learning souhaite cr√©er un espace de travail Azure Machine Learning. Quelle commande CLI (v2) doit √™tre utilis√©e ?\n",
      "az ml workspace list\n",
      "az ml workspace show\n",
      "(accrocher) az ml workspace create\n",
      "La commande workspace create cr√©e un espace de travail.\n",
      "2. Un scientifique des donn√©es souhaite cr√©er un environnement pour ex√©cuter un script Python sur un cluster de calcul. Pour l‚Äôutilisation de la commande az ml environment create --file basic-env.yml, que doit contenir le fichier basic-env.yml ?\n",
      "(accrocher) Nom et version de l‚Äôenvironnement.\n",
      "Entre autres choses, le fichier YAML de sp√©cification doit inclure le nom et la version de l‚Äôenvironnement.\n",
      "Packages et biblioth√®ques qui doivent √™tre install√©s sur le cluster de calcul pour ex√©cuter le script.\n",
      "Type et taille du cluster de calcul √† cr√©er.\n",
      "------------------------\n",
      "1. Quel avantage offre le d√©ploiement d‚Äôun service Cognitive Services en tant qu‚Äôappareil IoT Edge dans un conteneur ?\n",
      "Les services Cognitive Services peuvent s‚Äôex√©cuter plus rapidement\n",
      "    - Le d√©ploiement en tant que conteneur sur un appareil p√©riph√©rique n‚Äôimplique pas n√©cessairement un traitement plus rapide.\n",
      "Ex√©cution en ligne possible\n",
      "(accrocher) Ex√©cution hors connexion possible\n",
      "2. Pour un service Cognitive Services, o√π l‚Äôentra√Ænement a lieu ?\n",
      "√Ä la p√©riph√©rie\n",
      "(accrocher) Dans le cloud\n",
      "Localement\n",
      "3. Quelle est la fonction du service Azure Container Registry ?\n",
      "(accrocher) Stockage et gestion d‚Äôimages conteneur\n",
      "    - Azure Container Registry permet de stocker et de g√©rer des images conteneur.\n",
      "Stockage et gestion d‚Äôimages\n",
      "    - Azure Container Registry ne permet pas de stocker et de g√©rer des images.\n",
      "Stockage et gestion de services\n",
      "------------------------\n",
      "1. Voici les composants de l‚Äô√©cosyst√®me Azure Sphere : kit SDK Azure Sphere, locataire Azure Sphere, syst√®me d‚Äôexploitation Azure Sphere. Il en manque un. Lequel ?\n",
      "API Azure Sphere\n",
      "(accrocher) Service de s√©curit√© Azure Sphere\n",
      "    Le service de s√©curit√© Azure Sphere est un composant cl√© de l‚Äô√©cosyst√®me Azure Sphere.\n",
      "Cl√© de s√©curit√© Azure Sphere\n",
      "2. Votre organisation a cr√©√© un locataire Azure Sphere, puis a revendiqu√© chacun de ses appareils dans ce locataire. Dans quel but ?\n",
      "(accrocher) Vous permettre de g√©rer ces appareils √† distance et de mani√®re s√©curis√©e.\n",
      "    Le locataire vous permet de g√©rer les appareils √† distance et de mani√®re s√©curis√©e.\n",
      "Le locataire permet aux appareils de mieux communiquer avec d‚Äôautres locataires.\n",
      "Votre organisation peut nommer des appareils individuels.\n",
      "    Le locataire ne permet pas le nommage d‚Äôappareils.\n",
      "3. Si le service de s√©curit√© Azure Sphere √©tait absent, quelle fonction ne pourriez-vous pas ex√©cuter ?\n",
      "Vous ne pourriez pas recevoir d‚Äôalertes pour des anomalies.\n",
      "    L‚Äôabsence des mises √† jour du service de s√©curit√© n‚Äôest pas directement li√©e aux alertes en cas d‚Äôanomalie.\n",
      "Vous ne pourriez pas assurer la s√©curit√© du syst√®me d‚Äôexploitation.\n",
      "(accrocher) Vous ne pourriez pas b√©n√©ficier des derni√®res mises √† jour de s√©curit√© sur les appareils Azure Sphere.\n",
      "    Vous ne pourriez pas b√©n√©ficier des derni√®res mises √† jour de s√©curit√© sur les appareils Azure Sphere.\n",
      "4. Comment pouvez-vous ex√©cuter des applications temps r√©el sur un appareil Azure Sphere ?\n",
      "Vous ne pouvez pas ex√©cuter des applications temps r√©el sur un appareil Azure Sphere.\n",
      "Vous pouvez ex√©cuter des applications temps r√©el sur le c≈ìur Cortex-A7 avec noyau Linux d‚ÄôAzure Sphere.\n",
      "(accrocher) Vous pouvez ex√©cuter des applications temps r√©el sur les c≈ìurs Cortex-M4 d‚ÄôAzure Sphere.\n",
      "    Vous pouvez ex√©cuter du code directement ou un syst√®me d‚Äôexploitation temps r√©el, comme Azure RTOS ou FreeRTOS, sur les c≈ìurs Cortex-M4 d‚ÄôAzure Sphere.\n",
      "------------------------\n",
      "1.\n",
      "Dans le contexte de l‚Äôarchitecture de la solution Vision sur Edge, vous utilisez l‚ÄôAPI Custom Vision :\n",
      "Pour d√©tecter des objets avec des √©tiquettes donn√©es par l‚ÄôAPI\n",
      "Pour entra√Æner un mod√®le pour vos images en fonction du choix de votre mod√®le de Machine Learning\n",
      "Custom Vision ne vous permet pas d‚Äôutiliser votre mod√®le Machine Learning pour d√©tecter des objets.\n",
      "Pour entra√Æner un mod√®le de vos images en fonction d‚Äôun mod√®le pr√©d√©fini par Microsoft\n",
      "Le service Custom Vision utilise des algorithmes de machine learning fournis par Microsoft pour analyser des images\n",
      "2.\n",
      "Quand vous utilisez un script d‚Äôinstallation pour d√©ployer les ressources n√©cessaires dans votre abonnement, lequel des √©l√©ments suivants est charg√© d‚Äôinstaller les modules sur les appareils p√©riph√©riques ?\n",
      "Manifeste de d√©ploiement\n",
      "Le manifeste de d√©ploiement est un document JSON qui indique √† votre appareil quels modules installer et comment les configurer pour qu‚Äôils fonctionnent ensemble.\n",
      "Mod√®les Microsoft Azure Resource Manager\n",
      "Azure Container Registry\n",
      "------------------------\n",
      "1.\n",
      "Quand vous d√©ployez la solution, comment fonctionne le d√©ploiement IoT Edge ?\n",
      "Les donn√©es sont collect√©es aupr√®s du simulateur RTSP, le module Live Video Analytics utilise le service Custom Vision pour l‚Äôentra√Ænement et il d√©ploie un nouveau mod√®le.\n",
      "Les donn√©es sont collect√©es aupr√®s du simulateur RTSP, le module web envoie les images √©tiquet√©es √† Custom Vision pour l‚Äôentra√Ænement et d√©ploie un nouveau mod√®le.\n",
      "Le module web capture les images et les envoie pour l‚Äôentra√Ænement en utilisant l‚ÄôAPI Custom Vision.\n",
      "Les donn√©es sont collect√©es aupr√®s du simulateur RTSP, le module Live Video Analytics capture des images, √©tiquette les objets et envoie les images √©tiquet√©es au module web pour les d√©tecter.\n",
      "------------------------\n",
      "1.\n",
      "Contoso migre un cluster HBase local vers HDInsight, s‚Äôinqui√®te des √©ventuels probl√®mes de latence d‚Äô√©criture avec HBase et cherche √† am√©liorer les performances d‚Äô√©criture sur HBase. Quelle solution de la liste ci-dessous aimeriez-vous proposer ?\n",
      "Migrer vers HBase sur IaaS sur Azure.\n",
      "Migrer vers HDInsight HBase avec des √©critures acc√©l√©r√©es.\n",
      "Correct. HDInsight HBase avec √âcritures acc√©l√©r√©es attache un disque g√©re Premium SSD √† chaque serveur de r√©gion HBase (Worker Node) pendant le d√©ploiement du cluster.\n",
      "Migrer vers HDInsight HBase Regular.\n",
      "2.\n",
      "Contoso cherche √† am√©liorer les performances de lecture des clusters HBase HDInsight. Quelle solution de la liste ci-dessous aimeriez-vous offrir en plus des √©critures acc√©l√©r√©es ?\n",
      "Utiliser une mise en r√©seau plus rapide.\n",
      "Utilisez des objets Blob de pages Azure.\n",
      "Utilisez des objets BLOB de blocs Premium.\n",
      "Correct. Les objets Blob de blocs Premium offrent un acc√®s disque hautes performances pour am√©liorer les performances de lecture des clusters HBase HDInsight\n",
      "3.\n",
      "La strat√©gie de continuit√© des activit√©s de Contoso exige l‚Äôactivation de la r√©plication asynchrone entre r√©gions Azure entre les clusters HDInsight HBase. Quelle solution recommandez-vous ?\n",
      "Importation/Exportation\n",
      "Incorrect. La fonctionnalit√© d‚Äôimportation/exportation exporte les tables s√©lectionn√©es vers le stockage local attach√© au cluster. Apr√®s l‚Äôexportation, exportez les tables qui peuvent ensuite √™tre import√©es √† partir du cluster cible.\n",
      "copie du dossier hbase.\n",
      "R√©plication HBase\n",
      "Correct. La r√©plication HBase active la r√©plication asynchrone entre r√©gions Azure entre les clusters HDInsight HBase.\n",
      "------------------------\n",
      "1. Quelle est la m√©thode de connexion √† la source de donn√©es qui charge toutes les donn√©es dans le cache Power BI et ex√©cute des requ√™tes sur les donn√©es ing√©r√©es ?\n",
      "DirectQuery.\n",
      "(accrocher) Importer la connexion.\n",
      "Correct. Vous pouvez utiliser Obtenir des donn√©es dans Power BI Desktop pour vous connecter √† une source de donn√©es comme SQL Server √† des fins d‚Äôimportation.\n",
      "Connexion hybride\n",
      "2. Qu‚Äôest-ce qui peut √™tre consid√©r√© comme un avantage des vues mat√©rialis√©es ?\n",
      "(accrocher) Une distribution diff√©rente des donn√©es par rapport aux tables de base.\n",
      "Correct. Les donn√©es comprises dans une vue mat√©rialis√©e peuvent √™tre distribu√©es diff√©remment dans les tables de base.\n",
      "Une diminution des performances des requ√™tes pour les requ√™tes complexes avec des jointures et fonctions d‚Äôagr√©gation, mais une am√©lioration des performances pour les requ√™tes simples.\n",
      "Incorrect. Plus la requ√™te est complexe, plus le potentiel d‚Äôenregistrement au moment de l‚Äôex√©cution est √©lev√©.\n",
      "Des temps de r√©ponse des requ√™tes instantan√©s pour les mod√®les de requ√™te r√©p√©titifs.\n",
      "3. Quelle est la limite de la mise en cache des jeux de r√©sultats ?\n",
      "(accrocher) La taille maximale du cache des jeux de r√©sultats est de 1 To par base de donn√©es.\n",
      "Correct. Quand le cache des jeux de r√©sultats est proche de la taille maximale, une √©viction du cache d√©marre.\n",
      "Les utilisateurs ne peuvent pas vider manuellement le cache des jeux de r√©sultats.\n",
      "La suspension de la base de donn√©es nettoie le cache.\n",
      "------------------------\n",
      "1. Un scientifique des donn√©es souhaite cr√©er rapidement plusieurs pipelines pour tester diff√©rents algorithmes. Un ing√©nieur Machine Learning en tant que composant cr√©√© pour ces pipelines. Quelle est la m√©thode recommand√©e pour que le scientifique des donn√©es puisse gagner du temps lors du test des pipelines bas√©s sur des composants ?\n",
      "Utiliser l‚Äôinterface de ligne de commande Azure Machine Learning (v2).\n",
      "Cr√©er un fichier YAML de t√¢ches de pipeline peut √™tre long et complexe, et ce n‚Äôest pas l‚Äôid√©al pour une exp√©rimentation rapide.\n",
      "Utiliser le concepteur Azure Machine Learning.\n",
      "√Ä l‚Äôaide de l‚Äôinterface utilisateur, un utilisateur peut rapidement glisser-et-d√©poser des composants diff√©rents vers le pipeline.\n",
      "Utiliser l‚Äôespace de travail Azure Machine Learning.\n",
      "2. Quel pr√©fixe devez-vous utiliser lorsque vous souhaitez utiliser les entr√©es du pipeline comme une entr√©e de composant dans le fichier YAML du pipeline ?\n",
      "jobs.\n",
      "outputs.\n",
      "inputs.\n",
      "Bonne r√©ponse.\n",
      "------------------------\n",
      "1. Quel est l‚Äôobjectif de la comp√©tence/du module ¬´ R√©gime permanent ¬ª ?\n",
      "Bruit al√©atoire jusqu‚Äô√† 5 %.\n",
      "Minimiser la r√©f√©rence de concentration.\n",
      "Correct. Minimizing error to the concentration reference is one of the two goal objectives of our problem.\n",
      "Limite d‚Äôit√©ration d‚Äô√©pisode d√©finie sur 90.\n",
      "Emballement thermique.\n",
      "Thermal runaway is a condition we need to prevent the brain from visiting. The corresponding goal objective related to this condition is to AVOID thermal runaway.\n",
      "2. La le√ßon que doit apprendre la strat√©gie ¬´ R√©gime permanent ¬ª est :\n",
      "S‚Äôentra√Æner avec des conditions transitoires (signal de r√©f√©rence de concentration, Cref_signal, √©gal √† 1).\n",
      "S‚Äôentra√Æner avec diff√©rentes temp√©ratures d‚Äôemballement thermique.\n",
      "S‚Äôentra√Æner avec des conditions de r√©gime permanent (signal de r√©f√©rence de concentration, Cref_signal, √©gal √† 5).\n",
      "Correct. This is the scenario for the steady-state condition.\n",
      "Temp√©rature thermique √©gale √† 400 kelvins.\n",
      "------------------------\n",
      "1. Une organisation utilise trois environnements dans sa strat√©gie MLOps (Machine Learning Operations). Dans quel environnement l‚Äôassurance qualit√© est-elle la plus indiqu√©e ?\n",
      "D√©veloppement\n",
      "Incorrect. L‚Äôassurance qualit√© n‚Äôest pas encore n√©cessaire pendant le d√©veloppement du mod√®le.\n",
      "Pr√©production\n",
      "Correct. L‚Äôassurance qualit√© est un aspect essentiel en pr√©production.\n",
      "Production\n",
      "2. Quelle raison peut justifier l‚Äôajout d‚Äôune approbation pour un environnement quand GitHub Actions est utilis√© ?\n",
      "Quelqu‚Äôun doit v√©rifier le code et le mod√®le avant de d√©placer le mod√®le vers l‚Äôenvironnement suivant.\n",
      "Quelqu‚Äôun doit v√©rifier que l‚Äôensemble des ex√©cutions et des tests ont r√©ussi avant de d√©placer le mod√®le vers l‚Äôenvironnement suivant.\n",
      "Correct. M√™me lorsque les workflows GitHub Actions ont √©t√© ex√©cut√©s avec succ√®s, quelqu‚Äôun peut toujours avoir besoin d‚Äôexaminer la sortie dans l‚Äôespace de travail Azure Machine Learning.\n",
      "Quelqu‚Äôun doit d√©ployer et tester le mod√®le avant de le d√©placer vers l‚Äôenvironnement suivant.\n",
      "------------------------\n",
      "1. Quand un mod√®le Machine Learning doit g√©n√©rer des pr√©dictions sur de nouvelles donn√©es chaque semaine, quel est le d√©ploiement de mod√®le appropri√© ?\n",
      "Point de terminaison priv√©\n",
      "Point de terminaison en ligne\n",
      "(accrocher) Point de terminaison de lot\n",
      "Correct. Utilisez des points de terminaison de lot quand vous souhaitez g√©n√©rer un lot de pr√©dictions.\n",
      "2. Quelles ressources sont automatiquement g√©n√©r√©es lors de l‚Äôutilisation du d√©ploiement sans code avec un mod√®le MLflow ?\n",
      "Le script d‚Äôentra√Ænement et de scoring.\n",
      "(accrocher) Le script et l‚Äôenvironnement de scoring.\n",
      "Correct. Quand un mod√®le est journalis√© avec MLflow, le script de scoring et l‚Äôenvironnement sont cr√©√©s par l‚Äôespace de travail Azure Machine Learning lors du d√©ploiement.\n",
      "Le script de scoring et la configuration du d√©ploiement.\n",
      "------------------------\n",
      "1. Quel d√©clencheur doit √™tre utilis√© dans un workflow GitHub Actions pour ex√©cuter des v√©rifications de code lorsqu‚Äôune demande de tirage est cr√©√©e ?\n",
      "on: workflow_dispatch\n",
      "on: [push]\n",
      "(accrocher) on: [pull_request]\n",
      "Correct. Utiliser on: [pull_request] pour d√©clencher un workflow lorsqu‚Äôune demande de tirage est ouverte.\n",
      "2. Un scientifique des donn√©es a mis √† jour le script d‚Äôentra√Ænement pour un mod√®le, et cr√©e une demande de tirage pour fusionner les modifications. Les v√©rifications de code √©chouent, et les d√©tails mentionnent des erreurs telles que E302 et W292. Quelle est la cause probable de ces erreurs ?\n",
      "Les tests unitaires n‚Äôont pas √©t√© trouv√©s.\n",
      "Fonctions manquantes dans les scripts d‚Äôentra√Ænement.\n",
      "(accrocher) Erreurs stylistiques telles que les lignes vides manquantes.\n",
      "Correct. E302 et W292 sont des codes d‚Äôerreur et d‚Äôavertissement retourn√©s lors de l‚Äôex√©cution de linters sur du code.\n",
      "------------------------\n",
      "1. Quand est-il pr√©f√©rable d‚Äôutiliser le mod√®le de conception du cerveau de perception ?\n",
      "Quand nous devons classifier les images.\n",
      "(accrocher) Lorsqu‚Äôil y a un op√©rateur expert qui d√©cide des strat√©gies de contr√¥le en fonction de la perception avanc√©e.\n",
      "Correct. Le mod√®le de conception du cerveau de perception automatisera la prise de d√©cision comme l‚Äôhumain en fonction de la perception avanc√©e, comme la vision ou le son.\n",
      "Quand nous devons pr√©dire la demande de produits.\n",
      "Quand nous devons identifier les sons.\n",
      "2. Quand est-il pr√©f√©rable d‚Äôutiliser le mod√®le de conception du cerveau fonctionnel ?\n",
      "Lorsqu‚Äôil existe diff√©rentes t√¢ches qui ne peuvent √™tre contr√¥l√©es que par un seul op√©rateur expert √† la fois.\n",
      "Quand diff√©rentes t√¢ches sont ex√©cut√©es √† l‚Äôaide des m√™mes actions de contr√¥le.\n",
      "(accrocher) Quand diff√©rentes t√¢ches sont ex√©cut√©es √† l‚Äôaide d‚Äôactions de contr√¥le ind√©pendantes.\n",
      "Correct. Quand nous pouvons diviser le probl√®me en t√¢ches qui sont ex√©cut√©es par diff√©rents op√©rateurs experts sur des actions de contr√¥le ind√©pendantes (diff√©rents travaux dans le processus), la d√©composition fonctionnelle est le meilleur choix.\n",
      "Lorsqu‚Äôun op√©rateur expert est en train d‚Äôeffectuer la t√¢che.\n",
      "3. Quand est-il pr√©f√©rable d‚Äôutiliser le mod√®le de conception du cerveau strat√©gique ?\n",
      "Quand nous identifions des strat√©gies contr√¥l√©es √† l‚Äôaide d‚Äôactions de contr√¥le ind√©pendantes.\n",
      "Lorsqu‚Äôil existe diff√©rentes t√¢ches contr√¥l√©es par diff√©rents op√©rateurs experts ind√©pendamment.\n",
      "Lorsqu‚Äôun op√©rateur expert est en train d‚Äôeffectuer la t√¢che.\n",
      "(accrocher) Quand nous identifions des strat√©gies contr√¥l√©es √† l‚Äôaide d‚Äôactions de contr√¥le similaires.\n",
      "Correct. Nous identifions les strat√©gies √† l‚Äôaide de l‚Äôexercice en trois colonnes et chaque strat√©gie n√©cessite de contr√¥ler toutes les actions de contr√¥le de diff√©rentes mani√®res en fonction du sc√©nario.\n",
      "------------------------\n",
      "1. Vous envisagez d‚Äôutiliser le service Custom Vision pour entra√Æner un mod√®le de classification d‚Äôimages. Vous souhaitez cr√©er une ressource qui pourra √™tre utilis√©e pour l‚Äôentra√Ænement du mod√®le, mais pas pour la pr√©diction. Quelle sorte de ressource devez-vous cr√©er dans votre abonnement Azure ?\n",
      "Custom Vision\n",
      "Correct : Quand vous cr√©ez une ressource Custom Vision, vous pouvez indiquer si elle peut √™tre utilis√©e pour l‚Äôentra√Ænement, la pr√©diction ou les deux.\n",
      "Cognitive Services\n",
      "Vision par ordinateur\n",
      "2. Vous entra√Ænez un mod√®le de classification d‚Äôimages dont les m√©triques d‚Äô√©valuation n‚Äôatteignent pas un niveau satisfaisant. Comment pouvez-vous am√©liorer ce mod√®le ?\n",
      "En r√©duisant la taille des images utilis√©es pour entra√Æner le mod√®le.\n",
      "En ajoutant une nouvelle √©tiquette pour les classes ¬´ inconnues ¬ª.\n",
      "En ajoutant plus d‚Äôimages au jeu de donn√©es d‚Äôentra√Ænement.\n",
      "Correct : En r√®gle g√©n√©rale, l‚Äôajout d‚Äôimages suppl√©mentaires au projet et le r√©entra√Ænement du mod√®le suffisent pour am√©liorer les performances.\n",
      "3. Vous avez publi√© un mod√®le de classification d‚Äôimages. Quelles informations devez-vous fournir aux d√©veloppeurs qui souhaitent l‚Äôutiliser ?\n",
      "Uniquement l‚ÄôID du projet.\n",
      "L‚ÄôID du projet, le nom du mod√®le ainsi que la cl√© et le point de terminaison de la ressource de pr√©diction\n",
      "Correct : Pour utiliser un mod√®le publi√©, vous avez besoin de l‚ÄôID du projet, du nom du mod√®le ainsi que de la cl√© et du point de terminaison de la ressource de pr√©diction.\n",
      "L‚ÄôID du projet, le num√©ro d‚Äôit√©ration ainsi que la cl√© et le point de terminaison de la ressource d‚Äôentra√Ænement.\n",
      "------------------------\n",
      "1. Lequel des r√©sultats suivants un mod√®le de d√©tection d‚Äôobjets retourne-t-il g√©n√©ralement pour une image ?\n",
      "√âtiquette de classe et score de probabilit√© pour l‚Äôimage\n",
      "Coordonn√©es du rectangle englobant qui indiquent la r√©gion de l‚Äôimage o√π se trouvent tous les objets qu‚Äôelle contient\n",
      "Une √©tiquette de classe, une probabilit√© et un rectangle englobant pour chaque objet dans l‚Äôimage\n",
      "Correct : Un mod√®le de d√©tection d‚Äôobjets pr√©dit une √©tiquette de classe, une probabilit√© et un rectangle englobant pour chaque objet dans l‚Äôimage\n",
      "2. Vous envisagez d‚Äôutiliser un ensemble d‚Äôimages pour entra√Æner un mod√®le de d√©tection d‚Äôobjets, puis de publier le mod√®le en tant que service pr√©dictif. Vous souhaitez utiliser une seule ressource Azure avec les m√™mes cl√© et point de terminaison pour l‚Äôentra√Ænement et la pr√©diction. Quel type de ressource Azure devez-vous cr√©er ?\n",
      "Cognitive Services\n",
      "Correct : Une ressource Cognitive Services peut √™tre utilis√©e √† la fois pour l‚Äôentra√Ænement et la pr√©diction.\n",
      "Custom Vision\n",
      "Incorrect : La cr√©ation d‚Äôune ressource Custom Vision √† la fois pour l‚Äôentra√Ænement et la pr√©diction aboutit au provisionnement de deux ressources distinctes, chacune avec sa propre cl√© et son propre point de terminaison.\n",
      "Vision par ordinateur\n",
      "------------------------\n",
      "1. Vous envisagez d‚Äôutiliser Visage pour d√©tecter les visages humains sur une image. Comment le service indique-t-il l‚Äôemplacement des visages d√©tect√©s ?\n",
      "Paire de coordonn√©es pour chaque visage, indiquant le centre du visage\n",
      "Deux paires de coordonn√©es pour chaque visage, indiquant l‚Äôemplacement des yeux\n",
      "Ensemble de coordonn√©es pour chaque visage, d√©finissant un cadre englobant rectangulaire autour du visage\n",
      "Correct : Les emplacements des visages d√©tect√©s sont indiqu√©s par les coordonn√©es d‚Äôun cadre englobant rectangulaire\n",
      "2. Qu‚Äôest-ce qu‚Äôun aspect pouvant nuire √† la d√©tection des visages ?\n",
      "Lunettes\n",
      "Incorrect : Cet attribut n‚Äôest pas r√©pertori√© comme un handicap √† la d√©tection.\n",
      "Angles extr√™mes\n",
      "Correct : Les meilleurs r√©sultats sont obtenus lorsque les visages sont enti√®rement (ou le plus possible) de face\n",
      "Vitesse d‚Äôobturation rapide\n",
      "------------------------\n",
      "1. Parmi les termes suivants, lequel n‚Äôest pas un type de variable ?\n",
      "Entier (int)\n",
      "Flottant (float)\n",
      "Cha√Æne (str)\n",
      "Mot (word)\n",
      "Correct ! Un word n‚Äôest pas un type de variable. Utilisez plut√¥t une cha√Æne (str) pour du texte.\n",
      "2. Quelle affirmation est correcte ?\n",
      "Les listes peuvent stocker un seul type de donn√©es.\n",
      "Les listes peuvent stocker tous les types de donn√©es.\n",
      "Correct ! Les listes peuvent stocker tous les types de donn√©es.\n",
      "3. Laquelle des lignes de code suivantes devez-vous utiliser pour imprimer la valeur d‚Äôune variable appel√©e variable et du texte ?\n",
      "print(\"The variable's value is\"; variable)\n",
      "print(\"The variable's value is\", variable)\n",
      "Correct ! Voici comment imprimer correctement une variable et du texte.\n",
      "print(\"The variable's value is\": variable)\n",
      "print(\"The variable's value is\"~ variable)\n",
      "------------------------\n",
      "1. Comment devez-vous collecter les donn√©es de t√©l√©m√©trie de votre ressource Azure Cognitive Services pour une analyse ult√©rieure ?\n",
      "Cr√©ez une alerte.\n",
      "Configurer les param√®tres de diagnostic.\n",
      "Correct. Les param√®tres de diagnostic vous permettent de capturer des donn√©es pour une analyse ult√©rieure.\n",
      "Cr√©er un tableau de bord.\n",
      "Incorrect. Un tableau de bord vous permet d‚Äôafficher les m√©triques quasiment en temps r√©el.\n",
      "2. Vous d√©finissez une alerte qui vous avertit lorsqu‚Äôun √©v√©nement de r√©g√©n√©ration de cl√© est enregistr√© dans le journal d‚Äôactivit√© pour votre ressource de Cognitive Services ? Que devez-vous faire ?\n",
      "Sp√©cifiez une √©tendue de journal d‚Äôactivit√©.\n",
      "Sp√©cifiez une action qui utilise une application logique Azure pour lire le journal d‚Äôactivit√©.\n",
      "Incorrect. Les actions sont ex√©cut√©es lorsque l‚Äôalerte est d√©clench√©e.\n",
      "Sp√©cifiez une condition avec un type de signal Journal d‚Äôactivit√©.\n",
      "Correct. L‚Äô√©v√©nement Cl√© de r√©g√©n√©ration est un signal Journal d‚Äôactivit√©.\n",
      "3. Vous affichez une m√©trique pour votre ressource Cognitive Services dans un graphique. Vous souhaitez combiner le graphique avec des visualisations d‚Äôautres ressources et donn√©es. Que devez-vous faire ?\n",
      "Ajoutez le graphique un tableau de bord.\n",
      "Correct. Un tableau de bord vous permet de combiner des visualisations √† partir de plusieurs ressources.\n",
      "Partagez le graphique.\n",
      "Clonez le graphique.\n",
      "------------------------\n",
      "1. √Ä quoi sert l‚Äôintelligence artificielle ?\n",
      "√Ä g√©n√©rer Skynet.\n",
      "√Ä reproduire l‚Äôintelligence humaine √† l‚Äôaide d‚Äôun ordinateur.\n",
      "Correct !\n",
      "2. Laquelle des options suivantes n‚Äôest pas un indicateur fourni par Custom Vision pour vous aider √† comprendre le fonctionnement d‚Äôun mod√®le Machine Learning ?\n",
      "Matrice de confusion\n",
      "Correct ! Une matrice de confusion est une m√©trique valide, mais n‚Äôest pas fournie par Azure Cognitive Services Custom Vision.\n",
      "Rappel\n",
      "Pr√©cision moyenne\n",
      "Pr√©cision\n",
      "3. Quelle est l‚Äôerreur de d√©butant courante lors de l‚Äôutilisation de mod√®les Machine Learning ?\n",
      "Utilisation de donn√©es incorrectes.\n",
      "Correct ! Des donn√©es correctes sont essentielles pour cr√©er un bon mod√®le Machine Learning.\n",
      "Utilisation d‚Äôun trop grand nombre de donn√©es.\n",
      "Utilisation de donn√©es jamais vues (nouvelles) pour le test.\n",
      "4. Le mod√®le ne doit pas √™tre d√©ploy√© tant qu‚Äôil n‚Äôobtient pas des r√©sultats parfaits et qu‚Äôil n‚Äôest pas 100 % juste sur toutes les classes.\n",
      "Faux\n",
      "Correct ! Vous devez d√©cider du moment o√π le mod√®le est suffisamment performant pour le probl√®me que vous essayez de r√©soudre.\n",
      "Vrai\n",
      "------------------------\n",
      "1. Quel composant de Bonsai est responsable de la g√©n√©ration de mod√®les d‚Äôapprentissage bas√©s sur un programme d‚Äôapprentissage ?\n",
      "Le moteur de simulation\n",
      "Le programme d‚Äôapprentissage\n",
      "Le moteur d‚Äôapprentissage\n",
      "Correct. Le composant Architecte du moteur d‚Äôapprentissage g√©n√®re des mod√®les d‚Äôapprentissage.\n",
      "2. Dans lequel des sc√©narios suivants Bonsai pourrait-il √™tre avantageux pour une organisation ?\n",
      "Une organisation a conclu qu‚Äôil existe une marge consid√©rable pour l‚Äôam√©lioration des syst√®mes de production automatis√©s.\n",
      "Correct. Ce sc√©nario est id√©al pour Bonsai.\n",
      "Une organisation utilise peu les syst√®mes d‚Äôautomatisation.\n",
      "Une organisation n‚Äôa aucune simulation, et aucun expert n‚Äôest qualifi√© dans l‚Äôutilisation des simulations.\n",
      "3. Lors de la conception de votre mod√®le de simulation pour un cerveau Bonsai, quel est l‚Äôobjectif de l‚Äô√©tat de d√©marrage personnalisable ?\n",
      "Cela permet de garantir une √©valuation en temps r√©el significative pendant l‚Äôapprentissage.\n",
      "Elle permet de s‚Äôassurer que le cerveau Bonsai apprend de diff√©rentes conditions.\n",
      "Correct. Un √©tat de d√©marrage personnalisable signifie que vous pouvez ajuster les conditions de d√©marrage pour tester les r√©ponses du cerveau aux nouveaux sc√©narios.\n",
      "Il permet d‚Äôidentifier le moment o√π un syst√®me passe √† un √©tat o√π la progression est impossible.\n",
      "4. Laquelle des affirmations suivantes sur l‚Äôutilisation du moteur d‚Äôapprentissage dans Bonsai est vraie ?\n",
      "L‚ÄôInstructeur ex√©cute les algorithmes d‚ÄôIA sous-jacents s√©lectionn√©s par l‚ÄôArchitecte.\n",
      "Le Pr√©dicteur ex√©cute le plan d‚Äôapprentissage en configurant l‚ÄôApprenant.\n",
      "L‚ÄôArchitecte cr√©e et optimise les topologies d‚Äôapprentissage.\n",
      "Correct. L‚ÄôArchitecte propose √©galement la configuration des topologies et des algorithmes d‚Äôapprentissage.\n",
      "5. Quelle affirmation sur les cerveaux Bonsai est exacte ?\n",
      "Votre cerveau Bonsai ne peut contenir qu‚Äôune seule version.\n",
      "Le cerveau Bonsai apprend un programme donn√© via un apprentissage it√©ratif avec le moteur d‚Äôapprentissage.\n",
      "Correct. En outre, lorsque vous apportez des modifications importantes √† votre programme, Bonsai cr√©e automatiquement une nouvelle version du cerveau.\n",
      "Lorsque vous √™tes satisfait de votre cerveau Bonsai, vous pouvez exporter uniquement la version la plus r√©cente.\n",
      "Incorrect. Vous pouvez exporter n‚Äôimporte quelle version du cerveau.\n",
      "------------------------\n",
      "1. Quel avantage offre le d√©ploiement d‚Äôun service Cognitive Services en tant qu‚Äôappareil IoT Edge dans un conteneur ?\n",
      "Les services Cognitive Services peuvent s‚Äôex√©cuter plus rapidement\n",
      "    - Le d√©ploiement en tant que conteneur sur un appareil p√©riph√©rique n‚Äôimplique pas n√©cessairement un traitement plus rapide.\n",
      "Ex√©cution en ligne possible\n",
      "(accrocher) Ex√©cution hors connexion possible\n",
      "2. Pour un service Cognitive Services, o√π l‚Äôentra√Ænement a lieu ?\n",
      "√Ä la p√©riph√©rie\n",
      "(accrocher) Dans le cloud\n",
      "Localement\n",
      "3. Quelle est la fonction du service Azure Container Registry ?\n",
      "(accrocher) Stockage et gestion d‚Äôimages conteneur\n",
      "    - Azure Container Registry permet de stocker et de g√©rer des images conteneur.\n",
      "Stockage et gestion d‚Äôimages\n",
      "    - Azure Container Registry ne permet pas de stocker et de g√©rer des images.\n",
      "Stockage et gestion de services\n",
      "------------------------\n",
      "1. NVIDIA Triton est un logiciel open source multi-framework qui prend en charge l‚Äôex√©cution de l‚Äôinf√©rence sur des frameworks de machine learning connus, comme ...\n",
      "TensorFlow, ONNX Runtime, PyTorch et NVIDIA TensorRT\n",
      "Bonne r√©ponse. Ces frameworks sont tous pris en charge par NVIDIA Triton Inference Server.\n",
      "Studio Azure Machine Learning et Azure Cognitive Services.\n",
      "Tout framework de machine learning bas√© sur Python.\n",
      "2. NVIDIA Triton Inference Server peut traiter les charges de travail ONNX sur ...\n",
      "Machines √©quip√©es de CPU ou de GPU\n",
      "Bonne r√©ponse. NVIDIA Triton Inference Server peut ex√©cuter des charges de travail ONNX sur des syst√®mes bas√©s sur CPU et tirer parti de l‚Äôacc√©l√©ration sur les syst√®mes avec un GPU pr√©sent.\n",
      "Machines √©quip√©es de CPU uniquement\n",
      "Machines √©quip√©es de GPU uniquement\n",
      "3. Microsoft Azure prend en charge les instances GPU dans le cloud en tant qu‚Äôoption lors du d√©ploiement d‚Äôune ressource de machine virtuelle en sp√©cifiant ...\n",
      "Options de taille\n",
      "Bonne r√©ponse. Microsoft Azure autorise les machines virtuelles √† optimisation GPU comme option de taille lors du d√©ploiement d‚Äôune ressource de machine virtuelle.\n",
      "Options de fonctionnalit√© mat√©rielle\n",
      "Options de disponibilit√©\n",
      "------------------------\n",
      "1. Pour prendre en charge l‚Äôinf√©rence en temps r√©el dans les applications de production, quel est le meilleur choix de cible de d√©ploiement pour le service Web de scoring ?\n",
      "Azure Kubernetes Service (AKS).\n",
      "Correct. AKS est recommand√© pour les d√©ploiements de production √† grande √©chelle. AKS fournit un temps de r√©ponse rapide et une mise √† l‚Äô√©chelle automatique du service d√©ploy√©.\n",
      "Azure Container Instances (ACI).\n",
      "Clusters de calcul Azure Machine Learning.\n",
      "2. Vous souhaitez d√©ployer un mod√®le sur Azure Container Instances. Vous avez enregistr√© le mod√®le form√©, cr√©√© un script d‚Äôentr√©e et un environnement. Vous souhaitez combiner le script d‚Äôentr√©e et l‚Äôenvironnement. Quel genre d‚Äôobjet devez-vous utiliser ?\n",
      "InferenceConfig\n",
      "Correct. InferenceConfig repr√©sente les param√®tres de configuration d‚Äôun environnement personnalis√© utilis√© pour le d√©ploiement et utilise un script d‚Äôentr√©e et un environnement comme param√®tres d‚Äôentr√©e.\n",
      "WebserviceDeploymentConfiguration\n",
      "ComputeTarget\n",
      "------------------------\n",
      "1. Dans quelle version de SQL Server les projets SSIS ont-ils fait leur premi√®re apparition ?\n",
      "SQL Server 2008.\n",
      "SQL Server 2012.\n",
      "Correct. Les projets SSIS ont fait leur premi√®re apparition dans SQL Server 2012, et constituent l‚Äôunit√© de d√©ploiement des solutions SSIS.\n",
      "SQL Server 2016.\n",
      "2. Quel outil est utilis√© pour √©valuer la migration des packages SSIS vers les services Azure SQL Database ?\n",
      "L‚ÄôAssistant Migration de donn√©es.\n",
      "Correct. L‚ÄôAssistant Migration de donn√©es est utilis√© pour √©valuer la migration des packages SSIS vers les services Azure SQL Database.\n",
      "L‚Äô√©valuation des migrations de donn√©es.\n",
      "Le service de migration des donn√©es.\n",
      "3. Quel outil est utilis√© pour cr√©er et d√©ployer des packages d‚Äôint√©gration SQL Server sur Azure-SSIS Integration Runtime ou sur une instance locale de SQL Server ?\n",
      "SQL Server Data Tools.\n",
      "Correct. SQL Server Data Tools est g√©n√©ralement utilis√© pour cr√©er et d√©ployer des packages SQL Server Integration Services (SSIS).\n",
      "SQL Server Management Studio.\n",
      "dtexec.\n",
      "------------------------\n",
      "1. Dans quel type de syst√®me de fichiers Apache Hadoop stocke-t-il des donn√©es ?\n",
      "Il n‚Äôa aucun stockage, les donn√©es sont stock√©es en m√©moire.\n",
      "HDFS\n",
      "HDFS est l‚Äôacronyme de ¬´ Hadoop Distributed File System ¬ª et est le magasin de donn√©es d‚Äôun syst√®me Hadoop.\n",
      "RDD\n",
      "2. Quel composant Hadoop est charg√© de g√©rer les ressources sur un syst√®me Hadoop ?\n",
      "Spark\n",
      "MapReduce\n",
      "MapReduce est un mod√®le de programmation qui vous permet de traiter et d‚Äôanalyser des donn√©es.\n",
      "YARN\n",
      "Il s‚Äôagit du composant charg√© de g√©rer les ressources sur un cluster Hadoop\n",
      "------------------------\n",
      "1. Dans le cadre de la configuration d‚Äôun workflow GitHub Actions pour l‚Äôex√©cution d‚Äôun travail Azure Machine Learning, quel d√©clencheur peut se r√©v√©ler pratique pour v√©rifier si le workflow fonctionne comme pr√©vu ?\n",
      "on: workflow_dispatch\n",
      "Incorrect. Utiliser on: workflow_dispatch pour d√©clencher manuellement un workflow.\n",
      "on: [push]\n",
      "on: [pull_request]\n",
      "Correct. Utiliser on: [pull_request] pour d√©clencher un workflow lorsqu‚Äôune demande de tirage est ouverte.\n",
      "2. Quelles √©tapes doivent √™tre incluses dans un workflow GitHub Actions pour entra√Æner un mod√®le ?\n",
      "Dupliquer (fork) le d√©p√¥t, se connecter √† Azure, installer l‚Äôinterface CLI et ex√©cuter un travail Azure Machine Learning.\n",
      "Extraire le d√©p√¥t, se connecter √† Azure, installer l‚Äôextension ML et d√©clencher un travail Azure Machine Learning.\n",
      "Correct. Le travail peut entra√Æner un mod√®le √† l‚Äôaide de la capacit√© de calcul Azure Machine Learning.\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(out)):\n",
    "    rr = out[j].split(\"\\n\")\n",
    "    rr = [i.replace(\"\\n\", \"\") for i in rr if any(i)]\n",
    "    for i in rr:\n",
    "        print(f'{i}')\n",
    "    # OU\n",
    "    f = open(f\"Q_Azure/out{j}.txt\", \"wt\")\n",
    "    for i in rr:\n",
    "        f.write(f\"{i}\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062f0e35",
   "metadata": {},
   "source": [
    "# Utiliser le programme!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb5cf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import PySimpleGUI as sg\n",
    "import os\n",
    "from time import sleep\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import openai\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb0d33c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reddit'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sg.theme(\"DarkBlue15\")\n",
    "#sg.theme(\"LightGreen1\")\n",
    "sg.theme(\"reddit\")\n",
    "#sg.theme(\"DarkTeal2\")\n",
    "#sg.theme(\"Black\")\n",
    "#sg.theme(\"TealMono\")\n",
    "#sg.theme(\"TanBlue\")\n",
    "#sg.theme(\"Tan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba1116a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gen_rand = 206653513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af8e37eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credential :  <azure.identity._credentials.default.DefaultAzureCredential object at 0x7fb5ba6565f0>\n",
      "Primary key for storage account: ZJbEmvowrnI5issx8xXdG86dx+dPIn05vSG5dSbBf3Q8/pe3g+inOwDHhgQSwcc8qOyz3MzLi2ao+AStnppyTw==\n",
      "Connection string: DefaultEndpointsProtocol=https;EndpointSuffix=core.windows.net;AccountName=storagename206653513;AccountKey=ZJbEmvowrnI5issx8xXdG86dx+dPIn05vSG5dSbBf3Q8/pe3g+inOwDHhgQSwcc8qOyz3MzLi2ao+AStnppyTw==\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------\n",
    "# Lire des fichiers d'Azure\n",
    "# ----------------------------------\n",
    "from azure.identity import DefaultAzureCredential\n",
    "credential = DefaultAzureCredential()\n",
    "print('credential : ', credential)\n",
    "\n",
    "# Obtenir Nom d'abonnement\n",
    "subscription_id = '425ecd08-433c-4c16-bcb0-f1ad27233c6d'\n",
    "\n",
    "# Obtenir Resource Group Name\n",
    "RESOURCE_GROUP_NAME = f\"gdr-name-{num_gen_rand}\"\n",
    "\n",
    "# -------------------------------------\n",
    "\n",
    "# Connect √† Azure compte de stockage\n",
    "STORAGE_ACCOUNT_NAME = f\"storagename{num_gen_rand}\"\n",
    "\n",
    "from azure.mgmt.storage import StorageManagementClient\n",
    "\n",
    "# Provision the storage account, starting with a management object\n",
    "storage_client = StorageManagementClient(credential, subscription_id)\n",
    "\n",
    "keys = storage_client.storage_accounts.list_keys(RESOURCE_GROUP_NAME, STORAGE_ACCOUNT_NAME)\n",
    "\n",
    "print(f\"Primary key for storage account: {keys.keys[0].value}\")\n",
    "\n",
    "# Verifier acces: Avec mot de passe - obtenir le cha√Æne de connexion\n",
    "os.environ['AZURE_STORAGE_CONNECTION_STRING'] = f\"DefaultEndpointsProtocol=https;EndpointSuffix=core.windows.net;AccountName={STORAGE_ACCOUNT_NAME};AccountKey={keys.keys[0].value}\"\n",
    "\n",
    "connection_string = os.getenv('AZURE_STORAGE_CONNECTION_STRING')\n",
    "print(f\"Connection string: {connection_string}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1eb7916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir un liste des fichiers dans le compte de stockage\n",
    "from azure.storage.fileshare import ShareDirectoryClient\n",
    "from azure.storage.fileshare import ShareFileClient\n",
    "\n",
    "# ----------------------------------\n",
    "share_name = f\"fichiershare-{num_gen_rand}\"\n",
    "directory_path = f\"directory-{num_gen_rand}\"\n",
    "\n",
    "parent_dir = ShareDirectoryClient.from_connection_string(conn_str=connection_string, \n",
    "                                                         share_name=share_name, \n",
    "                                                         directory_path=directory_path)\n",
    "\n",
    "my_list = list(parent_dir.list_directories_and_files())\n",
    "listes_de_fichiers = [my_list[i].name for i in range(len(my_list))]\n",
    "# ----------------------------------\n",
    "\n",
    "# ----------------------------------\n",
    "# Parce des noms de fichiers\n",
    "tmp = sorted(listes_de_fichiers)\n",
    "replace_le = ['out', '.txt']\n",
    "replace_avec = ['', '']\n",
    "\n",
    "tmp1 = []\n",
    "for nom in tmp:\n",
    "    for ind, i in enumerate(replace_le):\n",
    "        nom = nom.replace(i, replace_avec[ind])\n",
    "    tmp1.append(int(nom))\n",
    "ordd = np.argsort(tmp1)\n",
    "\n",
    "listes_de_fichiers_sort = [tmp[i] for i in ordd]\n",
    "# ----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "725d6fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(textout):\n",
    "    to_replace = [\";\", '\\n', '</p>', '<a', 'id=', \"href=\", 'title=', 'class=', '</a>', \n",
    "                  '</sup>', '<p>', '</b>', '<sup', '>', '<', '\\\\']\n",
    "    replace_with = ''\n",
    "\n",
    "    for ind, tr in enumerate(to_replace):\n",
    "        textout = [i.replace(tr, replace_with) for i in textout]\n",
    "    return textout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e73377d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt reponse:  ['Pour r√©pondre √† ces exigences, vous devez cr√©er un jeu de donn√©es']\n",
      "myres:  0\n",
      "vrai_rep:  3. Cr√©ez un jeu de donn√©es tabulaire qui r√©f√©rence la banque de donn√©es et sp√©cifie explicitement chaque fichier 'sales/mm-yyyy/sales.csv'. Enregistrez le jeu de donn√©es avec le nom sales_dataset chaque mois en tant que nouvelle version et avec une balise nomm√©e mois indiquant le mois et l‚Äôann√©e o√π il a √©t√© enregistr√©. Utilisez ce jeu de donn√©es pour toutes les exp√©riences, en identifiant la version √† utiliser en fonction de la balise month si n√©cessaire.\n",
      "gpt:  1. Cr√©ez un jeu de donn√©es tabulaire qui r√©f√©rence la banque de donn√©es et sp√©cifie explicitement chaque fichier ¬´ sales/mm-yyyy/sales.csv ¬ª chaque mois. Enregistrez le jeu de donn√©es avec le nom sales_dataset chaque mois, en rempla√ßant le jeu de donn√©es existant et en sp√©cifiant une balise nomm√©e mois indiquant le mois et l‚Äôann√©e o√π il a √©t√© enregistr√©. Utilisez ce jeu de donn√©es pour toutes les exp√©riences.\n",
      "---------------------------------------\n",
      "gpt reponse:  ['Erreur de faux n√©gatif.']\n",
      "myres:  Faux n√©gatifs\n",
      "vrai_rep:  Faux n√©gatifs\n",
      "gpt:  Faux n√©gatifs\n",
      "---------------------------------------\n",
      "gpt reponse:  [\"Une visualisation couramment utilis√©e pour √©valuer la pr√©cision d'un mod√®le d'apprent\"]\n",
      "myres:  Courbe ROC (Receiver Operating Characteristic)\n",
      "vrai_rep:  Courbe ROC (Receiver Operating Characteristic)\n",
      "gpt:  Trac√© de violon\n",
      "---------------------------------------\n",
      "gpt reponse:  ['1. Utilisez des techniques de r√©gularisation telles que le dropout et la r√©gularisation L2 pour']\n",
      "myres:  Ajouter une r√©gularisation L1/L2 et Utiliser l‚Äôaugmentation des donn√©es d‚Äôapprentissage\n",
      "vrai_rep:  Ajouter une r√©gularisation L1/L2 et Utiliser l‚Äôaugmentation des donn√©es d‚Äôapprentissage\n",
      "gpt:  Ajouter une r√©gularisation L1/L2 et Utiliser l‚Äôaugmentation des donn√©es d‚Äôapprentissage\n",
      "---------------------------------------\n",
      "gpt reponse:  ['pca = PCA(n_components=10).fit(X_train)x_train = pca.transform']\n",
      "myres:  0\n",
      "vrai_rep:  Box1: PCA(n_components=10); Box2: pca; Box3: transform(x_test)\n",
      "gpt:  Box1: PCA(n_components=10); Box2: pca; Box3: transform(x_test)\n",
      "---------------------------------------\n",
      "gpt reponse:  [\"L'int√©gration continue peut inclure des activit√©s telles que la compilation, le test unitaire, le test\"]\n",
      "myres:  1. V√©rification lint\n",
      "vrai_rep:  1. V√©rification lint\n",
      "gpt:  1. V√©rification lint\n",
      "---------------------------------------\n",
      "gpt reponse:  [\"Non, le mod√®le de r√©gression lin√©aire ne peut pas atteindre l'objectif. Les mesures\"]\n",
      "myres:  Non\n",
      "vrai_rep:  Non\n",
      "gpt:  Non\n",
      "---------------------------------------\n",
      "gpt reponse:  [\"Lorsqu'une liste est multipli√©e par 5, chaque √©l√©ment de la liste est multipli√© par\"]\n",
      "myres:  La nouvelle liste cr√©√©e a la longueur 5 fois la longueur d‚Äôorigine avec la s√©quence r√©p√©t√©e 5 fois.\n",
      "vrai_rep:  La nouvelle liste cr√©√©e a la longueur 5 fois la longueur d‚Äôorigine avec la s√©quence r√©p√©t√©e 5 fois.\n",
      "gpt:  None\n",
      "---------------------------------------\n",
      "gpt reponse:  ['Ceci est une mesure de pr√©cision absolue.']\n",
      "myres:  Erreur quadratique moyenne (RMSE)\n",
      "vrai_rep:  Erreur quadratique moyenne (RMSE)\n",
      "gpt:  Rien\n",
      "---------------------------------------\n",
      "gpt reponse:  [\"Scikit-learn est une biblioth√®que open source pour l'apprentissage automatique en Python. Il\"]\n",
      "myres:  Offrir une analyse pr√©dictive des donn√©es simple et efficace\n",
      "vrai_rep:  Offrir une analyse pr√©dictive des donn√©es simple et efficace\n",
      "gpt:  Fournir des capacit√©s de machine learning et de deep learning\n",
      "---------------------------------------\n",
      "gpt reponse:  ['Les valeurs de donn√©es qui influencent les mod√®les de pr√©diction comprennent les variables']\n",
      "myres:  Caract√©ristiques\n",
      "vrai_rep:  Caract√©ristiques\n",
      "gpt:  Variables d√©pendantes\n",
      "---------------------------------------\n",
      "gpt reponse:  [\"Le type de machine learning le plus appropri√© pour ce type de probl√®me serait l'apprentissage supervis√©\"]\n",
      "myres:  R√©gression\n",
      "vrai_rep:  R√©gression\n",
      "gpt:  None\n",
      "---------------------------------------\n",
      "gpt reponse:  ['Vous devriez utiliser un mod√®le de machine learning appel√© r√©gression. La r√©gression est un type de mod']\n",
      "myres:  R√©gression\n",
      "vrai_rep:  R√©gression\n",
      "gpt:  R√©gression\n",
      "---------------------------------------\n",
      "gpt reponse:  [\"La t√¢che d'apprentissage automatique qui conviendrait le mieux √† cette application serait\"]\n",
      "myres:  S√©lection des fonctionnalit√©s\n",
      "vrai_rep:  S√©lection des fonctionnalit√©s\n",
      "gpt:  None\n",
      "---------------------------------------\n",
      "gpt reponse:  ['Vrai.']\n",
      "myres:  False\n",
      "vrai_rep:  False\n",
      "gpt:  True\n",
      "---------------------------------------\n",
      "gpt reponse:  ['- Machine Learning (apprentissage automatique)']\n",
      "myres:  Classification\n",
      "vrai_rep:  Classification\n",
      "gpt:  Clustering\n",
      "---------------------------------------\n",
      "gpt reponse:  ['-Matrice de confusion-Courbe ROC-Score de pr√©cision-Score F1']\n",
      "myres:  Taux de vrais positifs\n",
      "vrai_rep:  Taux de vrais positifs\n",
      "gpt:  Coefficient de d√©termination (R2)\n",
      "---------------------------------------\n",
      "gpt reponse:  [\"Faux. L'apprentissage automatique n√©cessite des donn√©es d'apprentissage pr\"]\n",
      "myres:  0\n",
      "vrai_rep:  Faux\n",
      "gpt:  Faux\n",
      "---------------------------------------\n",
      "gpt reponse:  ['Vrai.']\n",
      "myres:  True\n",
      "vrai_rep:  True\n",
      "gpt:  True\n",
      "---------------------------------------\n",
      "gpt reponse:  [\"Le type de machine learning le plus appropri√© pour ce type d'application CRM serait l'apprentissage supervis√©\"]\n",
      "myres:  Clustering\n",
      "vrai_rep:  Clustering\n",
      "gpt:  Classification\n",
      "---------------------------------------\n",
      "gpt reponse:  ['']\n",
      "myres:  A. 0, 1, 4\n",
      "vrai_rep:  A. 0, 1, 4\n",
      "gpt:  A. 0, 1, 4\n",
      "---------------------------------------\n",
      "gpt reponse:  ['Les deux param√®tres suppl√©mentaires √† ajouter au fichier config.json pour se connecter √† l']\n",
      "myres:  Resource_group et Subscription_id\n",
      "vrai_rep:  Resource_group et Subscription_id\n",
      "gpt:  Region\n",
      "---------------------------------------\n",
      "gpt reponse:  ['Pour le sc√©nario 1, vous devez utiliser un environnement de calcul Azure Machine Learning Compute pour ex']\n",
      "myres:  1 mlc_cluster, 2 aks_cluster\n",
      "vrai_rep:  1 mlc_cluster, 2 aks_cluster\n",
      "gpt:  1 mlc_cluster, 2 aks_cluster\n",
      "---------------------------------------\n",
      "gpt reponse:  ['Vous devriez utiliser un cluster de calcul Azure HDInsight pour d√©ployer votre espace de travail de']\n",
      "myres:  Azure Container Instances\n",
      "vrai_rep:  Azure Container Instances\n",
      "gpt:  Apache Spark pour HDInsight\n",
      "---------------------------------------\n",
      "gpt reponse:  [' )datastore = Datastore.register_azure_blob_container(workspace=ws,                                 ']\n",
      "myres:  register_azure_blob_container, create_if_not_exists = False\n",
      "vrai_rep:  register_azure_blob_container, create_if_not_exists = False\n",
      "gpt:  register_azure_blob_container, overwrite = True\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "gptcnt = 0\n",
    "SCORE = 0\n",
    "GPT_SCORE = 0\n",
    "noms = ['QUESTION', 'REPONSE0', 'REPONSE1', 'REPONSE2', 'REPONSE3', 'vrai_rep']\n",
    "\n",
    "myres = 0\n",
    "\n",
    "for ind, nom_de_fichier in enumerate(listes_de_fichiers_sort):\n",
    "    \n",
    "    # ----------------------------------\n",
    "    # Lire des fichiers d'Azure\n",
    "    # ----------------------------------\n",
    "    # T√©l√©chargez le fichier √† un path\n",
    "    file_client = ShareFileClient.from_connection_string(conn_str=connection_string, \n",
    "                                                     share_name=share_name, \n",
    "                                                     file_path=f\"{directory_path}/{nom_de_fichier}\")\n",
    "\n",
    "    with open(\"DEST_FILE\", \"wb\") as file_handle:\n",
    "        data = file_client.download_file()\n",
    "        data.readinto(file_handle)\n",
    "    # ----------------------------------\n",
    "    \n",
    "    # ----------------------------------\n",
    "    # Lire des fichiers de mon PC\n",
    "    # ----------------------------------\n",
    "    out = []\n",
    "    with open(\"DEST_FILE\", 'r') as reader:\n",
    "        out.append(reader.read())\n",
    "    out = out[0].split('\\n')\n",
    "    out = [i for i in out if any(i)]\n",
    "    # ----------------------------------\n",
    "    \n",
    "    d = dict(zip(noms, out))\n",
    "  \n",
    "    \n",
    "    # ----------------------------------\n",
    "    prompt = d['QUESTION']\n",
    "    response = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, \n",
    "                                        temperature=0.1, max_tokens=30, \n",
    "                                        top_p=1, n=1, logprobs=2)\n",
    "    \n",
    "    \n",
    "    df = pd.json_normalize(response.choices)\n",
    "    d['chatgpt_rep'] = clean_text(df.text.to_numpy())\n",
    "    print('gpt reponse: ', d['chatgpt_rep'])\n",
    "    \n",
    "    # Determiner laquelle est similar √† le reponse de chatgpt\n",
    "    a = ['REPONSE0', 'REPONSE1', 'REPONSE2', 'REPONSE3']\n",
    "    out = []\n",
    "    for i in a:\n",
    "        out.append(fuzz.partial_ratio(d['chatgpt_rep'], d[i]))\n",
    "    v_ind = np.argmax(out)\n",
    "    v = a[v_ind]\n",
    "    d['chatgpt_choix'] = d[v] \n",
    "    # ----------------------------------\n",
    "    \n",
    "    if ind == len(listes_de_fichiers)-1:\n",
    "        layout = [[sg.Text(f'Current SCORE: {SCORE}')], \n",
    "                  [sg.Text(d['QUESTION'])]]\n",
    "    else:\n",
    "        layout = [[sg.Text(f'Q{ind}, MY Current SCORE: {SCORE}, chatgpt: {v_ind+1}, GPTCHAT Score: {GPT_SCORE}')], \n",
    "                  [sg.Multiline(d['QUESTION'], size=(40,10))],\n",
    "              [sg.Button(d['REPONSE0'])],  \n",
    "              [sg.Button(d['REPONSE1'])],\n",
    "              [sg.Button(d['REPONSE2'])],\n",
    "              [sg.Button(d['REPONSE3'])]]\n",
    "    \n",
    "    # Create the window\n",
    "    window = sg.Window(\"DataLogger\", layout, margins=(200, 200))\n",
    "    \n",
    "    event, values = window.read()\n",
    "    \n",
    "    if event == d['REPONSE0'] and d['vrai_rep'] == d['REPONSE0']:  \n",
    "        cnt = cnt + 1\n",
    "        myres = d['REPONSE0']\n",
    "    if event == d['REPONSE1'] and d['vrai_rep'] == d['REPONSE1']:\n",
    "        cnt = cnt + 1\n",
    "        myres = d['REPONSE1']\n",
    "    if event == d['REPONSE2'] and d['vrai_rep'] == d['REPONSE2']:\n",
    "        cnt = cnt + 1\n",
    "        myres = d['REPONSE2']\n",
    "    if event == d['REPONSE3'] and d['vrai_rep'] == d['REPONSE3']:\n",
    "        cnt = cnt + 1\n",
    "        myres = d['REPONSE3']\n",
    "        \n",
    "    SCORE = cnt/(ind+1) * 100\n",
    "    \n",
    "    # ----------------------------------\n",
    "    \n",
    "    if d['chatgpt_choix'] == d['REPONSE0'] and d['vrai_rep'] == d['REPONSE0']:  \n",
    "        gptcnt = gptcnt + 1\n",
    "    if d['chatgpt_choix'] == d['REPONSE1'] and d['vrai_rep'] == d['REPONSE1']:\n",
    "        gptcnt = gptcnt + 1\n",
    "    if d['chatgpt_choix'] == d['REPONSE2'] and d['vrai_rep'] == d['REPONSE2']:\n",
    "        gptcnt = gptcnt + 1\n",
    "    if d['chatgpt_choix'] == d['REPONSE3'] and d['vrai_rep'] == d['REPONSE3']:\n",
    "        gptcnt = gptcnt + 1\n",
    "        \n",
    "    GPT_SCORE = gptcnt/(ind+1) * 100\n",
    "    \n",
    "    # ----------------------------------\n",
    "    \n",
    "    print('myres: ', myres)\n",
    "    print('vrai_rep: ', d['vrai_rep'])\n",
    "    print('gpt: ', d['chatgpt_choix'])\n",
    "    print('---------------------------------------')\n",
    "    \n",
    "    if myres == 0:\n",
    "        f = open(\"resultants.txt\", \"a\")\n",
    "        f.write(f\"{d['QUESTION']}\\n{myres}\\n{d['vrai_rep']}\")\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.close()\n",
    "        \n",
    "    myres = 0\n",
    "    window.close()\n",
    "\n",
    "\n",
    "sleep(1)  # Wait 10 second\n",
    "window.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3543a39b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c003a63c",
   "metadata": {},
   "source": [
    "# PLUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19804790",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Charger des fichiers au sharefile \n",
    "from azure.storage.fileshare import ShareFileClient\n",
    "\n",
    "file_client = ShareFileClient.from_connection_string(conn_str=connection_string, \n",
    "                                                     share_name=share_name, \n",
    "                                                     file_path=f\"{directory_path}/{nom_de_fichier}\")\n",
    "\n",
    "# ----------------------------------\n",
    "\n",
    "path = \"/home/oem2/Documents/PROGRAMMING/Github_analysis_PROJECTS/Cr√©er_des_questionnaires/Q_Azure\"\n",
    "listes_de_fichiers = os.listdir(path)\n",
    "\n",
    "# Parce des noms de fichiers\n",
    "tmp = sorted(listes_de_fichiers)\n",
    "replace_le = ['out', '.txt']\n",
    "replace_avec = ['', '']\n",
    "\n",
    "tmp1 = []\n",
    "for nom in tmp:\n",
    "    for ind, i in enumerate(replace_le):\n",
    "        nom = nom.replace(i, replace_avec[ind])\n",
    "    tmp1.append(int(nom))\n",
    "ordd = np.argsort(tmp1)\n",
    "\n",
    "listes_de_fichiers_sort = [tmp[i] for i in ordd]\n",
    "\n",
    "# ----------------------------------\n",
    "\n",
    "for ind, nom_de_fichier in enumerate(listes_de_fichiers_sort):\n",
    "\n",
    "    with open(f\"Q_Azure/{nom_de_fichier}\", \"rb\") as source_file:\n",
    "        file_client.upload_file(source_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd62878d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e66a967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
